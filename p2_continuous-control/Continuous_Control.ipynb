{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posix.uname_result(sysname='Linux', nodename='Anubis-Linux', release='5.4.0-48-generic', version='#52-Ubuntu SMP Thu Sep 10 10:58:49 UTC 2020', machine='x86_64')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.uname())\n",
    "\n",
    "# In the cloud environment?\n",
    "if 'root' in os.environ['HOME']:\n",
    "    UENVPATH = '/data/'\n",
    "    !pip -q install /home/workspace/python\n",
    "\n",
    "# In the standalone environment?\n",
    "if 'ferenc' in os.environ['HOME']:\n",
    "    UENVPATH = '/home/ferenc/Python/rl/udadrl/data/'\n",
    "\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "import pprint as pp\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "from time import time\n",
    "\n",
    "# Import the helper files\n",
    "from utilities import get_time_string, print_elapsed_time\n",
    "\n",
    "import pdb # Debug! Debug! Debug! Debug! Debug! Debug! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-26 / 21-29-16  Notebook for Continuous Control started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_size -> 5.0\n",
      "\t\tgoal_speed -> 1.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "print(get_time_string(sep=True), ' Notebook for Continuous Control started.')\n",
    "\n",
    "# ONE Agent, Standalone\n",
    "#UENVCHOICE = 'Reacher_Linux/Reacher.x86_64'\n",
    "\n",
    "# TWENTY Agents, Standalone\n",
    "#UENVCHOICE = 'Reacher_Linux_20/Reacher.x86_64'\n",
    "\n",
    "# ONE Agent, Cloud, No-Visuals \n",
    "#UENVCHOICE = 'Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64'\n",
    "\n",
    "# TWENTY Agents, Cloud, No-Visuals \n",
    "UENVCHOICE = 'Reacher_Linux_NoVis/Reacher.x86_64'\n",
    "\n",
    "env = UnityEnvironment( file_name=os.path.join( UENVPATH, UENVCHOICE ) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unityagents.environment.UnityEnvironment"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FA DEBUG! DEBUG! DEBUG! \n",
    "type(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ReacherBrain']\n",
      "<class 'unityagents.brain.BrainParameters'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ReacherBrain'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FA  DEBUG! DEBUG! DEBUG! \n",
    "print(env.brain_names)\n",
    "print( type(brain) )\n",
    "brain.brain_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space: 33 dimensions of continuous type\n",
      "Action Space: 4 dimensions of continuous type\n"
     ]
    }
   ],
   "source": [
    "# FA  DEBUG! DEBUG! DEBUG!\n",
    "print(f'Observation Space: {brain.vector_observation_space_size} dimensions of {brain.vector_observation_space_type} type') \n",
    "print(f'Action Space: {brain.vector_action_space_size} dimensions of {brain.vector_observation_space_type} type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 20 active agents\n",
      "\n",
      "***--> Total Elapsed Runtime: 00:00:00 for choosing random actions\n",
      "#\n",
      "Total score (averaged over agents) this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Should a run with random actions be perfomed first?\n",
    "RANDOMRUN = False\n",
    "\n",
    "# Some reminders about lambda functions\n",
    "# Thx2: https://realpython.com/python-lambda/\n",
    "# Thx2: https://thispointer.com/python-how-to-use-if-else-elif-in-lambda-functions/\n",
    "# thx2: https://www.blog.pythonlibrary.org/2016/05/24/python-101-an-intro-to-benchmarking-your-code/\n",
    "import timeit\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "\n",
    "epc = 0\n",
    "print(f'We have {num_agents} active agent' + ( lambda x: 's' if x>1 else '' )(num_agents) )\n",
    "\n",
    "start_time = time()\n",
    "setup = \"from unityagents import UnityEnvironment\"\n",
    "\n",
    "while RANDOMRUN:\n",
    "    epc += 1\n",
    "    #print(f'\\r#{epc}', end = ' ')\n",
    "    print(f'\\r#{str(epc).rjust(6)}', end = ' ')\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    #pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    #print( timeit.timeit(\"env_info = env.step(actions)[brain_name]\", setup) )\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    rewards = env_info.rewards\n",
    "    nprewards = np.array(rewards)\n",
    "    scores += rewards                         # update the score (for each agent)\n",
    "    if np.sum(nprewards) > 0:\n",
    "        #print(f'\\r#{epc} Rewards = {rewards}')\n",
    "        maskagent = nprewards > 0\n",
    "        agentbefore = False\n",
    "        for (nagent, action) in enumerate(actions):\n",
    "            if maskagent[nagent]:\n",
    "                if agentbefore:\n",
    "                    print('\\r#' + '&'.rjust(6), end = ' ')\n",
    "                print(' -> Agent {:0>2d} got reward {:+.5f} for action: {}'.format(nagent+1, rewards[nagent], action))\n",
    "                agentbefore = True\n",
    "                #pp.pprint(list(action))\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "        \n",
    "end_time = time()\n",
    "\n",
    "print_elapsed_time(start_time, end_time, \"for choosing random actions\")\n",
    "\n",
    "print('#')\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re check running time (Random run)\n",
    "This time with the leanest code possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 20 active agents\n",
      "\n",
      "***--> Total Elapsed Runtime: 00:00:00 for choosing fast random actions\n",
      "#\n",
      "Total score (averaged over agents) this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Should another run with random actions be perfomed?\n",
    "RANDOMRUN = False\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "#env_info = env.reset(train_mode=True)[brain_name] # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "\n",
    "epc = 0\n",
    "print(f'We have {num_agents} active agent' + ( lambda x: 's' if x>1 else '' )(num_agents) )\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "while RANDOMRUN:\n",
    "    epc += 1\n",
    "    print(f'\\r#{str(epc).rjust(6)}', end = ' ')\n",
    "    #pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "        \n",
    "end_time = time()\n",
    "\n",
    "print_elapsed_time(start_time, end_time, \"for choosing fast random actions\")\n",
    "\n",
    "print('#')\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.12805176e+00,\n",
       "        -1.00000000e+00, -3.63192368e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  3.92812490e-02],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  5.03456116e+00,\n",
       "        -1.00000000e+00,  6.21716690e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  9.63666677e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  5.24847412e+00,\n",
       "        -1.00000000e+00,  6.03767776e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00, -1.35212541e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -7.87846184e+00,\n",
       "        -1.00000000e+00, -1.38918507e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00, -5.42254448e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -2.79192984e-01,\n",
       "        -1.00000000e+00,  7.99512672e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  7.49394178e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  4.70228195e+00,\n",
       "        -1.00000000e+00, -6.47213650e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  2.25743055e-02],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -3.75577545e+00,\n",
       "        -1.00000000e+00, -7.06358004e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  5.07442713e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.38918495e+00,\n",
       "        -1.00000000e+00,  7.87846184e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00, -4.48411107e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.73616028e+00,\n",
       "        -1.00000000e+00, -7.51754141e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00, -5.25649071e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -5.55726719e+00,\n",
       "        -1.00000000e+00, -5.75471878e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  6.52894735e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -6.99695778e+00,\n",
       "        -1.00000000e+00,  3.87847900e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  8.39847088e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.60454559e+00,\n",
       "        -1.00000000e+00, -7.56414795e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  8.63162279e-02],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.30836487e+00,\n",
       "        -1.00000000e+00,  3.25389290e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  5.08338690e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.96955776e+00,\n",
       "        -1.00000000e+00,  6.97246552e-01,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  6.07460499e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.51754093e+00,\n",
       "        -1.00000000e+00,  2.73616028e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  5.45782328e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -7.25046158e+00,\n",
       "        -1.00000000e+00, -3.38094544e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  2.36645341e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -2.79193878e-01,\n",
       "        -1.00000000e+00,  7.99512482e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  5.87887526e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.33897400e+00,\n",
       "        -1.00000000e+00, -7.65043640e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  6.67207956e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -5.75471878e+00,\n",
       "        -1.00000000e+00,  5.55726624e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00, -5.25265932e-02],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  5.94515800e+00,\n",
       "        -1.00000000e+00, -5.35304642e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00, -8.03074121e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# thx2: https://github.com/udacity/deep-reinforcement-learning/blob/master/python/unityagents/brain.py\n",
    "env_info.vector_observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When finished, you can close the environment.\n",
    "#### Just not for now because unit testing below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FA: One BIG MISUNDERSTANDING & STACKS OF TENSORS (23-08-2020) --> #FA; BMSoT:\n",
    "It has cost me several days if not weeks to get behind the fact that the [A2C sample implementation of Miguel](https://github.com/mimoralea/gdrl/blob/master/notebooks/chapter_11/chapter-11.ipynb) is working with **stacks of tensors** instead of single tensors. Which was especially hard to find because the PyTorch code looks exactly the same for both.\n",
    "\n",
    "In the end, when I thought about it, it makes sense and is a nifty feature of PyTorch. It is just not obvious to people like me, without in deep insights in the inner workings of PyTorch. \n",
    "\n",
    "Furthermore the authors of the PyTorch documentation seem not to make it too visible, I had to dig it out of one of the function definitions I use, however inderectly over the layer defintion for a2cnet:\n",
    "\n",
    "https://pytorch.org/docs/0.4.0/_modules/torch/nn/functional.html#linear\n",
    "\n",
    "> def linear(input, weight, bias=None):\n",
    ">    \"\"\"\n",
    ">    Applies a linear transformation to the incoming data: :math:`y = xA^T + b`.\n",
    ">\n",
    ">    Shape:\n",
    ">        - Input: :math:`(N, *, in\\_features)` where `*` means any number of\n",
    ">          additional dimensions\n",
    ">        - Weight: :math:`(out\\_features, in\\_features)`\n",
    ">        - Bias: :math:`(out\\_features)`\n",
    ">        - Output: :math:`(N, *, out\\_features)`\n",
    ">    \"\"\"\n",
    ">    if input.dim() == 2 and bias is not None:\n",
    ">        # fused op is marginally faster\n",
    ">        return torch.addmm(bias, input, weight.t())\n",
    ">\n",
    ">    output = input.matmul(weight.t())\n",
    ">    if bias is not None:\n",
    ">        output += bias\n",
    ">    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracing the error in the 'mya2cnet' module code refactoring below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! \n",
    "#import pdb; pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(20200808) # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "#torch.manual_seed(456454618181) # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "\n",
    "# Format: IN_Num [Layer 1] (OUT_Num = IN_Num) [Layer 2] OUT_Num = ...\n",
    "HIDDEN_DIMS_DEFAULT = {\n",
    "    'shared' : (512, 512, 256, 256),\n",
    "    'actor' : (256, 128, 128, 64),\n",
    "    'critic' : (256, 128, 128, 64)\n",
    "}\n",
    "hidden_dims = HIDDEN_DIMS_DEFAULT\n",
    "\n",
    "hlayers = dict()\n",
    "\n",
    "hlayers['shared'] = nn.ModuleList()\n",
    "hlayers['actor'] = nn.ModuleList()\n",
    "hlayers['critic'] = nn.ModuleList()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "input_layer = nn.Linear( 33, hidden_dims['shared'][0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=33, out_features=512, bias=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layers shared\n",
    "for i in range( len(hidden_dims['shared']) -1 ):\n",
    "    hlayers['shared'].append( nn.Linear( hidden_dims['shared'][i], hidden_dims['shared'][i+1] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hlayers['shared']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actor layers\n",
    "for i in range( len(hidden_dims['actor']) ):\n",
    "    #import pdb; pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "    if i == 0:\n",
    "        hlayers['actor'].append( nn.Linear( hidden_dims['shared'][-1], hidden_dims['actor'][i] ) )\n",
    "    else:\n",
    "        # hlayers['actor'].append( nn.Linear( hidden_dims['actor'][i], hidden_dims['actor'][i+1] ERROR !!!\n",
    "        hlayers['actor'].append( nn.Linear( hidden_dims['actor'][i-1], hidden_dims['actor'][i] ) )\n",
    "    #print( i, hlayers['actor'] ) # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "        \n",
    "actor_out_layer = nn.Linear( hidden_dims['actor'][-1], 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (3): Linear(in_features=128, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hlayers['actor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=64, out_features=4, bias=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Critic layers\n",
    "for i in range( len(hidden_dims['critic']) ):\n",
    "    if i == 0:\n",
    "        hlayers['critic'].append( nn.Linear( hidden_dims['shared'][-1], hidden_dims['critic'][i] ) )\n",
    "    else:\n",
    "        hlayers['critic'].append( nn.Linear( hidden_dims['critic'][i-1], hidden_dims['critic'][i] ) )\n",
    "critic_out_layer = nn.Linear( hidden_dims['critic'][-1], 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (3): Linear(in_features=128, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hlayers['critic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=64, out_features=1, bias=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic_out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevents non Pytorch Tensor Object entering the processing stream\n",
    "def torch_format(state):\n",
    "    x = state\n",
    "    if not isinstance(x, torch.Tensor):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        if len(x.size()) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(state):\n",
    "    check_tensor = lambda x: isinstance(x, torch.Tensor)\n",
    "    x_act = True \n",
    "    x_crit = True\n",
    "\n",
    "    x = torch_format(state)\n",
    "    x = F.relu(  input_layer(x) )\n",
    "    for label in ['shared', 'actor', 'critic']:\n",
    "        for hlayer in  hlayers[label]:\n",
    "            if label == 'shared':\n",
    "                x = F.relu(  hlayer(x) )\n",
    "            if label == 'actor':\n",
    "                x_act = F.relu(  hlayer(x_act) )\n",
    "            if label == 'critic':\n",
    "                x_crit = F.relu(  hlayer(x_crit) )\n",
    "\n",
    "        # Thx2: https://discuss.pytorch.org/t/copy-deepcopy-vs-clone/55022\n",
    "        if ( type(x_act) == bool ):\n",
    "            x_act = x.clone()  # Create an Inplace copy...\n",
    "        if ( type(x_crit) == bool ):\n",
    "            x_crit = x.clone() # ...after processing shared layers\n",
    "\n",
    "    return  actor_out_layer(x_act),  critic_out_layer(x_crit) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if A STACK OF (BMSoT) states are propagated through the debug network\n",
    "And make a list of outputs of two A2C instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor: tensor(1.00000e-02 *\n",
      "       [[ 4.6543,  4.9756, -4.4953,  4.2128],\n",
      "        [ 4.7037,  4.9775, -4.4215,  4.1041],\n",
      "        [ 4.7006,  4.9798, -4.4235,  4.1018],\n",
      "        [ 4.6981,  4.9901, -4.3603,  4.1175],\n",
      "        [ 4.7117,  4.9911, -4.4272,  4.1191],\n",
      "        [ 4.6864,  4.9768, -4.4898,  4.2664],\n",
      "        [ 4.7017,  5.0059, -4.4374,  4.2481],\n",
      "        [ 4.7107,  4.9870, -4.4269,  4.1114],\n",
      "        [ 4.6985,  4.9721, -4.4752,  4.2727],\n",
      "        [ 4.6935,  5.0025, -4.4124,  4.2141],\n",
      "        [ 4.7007,  4.9718, -4.3907,  4.1061],\n",
      "        [ 4.6997,  4.9750, -4.4772,  4.2800],\n",
      "        [ 4.6790,  4.9917, -4.4376,  4.1197],\n",
      "        [ 4.6685,  4.9951, -4.4505,  4.1421],\n",
      "        [ 4.6763,  4.9944, -4.4406,  4.1248],\n",
      "        [ 4.6967,  4.9936, -4.3724,  4.1618],\n",
      "        [ 4.7116,  4.9925, -4.4258,  4.1176],\n",
      "        [ 4.7030,  4.9784, -4.4800,  4.2864],\n",
      "        [ 4.7116,  4.9804, -4.4134,  4.1002],\n",
      "        [ 4.6749,  4.9665, -4.4912,  4.2393]])\n",
      "Critic: tensor(1.00000e-02 *\n",
      "       [[ 4.7572],\n",
      "        [ 4.8767],\n",
      "        [ 4.8752],\n",
      "        [ 4.8696],\n",
      "        [ 4.8610],\n",
      "        [ 4.7746],\n",
      "        [ 4.8414],\n",
      "        [ 4.8706],\n",
      "        [ 4.8107],\n",
      "        [ 4.8393],\n",
      "        [ 4.8479],\n",
      "        [ 4.8147],\n",
      "        [ 4.8553],\n",
      "        [ 4.8110],\n",
      "        [ 4.8488],\n",
      "        [ 4.8638],\n",
      "        [ 4.8612],\n",
      "        [ 4.8194],\n",
      "        [ 4.8508],\n",
      "        [ 4.7676]])\n"
     ]
    }
   ],
   "source": [
    "#al = []\n",
    "#bl = []\n",
    "\n",
    "#for (dc, st) in enumerate(states):\n",
    "#    al.append(a)\n",
    "#    bl.append(b)\n",
    "\n",
    "#import pdb; pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!    \n",
    "    \n",
    "#FA; BMSoT: No need to iterate through states any more!\n",
    "a,b = forward(states)\n",
    "print(f'Actor: {a}')\n",
    "print(f'Critic: {b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if A STACK OF (BMSoT) states is propagated through the imported network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "\n",
    "#from mya2cnet import A2CNetwork\n",
    "import mya2cnet\n",
    "\n",
    "# Thx2: https://emacs.stackexchange.com/a/13483\n",
    "import imp\n",
    "imp.reload(mya2cnet)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tstnet1 = mya2cnet.A2CNetwork(33, 4).to(device) #FA; BMSoT: Looks exactly the same...\n",
    "tstnet2 = mya2cnet.A2CNetwork(33, 4).to(device) #FA; BMSoT: ...like without stacks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FA; BMSoT: OBSOLETE\n",
    "#for (dc, st) in enumerate(states):\n",
    "\n",
    "\n",
    "\n",
    "# pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "    \n",
    "#a1,b1 = tstnet1.forward(torch.tensor(states, dtype=torch.float, device=device))\n",
    "#a2,b2 = tstnet2.forward(torch.tensor(states).to(device))\n",
    "\n",
    "#print(f'Dist. Actor stacks 1-2: {torch.dist(a1, a2)}'.ljust(50) + ' # ' +\\\n",
    "#     f'Dist. Actor 1 stacks - Notebook stacks {torch.dist(a1, a)}'.rjust(50))\n",
    "#print(f'Dist. Critic stacks 1-2: {torch.dist(b1, b2)}'.ljust(50) + ' # ' +\\\n",
    "#     f'Dist. Critic 1 stacks - Notebook stacks {torch.dist(b1, b)}'.rjust(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next(tstnet1.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next(tstnet2.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FA; BMSoT: OBSOLETE\n",
    "#for (dc, st) in enumerate(states):\n",
    "#    print(f'({dc+1}) -> {tstnet1.fullpass(st)}')\n",
    "    \n",
    "#tstnet1.fullpass( torch.tensor(states, device = device, dtype = torch.float) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FA; BMSoT: OBSOLETE\n",
    "#for (dc, st) in enumerate(states):\n",
    "#    print(f'({dc+1})-> {tstnet1.select_action(st)}') #, end=' ')\n",
    "    \n",
    "#tstnet1.select_action(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the agent instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mya2cagent\n",
    "\n",
    "# Thx2: https://emacs.stackexchange.com/a/13483\n",
    "import imp\n",
    "imp.reload(mya2cagent)\n",
    "\n",
    "agent = mya2cagent.a2cagent(len(env_info.agents), env, brain, max_steps = 500, max_n_steps = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --> Actions:\n",
      "mean: 0.01808287083606173 sdev: 0.07060895642852447\n",
      "Training iteration: 1            last optimization: 0+ --> Actions:\n",
      "mean: 0.01807734779361262 sdev: 0.07063281014675264\n",
      "Training iteration: 2            last optimization: 0# --> Actions:\n",
      "mean: 0.018071174317049327 sdev: 0.07065008669578025\n",
      "Training iteration: 3            last optimization: 0+ --> Actions:\n",
      "mean: 0.01806348189600602 sdev: 0.07066046072974423\n",
      "Training iteration: 4            last optimization: 0# --> Actions:\n",
      "mean: 0.01805669696022093 sdev: 0.07066249225850192\n",
      "Training iteration: 5            last optimization: 5+ --> Actions:\n",
      "mean: 0.02401661100221554 sdev: 0.05739678617372673\n",
      "Training iteration: 6            last optimization: 5# --> Actions:\n",
      "mean: 0.024007067233461597 sdev: 0.057397730060849535\n",
      "Training iteration: 7            last optimization: 5+ --> Actions:\n",
      "mean: 0.023994723792416184 sdev: 0.05739900105979525\n",
      "Training iteration: 8            last optimization: 5# --> Actions:\n",
      "mean: 0.02398220817050119 sdev: 0.05740142105062771\n",
      "Training iteration: 9            last optimization: 5+ --> Actions:\n",
      "mean: 0.02396965906958251 sdev: 0.05740518865248126\n",
      "Training iteration: 10           last optimization: 10# --> Actions:\n",
      "mean: 0.030712148810256495 sdev: 0.04459833430687756\n",
      "Training iteration: 11           last optimization: 10+ --> Actions:\n",
      "mean: 0.03068801192298217 sdev: 0.044601528778503347\n",
      "Training iteration: 12           last optimization: 10# --> Actions:\n",
      "mean: 0.030660926202356442 sdev: 0.044606016953891776\n",
      "Training iteration: 13           last optimization: 10+ --> Actions:\n",
      "mean: 0.03063528228636888 sdev: 0.044612000710515014\n",
      "Training iteration: 14           last optimization: 10# --> Actions:\n",
      "mean: 0.030609309218684617 sdev: 0.044619706164636834\n",
      "Training iteration: 15           last optimization: 15+ --> Actions:\n",
      "mean: 0.037722027257310796 sdev: 0.030803417736153946\n",
      "Training iteration: 16           last optimization: 15# --> Actions:\n",
      "mean: 0.03767195851201964 sdev: 0.030843004311819796\n",
      "Training iteration: 17           last optimization: 15+ --> Actions:\n",
      "mean: 0.03762496587755827 sdev: 0.030883637776829818\n",
      "Training iteration: 18           last optimization: 15# --> Actions:\n",
      "mean: 0.03758283141575808 sdev: 0.030925428620736984\n",
      "Training iteration: 19           last optimization: 15+ --> Actions:\n",
      "mean: 0.03754674205193334 sdev: 0.030966643479899938\n",
      "Training iteration: 20           last optimization: 20# --> Actions:\n",
      "mean: 0.043900209261271986 sdev: 0.018873656301877952\n",
      "Training iteration: 21           last optimization: 20+ --> Actions:\n",
      "mean: 0.043863581000820294 sdev: 0.018910003172999984\n",
      "Training iteration: 22           last optimization: 20# --> Actions:\n",
      "mean: 0.043842548000362906 sdev: 0.01894862729908606\n",
      "Training iteration: 23           last optimization: 20+ --> Actions:\n",
      "mean: 0.04383727924271089 sdev: 0.01898373037116663\n",
      "Training iteration: 24           last optimization: 20# --> Actions:\n",
      "mean: 0.04384760266613329 sdev: 0.019010986661793777\n",
      "Training iteration: 25           last optimization: 25+ --> Actions:\n",
      "mean: 0.04903825000414915 sdev: 0.009025764647179196\n",
      "Training iteration: 26           last optimization: 25# --> Actions:\n",
      "mean: 0.04905882873225933 sdev: 0.008996892269051855\n",
      "Training iteration: 27           last optimization: 25+ --> Actions:\n",
      "mean: 0.04907815379230541 sdev: 0.008972073634853263\n",
      "Training iteration: 28           last optimization: 25# --> Actions:\n",
      "mean: 0.04909331296212925 sdev: 0.008953721590516604\n",
      "Training iteration: 29           last optimization: 25+ --> Actions:\n",
      "mean: 0.04910499647423976 sdev: 0.008940400473086231\n",
      "Training iteration: 30           last optimization: 30# --> Actions:\n",
      "mean: 0.05168946463543107 sdev: 0.016166409541743445\n",
      "Training iteration: 31           last optimization: 30+ --> Actions:\n",
      "mean: 0.05169406313652468 sdev: 0.01615992948434098\n",
      "Training iteration: 32           last optimization: 30# --> Actions:\n",
      "mean: 0.051695199746388976 sdev: 0.016163174250678633\n",
      "Training iteration: 33           last optimization: 30+ --> Actions:\n",
      "mean: 0.05169250072681987 sdev: 0.0161733506818784\n",
      "Training iteration: 34           last optimization: 30# --> Actions:\n",
      "mean: 0.05168555029335557 sdev: 0.016188448071131616\n",
      "Training iteration: 35           last optimization: 35+ --> Actions:\n",
      "mean: 0.051818030730252776 sdev: 0.016984643298649404\n",
      "Training iteration: 36           last optimization: 35# --> Actions:\n",
      "mean: 0.051815442073392795 sdev: 0.017009738891102626\n",
      "Training iteration: 37           last optimization: 35+ --> Actions:\n",
      "mean: 0.051813421752148404 sdev: 0.017039184922454147\n",
      "Training iteration: 38           last optimization: 35# --> Actions:\n",
      "mean: 0.05181258478223375 sdev: 0.017072877262601628\n",
      "Training iteration: 39           last optimization: 35+ --> Actions:\n",
      "mean: 0.05181352840712465 sdev: 0.017109462116055702\n",
      "Training iteration: 40           last optimization: 40# --> Actions:\n",
      "mean: 0.050460746886386076 sdev: 0.01240688265461803\n",
      "Training iteration: 41           last optimization: 40+ --> Actions:\n",
      "mean: 0.05047449605573878 sdev: 0.012438121763636125\n",
      "Training iteration: 42           last optimization: 40# --> Actions:\n",
      "mean: 0.050488117832384605 sdev: 0.012472391537310643\n",
      "Training iteration: 43           last optimization: 40+ --> Actions:\n",
      "mean: 0.050496252696001276 sdev: 0.012503362635650979\n",
      "Training iteration: 44           last optimization: 40# --> Actions:\n",
      "mean: 0.05049336583374768 sdev: 0.012525901079827652\n",
      "Training iteration: 45           last optimization: 45+ --> Actions:\n",
      "mean: 0.048626156320975 sdev: 0.006497080518561065\n",
      "Training iteration: 46           last optimization: 45# --> Actions:\n",
      "mean: 0.04860369662239153 sdev: 0.006507098877762856\n",
      "Training iteration: 47           last optimization: 45+ --> Actions:\n",
      "mean: 0.04857163834212884 sdev: 0.006511214823791732\n",
      "Training iteration: 48           last optimization: 45# --> Actions:\n",
      "mean: 0.04853358645041791 sdev: 0.0065097781314542675\n",
      "Training iteration: 49           last optimization: 45+ --> Actions:\n",
      "mean: 0.04849058674270604 sdev: 0.006502860553147603\n",
      "Training iteration: 50           last optimization: 50# --> Actions:\n",
      "mean: 0.046437461298474016 sdev: 0.0047770831096643485\n",
      "Training iteration: 51           last optimization: 50+ --> Actions:\n",
      "mean: 0.04640668722502168 sdev: 0.004769405668355896\n",
      "Training iteration: 52           last optimization: 50# --> Actions:\n",
      "mean: 0.04637745252550022 sdev: 0.0047643292936362614\n",
      "Training iteration: 53           last optimization: 50+ --> Actions:\n",
      "mean: 0.046350845717940736 sdev: 0.004763279545771092\n",
      "Training iteration: 54           last optimization: 50# --> Actions:\n",
      "mean: 0.04632721975258196 sdev: 0.004766408712101935\n",
      "Training iteration: 55           last optimization: 55+ --> Actions:\n",
      "mean: 0.044696671888967636 sdev: 0.0065681053693308145\n",
      "Training iteration: 56           last optimization: 55# --> Actions:\n",
      "mean: 0.04469018074594653 sdev: 0.006576549878793914\n",
      "Training iteration: 57           last optimization: 55+ --> Actions:\n",
      "mean: 0.044688104535645944 sdev: 0.0065888883421016935\n",
      "Training iteration: 58           last optimization: 55# --> Actions:\n",
      "mean: 0.04469022230384777 sdev: 0.00660311766109969\n",
      "Training iteration: 59           last optimization: 55+ --> Actions:\n",
      "mean: 0.04469693575707118 sdev: 0.00661757186144107\n",
      "Training iteration: 60           last optimization: 60# --> Actions:\n",
      "mean: 0.04360141632987128 sdev: 0.006806621295143546\n",
      "Training iteration: 61           last optimization: 60+ --> Actions:\n",
      "mean: 0.043614810589563124 sdev: 0.0068219834643771585\n",
      "Training iteration: 62           last optimization: 60# --> Actions:\n",
      "mean: 0.04363105256649792 sdev: 0.006834891238172553\n",
      "Training iteration: 63           last optimization: 60+ --> Actions:\n",
      "mean: 0.043649701456838705 sdev: 0.006844295443642939\n",
      "Training iteration: 64           last optimization: 60# --> Actions:\n",
      "mean: 0.04367087247607875 sdev: 0.0068494278602058275\n",
      "Training iteration: 65           last optimization: 65+ --> Actions:\n",
      "mean: 0.04302820998995266 sdev: 0.005524352556734322\n",
      "Training iteration: 66           last optimization: 65# --> Actions:\n",
      "mean: 0.04304815169654131 sdev: 0.0055216551078821965\n",
      "Training iteration: 67           last optimization: 65+ --> Actions:\n",
      "mean: 0.04307033501531032 sdev: 0.0055173490098474765\n",
      "Training iteration: 68           last optimization: 65# --> Actions:\n",
      "mean: 0.04309452652057363 sdev: 0.0055116564670798585\n",
      "Training iteration: 69           last optimization: 65+ --> Actions:\n",
      "mean: 0.04312264298722644 sdev: 0.005504197375983531\n",
      "Training iteration: 70           last optimization: 70# --> Actions:\n",
      "mean: 0.04288004139253675 sdev: 0.0038245261784774546\n",
      "Training iteration: 71           last optimization: 70+ --> Actions:\n",
      "mean: 0.04291234734505411 sdev: 0.0038068144015414905\n",
      "Training iteration: 72           last optimization: 70# --> Actions:\n",
      "mean: 0.042948556792540823 sdev: 0.0037873377456202756\n",
      "Training iteration: 73           last optimization: 70+ --> Actions:\n",
      "mean: 0.042985941038665966 sdev: 0.0037664526987431566\n",
      "Training iteration: 74           last optimization: 70# --> Actions:\n",
      "mean: 0.04302257687359297 sdev: 0.003745146188415284\n",
      "Training iteration: 75           last optimization: 75+ --> Actions:\n",
      "mean: 0.04320929770797602 sdev: 0.0039771697781698576\n",
      "Training iteration: 76           last optimization: 75# --> Actions:\n",
      "mean: 0.04323545359295 sdev: 0.0040062467154845524\n",
      "Training iteration: 77           last optimization: 75+ --> Actions:\n",
      "mean: 0.04325474212988664 sdev: 0.004039925843127768\n",
      "Training iteration: 78           last optimization: 75# --> Actions:\n",
      "mean: 0.043266619129563574 sdev: 0.0040755159831833395\n",
      "Training iteration: 79           last optimization: 75+ --> Actions:\n",
      "mean: 0.04327225567709893 sdev: 0.004111120832954212\n",
      "Training iteration: 80           last optimization: 80# --> Actions:\n",
      "mean: 0.04359003313197307 sdev: 0.004626926631381507\n",
      "Training iteration: 81           last optimization: 80+ --> Actions:\n",
      "mean: 0.0435871260356756 sdev: 0.004665533024048483\n",
      "Training iteration: 82           last optimization: 80# --> Actions:\n",
      "mean: 0.04357939149267144 sdev: 0.004693581899114646\n",
      "Training iteration: 83           last optimization: 80+ --> Actions:\n",
      "mean: 0.04356766885968074 sdev: 0.004710815012306701\n",
      "Training iteration: 84           last optimization: 80# --> Actions:\n",
      "mean: 0.04355458565185887 sdev: 0.004716063802463487\n",
      "Training iteration: 85           last optimization: 85+ --> Actions:\n",
      "mean: 0.043641883300186354 sdev: 0.0037045337756624335\n",
      "Training iteration: 86           last optimization: 85# --> Actions:\n",
      "mean: 0.043623551504588645 sdev: 0.003671530242724015\n",
      "Training iteration: 87           last optimization: 85+ --> Actions:\n",
      "mean: 0.04360572416799199 sdev: 0.003624678335192595\n",
      "Training iteration: 88           last optimization: 85# --> Actions:\n",
      "mean: 0.04358904503912609 sdev: 0.003566943355933992\n",
      "Training iteration: 89           last optimization: 85+ --> Actions:\n",
      "mean: 0.043573956437526526 sdev: 0.0035030895766235163\n",
      "Training iteration: 90           last optimization: 90# --> Actions:\n",
      "mean: 0.043173388630229625 sdev: 0.001838777787080241\n",
      "Training iteration: 91           last optimization: 90+ --> Actions:\n",
      "mean: 0.04316353068065515 sdev: 0.0018045976564100073\n",
      "Training iteration: 92           last optimization: 90# --> Actions:\n",
      "mean: 0.04315622309330513 sdev: 0.0017793933769699522\n",
      "Training iteration: 93           last optimization: 90+ --> Actions:\n",
      "mean: 0.043150538776997115 sdev: 0.0017616770839518185\n",
      "Training iteration: 94           last optimization: 90# --> Actions:\n",
      "mean: 0.04314543339153152 sdev: 0.001749391458025033\n",
      "Training iteration: 95           last optimization: 95+ --> Actions:\n",
      "mean: 0.04202590404981101 sdev: 0.002662918739618536\n",
      "Training iteration: 96           last optimization: 95# --> Actions:\n",
      "mean: 0.04202537273253134 sdev: 0.002679167497193382\n",
      "Training iteration: 97           last optimization: 95+ --> Actions:\n",
      "mean: 0.042024008696778935 sdev: 0.0026947777641475896\n",
      "Training iteration: 98           last optimization: 95# --> Actions:\n",
      "mean: 0.042021801918564604 sdev: 0.002710563845383962\n",
      "Training iteration: 99           last optimization: 95+ --> Actions:\n",
      "mean: 0.04201829260799564 sdev: 0.00272718745439246\n",
      "Training iteration: 100          last optimization: 100# --> Actions:\n",
      "mean: 0.041278194707271856 sdev: 0.0036468487292450735\n",
      "Training iteration: 101          last optimization: 100+ --> Actions:\n",
      "mean: 0.041272879845009804 sdev: 0.003660836877048264\n",
      "Training iteration: 102          last optimization: 100# --> Actions:\n",
      "mean: 0.041264938836857466 sdev: 0.003676747021833239\n",
      "Training iteration: 103          last optimization: 100+ --> Actions:\n",
      "mean: 0.041254276814553334 sdev: 0.003693553534849389\n",
      "Training iteration: 104          last optimization: 100# --> Actions:\n",
      "mean: 0.04124094264012466 sdev: 0.0037087592883624327\n",
      "Training iteration: 105          last optimization: 105+ --> Actions:\n",
      "mean: 0.041062828390165215 sdev: 0.0032590125474305223\n",
      "Training iteration: 106          last optimization: 105# --> Actions:\n",
      "mean: 0.04103956772463844 sdev: 0.003272985217319484\n",
      "Training iteration: 107          last optimization: 105+ --> Actions:\n",
      "mean: 0.04101447356932232 sdev: 0.0032833408167359146\n",
      "Training iteration: 108          last optimization: 105# --> Actions:\n",
      "mean: 0.040988201392880334 sdev: 0.0032920968232762675\n",
      "Training iteration: 109          last optimization: 105+ --> Actions:\n",
      "mean: 0.040960828377538935 sdev: 0.003300363662703003\n",
      "Training iteration: 110          last optimization: 110# --> Actions:\n",
      "mean: 0.04133405217551184 sdev: 0.0015281274011784208\n",
      "Training iteration: 111          last optimization: 110+ --> Actions:\n",
      "mean: 0.0413020799664958 sdev: 0.0015440232493710115\n",
      "Training iteration: 112          last optimization: 110# --> Actions:\n",
      "mean: 0.041270260332541865 sdev: 0.001566934492510356\n",
      "Training iteration: 113          last optimization: 110+ --> Actions:\n",
      "mean: 0.041237453633905866 sdev: 0.0015972932964838761\n",
      "Training iteration: 114          last optimization: 110# --> Actions:\n",
      "mean: 0.041204907667077295 sdev: 0.001636080302477351\n",
      "Training iteration: 115          last optimization: 115+ --> Actions:\n",
      "mean: 0.04211482074209617 sdev: 0.0015957875698426646\n",
      "Training iteration: 116          last optimization: 115# --> Actions:\n",
      "mean: 0.04208215356739715 sdev: 0.0015226536283142434\n",
      "Training iteration: 117          last optimization: 115+ --> Actions:\n",
      "mean: 0.0420557907781904 sdev: 0.0014516905636960545\n",
      "Training iteration: 118          last optimization: 115# --> Actions:\n",
      "mean: 0.042037457677753846 sdev: 0.0013887709403365943\n",
      "Training iteration: 119          last optimization: 115+ --> Actions:\n",
      "mean: 0.04202821812324685 sdev: 0.0013399037612809796\n",
      "Training iteration: 120          last optimization: 120# --> Actions:\n",
      "mean: 0.04205089861691558 sdev: 0.0023043071640931694\n",
      "Training iteration: 121          last optimization: 120+ --> Actions:\n",
      "mean: 0.04205660579546441 sdev: 0.002284725310646714\n",
      "Training iteration: 122          last optimization: 120# --> Actions:\n",
      "mean: 0.042067355152008136 sdev: 0.0022817140372684\n",
      "Training iteration: 123          last optimization: 120+ --> Actions:\n",
      "mean: 0.04208205381868505 sdev: 0.0022932714002159298\n",
      "Training iteration: 124          last optimization: 120# --> Actions:\n",
      "mean: 0.04209924036454987 sdev: 0.002317733326493205\n",
      "Training iteration: 125          last optimization: 125+ --> Actions:\n",
      "mean: 0.041622171367195905 sdev: 0.0018961819830853198\n",
      "Training iteration: 126          last optimization: 125# --> Actions:\n",
      "mean: 0.041646250039265774 sdev: 0.001922297516809051\n",
      "Training iteration: 127          last optimization: 125+ --> Actions:\n",
      "mean: 0.04167023236900556 sdev: 0.001954815943184566\n",
      "Training iteration: 128          last optimization: 125# --> Actions:\n",
      "mean: 0.04169340489149699 sdev: 0.001992174726460955\n",
      "Training iteration: 129          last optimization: 125+ --> Actions:\n",
      "mean: 0.041716014595806386 sdev: 0.002032373988899512\n",
      "Training iteration: 130          last optimization: 130# --> Actions:\n",
      "mean: 0.04104480118446923 sdev: 0.0009664964277261256\n",
      "Training iteration: 131          last optimization: 130+ --> Actions:\n",
      "mean: 0.041070519804076444 sdev: 0.0009386742697931321\n",
      "Training iteration: 132          last optimization: 130# --> Actions:\n",
      "mean: 0.04109536416549092 sdev: 0.0009190367758524312\n",
      "Training iteration: 133          last optimization: 130+ --> Actions:\n",
      "mean: 0.041118530829472866 sdev: 0.0009066426115665136\n",
      "Training iteration: 134          last optimization: 130# --> Actions:\n",
      "mean: 0.04113965547302627 sdev: 0.0009003700204766903\n",
      "Training iteration: 135          last optimization: 135+ --> Actions:\n",
      "mean: 0.04084715731609734 sdev: 0.001440871749539287\n",
      "Training iteration: 136          last optimization: 135# --> Actions:\n",
      "mean: 0.0408600613262194 sdev: 0.0014254281192797472\n",
      "Training iteration: 137          last optimization: 135+ --> Actions:\n",
      "mean: 0.040867017758537766 sdev: 0.0014115720666435332\n",
      "Training iteration: 138          last optimization: 135# --> Actions:\n",
      "mean: 0.04086825680308018 sdev: 0.001396428598719481\n",
      "Training iteration: 139          last optimization: 135+ --> Actions:\n",
      "mean: 0.04086472272841319 sdev: 0.0013790259718586538\n",
      "Training iteration: 140          last optimization: 140# --> Actions:\n",
      "mean: 0.040781199681986895 sdev: 0.0017396651585640582\n",
      "Training iteration: 141          last optimization: 140+ --> Actions:\n",
      "mean: 0.040768351652142175 sdev: 0.0017270840193404525\n",
      "Training iteration: 142          last optimization: 140# --> Actions:\n",
      "mean: 0.040753078192203446 sdev: 0.0017154200119930223\n",
      "Training iteration: 143          last optimization: 140+ --> Actions:\n",
      "mean: 0.04073610989510349 sdev: 0.00170683682047664\n",
      "Training iteration: 144          last optimization: 140# --> Actions:\n",
      "mean: 0.04071721155792769 sdev: 0.0017038420166717672\n",
      "Training iteration: 145          last optimization: 145+ --> Actions:\n",
      "mean: 0.04087641241855632 sdev: 0.0012667991480534034\n",
      "Training iteration: 146          last optimization: 145# --> Actions:\n",
      "mean: 0.04085050264808864 sdev: 0.0012768676493443963\n",
      "Training iteration: 147          last optimization: 145+ --> Actions:\n",
      "mean: 0.04082679428293107 sdev: 0.0012933784024839305\n",
      "Training iteration: 148          last optimization: 145# --> Actions:\n",
      "mean: 0.040810297334454175 sdev: 0.0013136008881766271\n",
      "Training iteration: 149          last optimization: 145+ --> Actions:\n",
      "mean: 0.04080424401715859 sdev: 0.0013315151612762997\n",
      "Training iteration: 150          last optimization: 150# --> Actions:\n",
      "mean: 0.041197440428288844 sdev: 0.0011051060403839894\n",
      "Training iteration: 151          last optimization: 150+ --> Actions:\n",
      "mean: 0.041215065810941094 sdev: 0.0011038772005728121\n",
      "Training iteration: 152          last optimization: 150# --> Actions:\n",
      "mean: 0.04124397468504594 sdev: 0.0011164577007512803\n",
      "Training iteration: 153          last optimization: 150+ --> Actions:\n",
      "mean: 0.04128135694613268 sdev: 0.0011431871716751872\n",
      "Training iteration: 154          last optimization: 150# --> Actions:\n",
      "mean: 0.04132386231612491 sdev: 0.0011839398365892562\n",
      "Training iteration: 155          last optimization: 155+ --> Actions:\n",
      "mean: 0.04132613790469133 sdev: 0.0013215487610605387\n",
      "Training iteration: 156          last optimization: 155# --> Actions:\n",
      "mean: 0.04137576663814187 sdev: 0.0013941664222277164\n",
      "Training iteration: 157          last optimization: 155+ --> Actions:\n",
      "mean: 0.0414259570813023 sdev: 0.0014751289078872116\n",
      "Training iteration: 158          last optimization: 155# --> Actions:\n",
      "mean: 0.04147622546596945 sdev: 0.001561628124937208\n",
      "Training iteration: 159          last optimization: 155+ --> Actions:\n",
      "mean: 0.04152474652480946 sdev: 0.0016504535041090612\n",
      "Training iteration: 160          last optimization: 160# --> Actions:\n",
      "mean: 0.041050556015305835 sdev: 0.0009657818640399637\n",
      "Training iteration: 161          last optimization: 160+ --> Actions:\n",
      "mean: 0.04109843828952173 sdev: 0.0010083292017811197\n",
      "Training iteration: 162          last optimization: 160# --> Actions:\n",
      "mean: 0.04114215064492602 sdev: 0.0010520377728953194\n",
      "Training iteration: 163          last optimization: 160+ --> Actions:\n",
      "mean: 0.04117926894135971 sdev: 0.0010899578205129945\n",
      "Training iteration: 164          last optimization: 160# --> Actions:\n",
      "mean: 0.04120627428951205 sdev: 0.0011147208288320074\n",
      "Training iteration: 165          last optimization: 165+ --> Actions:\n",
      "mean: 0.04052233315618459 sdev: 0.0013108445048467226\n",
      "Training iteration: 166          last optimization: 165# --> Actions:\n",
      "mean: 0.040521399395223714 sdev: 0.0013266823772217684\n",
      "Training iteration: 167          last optimization: 165+ --> Actions:\n",
      "mean: 0.040504180626103406 sdev: 0.0013693188919136083\n",
      "Training iteration: 168          last optimization: 165# --> Actions:\n",
      "mean: 0.040472834552510537 sdev: 0.0014325489508202707\n",
      "Training iteration: 169          last optimization: 165+ --> Actions:\n",
      "mean: 0.04043235152970779 sdev: 0.0015066572414759757\n",
      "Training iteration: 170          last optimization: 170# --> Actions:\n",
      "mean: 0.040260757055754194 sdev: 0.0018655289392678083\n",
      "Training iteration: 171          last optimization: 170+ --> Actions:\n",
      "mean: 0.04021396357137775 sdev: 0.0019253703251700062\n",
      "Training iteration: 172          last optimization: 170# --> Actions:\n",
      "mean: 0.0401672647771814 sdev: 0.001984932304894917\n",
      "Training iteration: 173          last optimization: 170+ --> Actions:\n",
      "mean: 0.04012024779624966 sdev: 0.0020463063001968196\n",
      "Training iteration: 174          last optimization: 170# --> Actions:\n",
      "mean: 0.04007132189197633 sdev: 0.0021121513242908776\n",
      "Training iteration: 175          last optimization: 175+ --> Actions:\n",
      "mean: 0.04032538106823369 sdev: 0.0016530511476101825\n",
      "Training iteration: 176          last optimization: 175# --> Actions:\n",
      "mean: 0.040267266377734943 sdev: 0.0016999788570104357\n",
      "Training iteration: 177          last optimization: 175+ --> Actions:\n",
      "mean: 0.04020751971763047 sdev: 0.001760745326605772\n",
      "Training iteration: 178          last optimization: 175# --> Actions:\n",
      "mean: 0.0401479181834848 sdev: 0.0018346938467915014\n",
      "Training iteration: 179          last optimization: 175+ --> Actions:\n",
      "mean: 0.04009365323588816 sdev: 0.0019172693926781804\n",
      "Training iteration: 180          last optimization: 180# --> Actions:\n",
      "mean: 0.04059420130633688 sdev: 0.0010273085005256405\n",
      "Training iteration: 181          last optimization: 180+ --> Actions:\n",
      "mean: 0.04055871923864865 sdev: 0.0010220474002735776\n",
      "Training iteration: 182          last optimization: 180# --> Actions:\n",
      "mean: 0.040542466354355385 sdev: 0.0010314102458715232\n",
      "Training iteration: 183          last optimization: 180+ --> Actions:\n",
      "mean: 0.04054576382939623 sdev: 0.0010466017128436902\n",
      "Training iteration: 184          last optimization: 180# --> Actions:\n",
      "mean: 0.04056487379837374 sdev: 0.0010626764178793846\n",
      "Training iteration: 185          last optimization: 185+ --> Actions:\n",
      "mean: 0.04100941400914398 sdev: 0.0011762904191340905\n",
      "Training iteration: 186          last optimization: 185# --> Actions:\n",
      "mean: 0.041044729037041046 sdev: 0.001230136911271129\n",
      "Training iteration: 187          last optimization: 185+ --> Actions:\n",
      "mean: 0.04108297945684531 sdev: 0.001298777666298323\n",
      "Training iteration: 188          last optimization: 185# --> Actions:\n",
      "mean: 0.041122036927565 sdev: 0.00137792452769263\n",
      "Training iteration: 189          last optimization: 185+ --> Actions:\n",
      "mean: 0.0411612163069192 sdev: 0.0014632668940962395\n",
      "Training iteration: 190          last optimization: 190# --> Actions:\n",
      "mean: 0.0410454540221256 sdev: 0.002076378188810466\n",
      "Training iteration: 191          last optimization: 190+ --> Actions:\n",
      "mean: 0.04108462998849086 sdev: 0.0021160722051318196\n",
      "Training iteration: 192          last optimization: 190# --> Actions:\n",
      "mean: 0.04112045441349903 sdev: 0.002157256947756174\n",
      "Training iteration: 193          last optimization: 190+ --> Actions:\n",
      "mean: 0.0411518610162115 sdev: 0.002196539786156148\n",
      "Training iteration: 194          last optimization: 190# --> Actions:\n",
      "mean: 0.04117686086445589 sdev: 0.0022300579033120746\n",
      "Training iteration: 195          last optimization: 195+ --> Actions:\n",
      "mean: 0.04080883377805561 sdev: 0.0020791402467785747\n",
      "Training iteration: 196          last optimization: 195# --> Actions:\n",
      "mean: 0.04081635563623909 sdev: 0.0020803063639968098\n",
      "Training iteration: 197          last optimization: 195+ --> Actions:\n",
      "mean: 0.040809397164468554 sdev: 0.0020785663054738177\n",
      "Training iteration: 198          last optimization: 195# --> Actions:\n",
      "mean: 0.04078736949122213 sdev: 0.00207496221300258\n",
      "Training iteration: 199          last optimization: 195+ --> Actions:\n",
      "mean: 0.040752315134844355 sdev: 0.0020720304366474993\n",
      "Training iteration: 200          last optimization: 200# --> Actions:\n",
      "mean: 0.04036283439909391 sdev: 0.0012074418616753947\n",
      "Training iteration: 201          last optimization: 200+ --> Actions:\n",
      "mean: 0.040318654515571664 sdev: 0.0012635685080756452\n",
      "Training iteration: 202          last optimization: 200# --> Actions:\n",
      "mean: 0.040273594157621516 sdev: 0.0013247864875309276\n",
      "Training iteration: 203          last optimization: 200+ --> Actions:\n",
      "mean: 0.04022960822013822 sdev: 0.0013867563234324848\n",
      "Training iteration: 204          last optimization: 200# --> Actions:\n",
      "mean: 0.040186680393739425 sdev: 0.0014478207729043578\n",
      "Training iteration: 205          last optimization: 205+ --> Actions:\n",
      "mean: 0.04021735118339705 sdev: 0.0010510852878974383\n",
      "Training iteration: 206          last optimization: 205# --> Actions:\n",
      "mean: 0.0401769212736404 sdev: 0.0010708811742969643\n",
      "Training iteration: 207          last optimization: 205+ --> Actions:\n",
      "mean: 0.04013833877567255 sdev: 0.0010992080853890701\n",
      "Training iteration: 208          last optimization: 205# --> Actions:\n",
      "mean: 0.040102390523010754 sdev: 0.001133392641240351\n",
      "Training iteration: 209          last optimization: 205+ --> Actions:\n",
      "mean: 0.040073352947635026 sdev: 0.0011680473536461147\n",
      "Training iteration: 210          last optimization: 210# --> Actions:\n",
      "mean: 0.04034246668531248 sdev: 0.0018891250511913697\n",
      "Training iteration: 211          last optimization: 210+ --> Actions:\n",
      "mean: 0.040340079856443924 sdev: 0.00188980976525779\n",
      "Training iteration: 212          last optimization: 210# --> Actions:\n",
      "mean: 0.04035465045622298 sdev: 0.0019007574577638606\n",
      "Training iteration: 213          last optimization: 210+ --> Actions:\n",
      "mean: 0.040384456018363414 sdev: 0.0019213440226824989\n",
      "Training iteration: 214          last optimization: 210# --> Actions:\n",
      "mean: 0.040424910298695174 sdev: 0.0019528369194250278\n",
      "Training iteration: 215          last optimization: 215+ --> Actions:\n",
      "mean: 0.04052553585619202 sdev: 0.0017596724255575912\n",
      "Training iteration: 216          last optimization: 215# --> Actions:\n",
      "mean: 0.0405798887251725 sdev: 0.001836256435786672\n",
      "Training iteration: 217          last optimization: 215+ --> Actions:\n",
      "mean: 0.0406371199823947 sdev: 0.0019246487766717267\n",
      "Training iteration: 218          last optimization: 215# --> Actions:\n",
      "mean: 0.04069523571881479 sdev: 0.0020232162620075164\n",
      "Training iteration: 219          last optimization: 215+ --> Actions:\n",
      "mean: 0.040753732835647 sdev: 0.002129401906482573\n",
      "Training iteration: 220          last optimization: 220# --> Actions:\n",
      "mean: 0.04045316844894041 sdev: 0.0006710631352724689\n",
      "Training iteration: 221          last optimization: 220+ --> Actions:\n",
      "mean: 0.04051121143353485 sdev: 0.0007782719037251352\n",
      "Training iteration: 222          last optimization: 220# --> Actions:\n",
      "mean: 0.04056766224522402 sdev: 0.000895290735004677\n",
      "Training iteration: 223          last optimization: 220+ --> Actions:\n",
      "mean: 0.04062251399333543 sdev: 0.0010156931114858661\n",
      "Training iteration: 224          last optimization: 220# --> Actions:\n",
      "mean: 0.04067531624908196 sdev: 0.0011339854841181732\n",
      "Training iteration: 225          last optimization: 225+ --> Actions:\n",
      "mean: 0.03991341869955336 sdev: 0.0020767530318163575\n",
      "Training iteration: 226          last optimization: 225# --> Actions:\n",
      "mean: 0.03995821183960728 sdev: 0.002012920621900047\n",
      "Training iteration: 227          last optimization: 225+ --> Actions:\n",
      "mean: 0.03999473512539193 sdev: 0.001967680651052571\n",
      "Training iteration: 228          last optimization: 225# --> Actions:\n",
      "mean: 0.040018709646922404 sdev: 0.0019453211069657191\n",
      "Training iteration: 229          last optimization: 225+ --> Actions:\n",
      "mean: 0.040026793633450256 sdev: 0.0019493726344892233\n",
      "Training iteration: 230          last optimization: 230# --> Actions:\n",
      "mean: 0.03967834658228416 sdev: 0.002845197231509772\n",
      "Training iteration: 231          last optimization: 230+ --> Actions:\n",
      "mean: 0.039656601165495 sdev: 0.0029044326145008883\n",
      "Training iteration: 232          last optimization: 230# --> Actions:\n",
      "mean: 0.0396253600418201 sdev: 0.0029786489349241537\n",
      "Training iteration: 233          last optimization: 230+ --> Actions:\n",
      "mean: 0.03958869715257234 sdev: 0.0030606434387993216\n",
      "Training iteration: 234          last optimization: 230# --> Actions:\n",
      "mean: 0.0395512006859707 sdev: 0.0031422941513942855\n",
      "Training iteration: 235          last optimization: 235+ --> Actions:\n",
      "mean: 0.03963874452628111 sdev: 0.0024493068687879015\n",
      "Training iteration: 236          last optimization: 235# --> Actions:\n",
      "mean: 0.03959867012367933 sdev: 0.0025307970313659988\n",
      "Training iteration: 237          last optimization: 235+ --> Actions:\n",
      "mean: 0.03955657691384146 sdev: 0.002615497163351388\n",
      "Training iteration: 238          last optimization: 235# --> Actions:\n",
      "mean: 0.03951209403977389 sdev: 0.002705773441033231\n",
      "Training iteration: 239          last optimization: 235+ --> Actions:\n",
      "mean: 0.03946532928230813 sdev: 0.0028001920047869026\n",
      "Training iteration: 240          last optimization: 240# --> Actions:\n",
      "mean: 0.03995682358787038 sdev: 0.0008500890506170781\n",
      "Training iteration: 241          last optimization: 240+ --> Actions:\n",
      "mean: 0.039906293824934165 sdev: 0.0009505999133066646\n",
      "Training iteration: 242          last optimization: 240# --> Actions:\n",
      "mean: 0.03986259948089222 sdev: 0.0010475699583299383\n",
      "Training iteration: 243          last optimization: 240+ --> Actions:\n",
      "mean: 0.03983096555712302 sdev: 0.0011264043034558359\n",
      "Training iteration: 244          last optimization: 240# --> Actions:\n",
      "mean: 0.03981504542147151 sdev: 0.0011735922099614297\n",
      "Training iteration: 245          last optimization: 245+ --> Actions:\n",
      "mean: 0.04077252419650381 sdev: 0.0024619213919163667\n",
      "Training iteration: 246          last optimization: 245# --> Actions:\n",
      "mean: 0.04078400541389153 sdev: 0.0024849016498467136\n",
      "Training iteration: 247          last optimization: 245+ --> Actions:\n",
      "mean: 0.04080752971146041 sdev: 0.0025383989589893067\n",
      "Training iteration: 248          last optimization: 245# --> Actions:\n",
      "mean: 0.04084035199513835 sdev: 0.0026141490765827055\n",
      "Training iteration: 249          last optimization: 245+ --> Actions:\n",
      "mean: 0.04087841600918245 sdev: 0.002706187713401685\n",
      "Training iteration: 250          last optimization: 250# --> Actions:\n",
      "mean: 0.041261725802647295 sdev: 0.004175558089526212\n",
      "Training iteration: 251          last optimization: 250+ --> Actions:\n",
      "mean: 0.041305404236306645 sdev: 0.004288551615589098\n",
      "Training iteration: 252          last optimization: 250# --> Actions:\n",
      "mean: 0.04134841146960635 sdev: 0.004401964761344606\n",
      "Training iteration: 253          last optimization: 250+ --> Actions:\n",
      "mean: 0.041389400171197424 sdev: 0.004511914318534676\n",
      "Training iteration: 254          last optimization: 250# --> Actions:\n",
      "mean: 0.04142648633053192 sdev: 0.004613654834756956\n",
      "Training iteration: 255          last optimization: 255+ --> Actions:\n",
      "mean: 0.04119546711105908 sdev: 0.0041410937078367556\n",
      "Training iteration: 256          last optimization: 255# --> Actions:\n",
      "mean: 0.04122068500420841 sdev: 0.004211487136449046\n",
      "Training iteration: 257          last optimization: 255+ --> Actions:\n",
      "mean: 0.0412346805567928 sdev: 0.0042539983344336745\n",
      "Training iteration: 258          last optimization: 255# --> Actions:\n",
      "mean: 0.041234249213063685 sdev: 0.004259157346005398\n",
      "Training iteration: 259          last optimization: 255+ --> Actions:\n",
      "mean: 0.04121751284350666 sdev: 0.004221661444923335\n",
      "Training iteration: 260          last optimization: 260# --> Actions:\n",
      "mean: 0.04042762434840233 sdev: 0.002033441295086014\n",
      "Training iteration: 261          last optimization: 260+ --> Actions:\n",
      "mean: 0.040388014800699784 sdev: 0.0019538953567599755\n",
      "Training iteration: 262          last optimization: 260# --> Actions:\n",
      "mean: 0.040339999845442495 sdev: 0.00186132127389505\n",
      "Training iteration: 263          last optimization: 260+ --> Actions:\n",
      "mean: 0.04028883055491082 sdev: 0.0017656161106670385\n",
      "Training iteration: 264          last optimization: 260# --> Actions:\n",
      "mean: 0.0402368388327175 sdev: 0.001673329863043953\n",
      "Training iteration: 265          last optimization: 265+ --> Actions:\n",
      "mean: 0.039168778913437896 sdev: 0.0018806068475548336\n",
      "Training iteration: 266          last optimization: 265# --> Actions:\n",
      "mean: 0.039122768570354065 sdev: 0.0019875273630734318\n",
      "Training iteration: 267          last optimization: 265+ --> Actions:\n",
      "mean: 0.03907658653916689 sdev: 0.0020977373539571085\n",
      "Training iteration: 268          last optimization: 265# --> Actions:\n",
      "mean: 0.039028433061515225 sdev: 0.002215578477086978\n",
      "Training iteration: 269          last optimization: 265+ --> Actions:\n",
      "mean: 0.03897770289712034 sdev: 0.0023413428064770095\n",
      "Training iteration: 270          last optimization: 270# --> Actions:\n",
      "mean: 0.038652136401505485 sdev: 0.003466580783420265\n",
      "Training iteration: 271          last optimization: 270+ --> Actions:\n",
      "mean: 0.03860507286255864 sdev: 0.003583556514984825\n",
      "Training iteration: 272          last optimization: 270# --> Actions:\n",
      "mean: 0.03856338977416853 sdev: 0.0036918428905164244\n",
      "Training iteration: 273          last optimization: 270+ --> Actions:\n",
      "mean: 0.03853045028744923 sdev: 0.0037763037128893395\n",
      "Training iteration: 274          last optimization: 270# --> Actions:\n",
      "mean: 0.03851145327284739 sdev: 0.003824831555926751\n",
      "Training iteration: 275          last optimization: 275+ --> Actions:\n",
      "mean: 0.03875743843685171 sdev: 0.0034304889841053144\n",
      "Training iteration: 276          last optimization: 275# --> Actions:\n",
      "mean: 0.038767043915417694 sdev: 0.0034072335642005448\n",
      "Training iteration: 277          last optimization: 275+ --> Actions:\n",
      "mean: 0.038787436340372954 sdev: 0.0033594062547375376\n",
      "Training iteration: 278          last optimization: 275# --> Actions:\n",
      "mean: 0.038815198977271856 sdev: 0.0032919393575025937\n",
      "Training iteration: 279          last optimization: 275+ --> Actions:\n",
      "mean: 0.03884838646531179 sdev: 0.003211037561926896\n",
      "Training iteration: 280          last optimization: 280# --> Actions:\n",
      "mean: 0.03946544239279082 sdev: 0.0018985586650027816\n",
      "Training iteration: 281          last optimization: 280+ --> Actions:\n",
      "mean: 0.03950388815199717 sdev: 0.0018345684959841823\n",
      "Training iteration: 282          last optimization: 280# --> Actions:\n",
      "mean: 0.0395438270864965 sdev: 0.0017716989698665006\n",
      "Training iteration: 283          last optimization: 280+ --> Actions:\n",
      "mean: 0.03958441101193572 sdev: 0.0017134649716716373\n",
      "Training iteration: 284          last optimization: 280# --> Actions:\n",
      "mean: 0.03962578627698881 sdev: 0.001661752184494687\n",
      "Training iteration: 285          last optimization: 285+ --> Actions:\n",
      "mean: 0.04044219287816674 sdev: 0.0017066424125399262\n",
      "Training iteration: 286          last optimization: 285# --> Actions:\n",
      "mean: 0.04048050309157575 sdev: 0.0018025709561531578\n",
      "Training iteration: 287          last optimization: 285+ --> Actions:\n",
      "mean: 0.040515797244939006 sdev: 0.0018905980969916658\n",
      "Training iteration: 288          last optimization: 285# --> Actions:\n",
      "mean: 0.04054618705913298 sdev: 0.0019667234882416087\n",
      "Training iteration: 289          last optimization: 285+ --> Actions:\n",
      "mean: 0.040570397432580334 sdev: 0.0020288155440834465\n",
      "Training iteration: 290          last optimization: 290# --> Actions:\n",
      "mean: 0.040748314085589835 sdev: 0.002638219014133292\n",
      "Training iteration: 291          last optimization: 290+ --> Actions:\n",
      "mean: 0.040760210467047586 sdev: 0.0026683621343681577\n",
      "Training iteration: 292          last optimization: 290# --> Actions:\n",
      "mean: 0.04076741914318836 sdev: 0.0026852116295847123\n",
      "Training iteration: 293          last optimization: 290+ --> Actions:\n",
      "mean: 0.04077082826324163 sdev: 0.002692006380483636\n",
      "Training iteration: 294          last optimization: 290# --> Actions:\n",
      "mean: 0.040771293492149904 sdev: 0.0026914536173576406\n",
      "Training iteration: 295          last optimization: 295+ --> Actions:\n",
      "mean: 0.04038224046281444 sdev: 0.002066263378863127\n",
      "Training iteration: 296          last optimization: 295# --> Actions:\n",
      "mean: 0.040382419042276844 sdev: 0.002057783707875871\n",
      "Training iteration: 297          last optimization: 295+ --> Actions:\n",
      "mean: 0.04037979625738801 sdev: 0.002043342447794082\n",
      "Training iteration: 298          last optimization: 295# --> Actions:\n",
      "mean: 0.04037432175733875 sdev: 0.002022678281285444\n",
      "Training iteration: 299          last optimization: 295+ --> Actions:\n",
      "mean: 0.04036577268130963 sdev: 0.0019952207245772986\n",
      "Training iteration: 300          last optimization: 300# --> Actions:\n",
      "mean: 0.03959775870444313 sdev: 0.0010683173914140566\n",
      "Training iteration: 301          last optimization: 300+ --> Actions:\n",
      "mean: 0.039590510575645894 sdev: 0.001067237653872783\n",
      "Training iteration: 302          last optimization: 300# --> Actions:\n",
      "mean: 0.03958415636781986 sdev: 0.0010708556935294382\n",
      "Training iteration: 303          last optimization: 300+ --> Actions:\n",
      "mean: 0.03957911545649153 sdev: 0.0010780332875908482\n",
      "Training iteration: 304          last optimization: 300# --> Actions:\n",
      "mean: 0.03957647696021907 sdev: 0.0010861206758472602\n",
      "Training iteration: 305          last optimization: 305+ --> Actions:\n",
      "mean: 0.03908574795042436 sdev: 0.001782774532509942\n",
      "Training iteration: 306          last optimization: 305# --> Actions:\n",
      "mean: 0.03908768097580967 sdev: 0.0017837333221595816\n",
      "Training iteration: 307          last optimization: 305+ --> Actions:\n",
      "mean: 0.03909321535989858 sdev: 0.0017754189203368787\n",
      "Training iteration: 308          last optimization: 305# --> Actions:\n",
      "mean: 0.03910179047572417 sdev: 0.0017587240826870913\n",
      "Training iteration: 309          last optimization: 305+ --> Actions:\n",
      "mean: 0.039112787577391096 sdev: 0.0017350585047231186\n",
      "Training iteration: 310          last optimization: 310# --> Actions:\n",
      "mean: 0.0391471703936593 sdev: 0.0017940448409397907\n",
      "Training iteration: 311          last optimization: 310+ --> Actions:\n",
      "mean: 0.03915826421131806 sdev: 0.001767156283755405\n",
      "Training iteration: 312          last optimization: 310# --> Actions:\n",
      "mean: 0.039170784710667504 sdev: 0.0017397338102455927\n",
      "Training iteration: 313          last optimization: 310+ --> Actions:\n",
      "mean: 0.039183039186425635 sdev: 0.0017136126996768885\n",
      "Training iteration: 314          last optimization: 310# --> Actions:\n",
      "mean: 0.039194644169866295 sdev: 0.0016904004941199018\n",
      "Training iteration: 315          last optimization: 315+ --> Actions:\n",
      "mean: 0.03964323200961236 sdev: 0.0009432256298655931\n",
      "Training iteration: 316          last optimization: 315# --> Actions:\n",
      "mean: 0.03964986812708876 sdev: 0.0009343102361964175\n",
      "Training iteration: 317          last optimization: 315+ --> Actions:\n",
      "mean: 0.039653811285489206 sdev: 0.0009283345247272784\n",
      "Training iteration: 318          last optimization: 315# --> Actions:\n",
      "mean: 0.039654925154417056 sdev: 0.0009272262364150675\n",
      "Training iteration: 319          last optimization: 315+ --> Actions:\n",
      "mean: 0.039652759220486763 sdev: 0.0009314459552803786\n",
      "Training iteration: 320          last optimization: 320# --> Actions:\n",
      "mean: 0.04027615522791897 sdev: 0.0012381056973215692\n",
      "Training iteration: 321          last optimization: 320+ --> Actions:\n",
      "mean: 0.040270428600945846 sdev: 0.0012199021747285256\n",
      "Training iteration: 322          last optimization: 320# --> Actions:\n",
      "mean: 0.040265190796802554 sdev: 0.0012065215736911448\n",
      "Training iteration: 323          last optimization: 320+ --> Actions:\n",
      "mean: 0.04026046003848652 sdev: 0.0011981200526891662\n",
      "Training iteration: 324          last optimization: 320# --> Actions:\n",
      "mean: 0.04025543492396043 sdev: 0.001193193804765563\n",
      "Training iteration: 325          last optimization: 325+ --> Actions:\n",
      "mean: 0.040323585051091335 sdev: 0.0015017111737829758\n",
      "Training iteration: 326          last optimization: 325# --> Actions:\n",
      "mean: 0.040317133823830544 sdev: 0.0014947846370221237\n",
      "Training iteration: 327          last optimization: 325+ --> Actions:\n",
      "mean: 0.040308812883748164 sdev: 0.0014810647717117538\n",
      "Training iteration: 328          last optimization: 325# --> Actions:\n",
      "mean: 0.04029683423135384 sdev: 0.0014573038659086179\n",
      "Training iteration: 329          last optimization: 325+ --> Actions:\n",
      "mean: 0.040280366101447196 sdev: 0.0014217408207904529\n",
      "Training iteration: 330          last optimization: 330# --> Actions:\n",
      "mean: 0.0398429045325318 sdev: 0.0006656407981258217\n",
      "Training iteration: 331          last optimization: 330+ --> Actions:\n",
      "mean: 0.039819953575670516 sdev: 0.0006355172535093722\n",
      "Training iteration: 332          last optimization: 330# --> Actions:\n",
      "mean: 0.03979385614979009 sdev: 0.0006078031549290975\n",
      "Training iteration: 333          last optimization: 330+ --> Actions:\n",
      "mean: 0.03976563076838487 sdev: 0.0005879953399853474\n",
      "Training iteration: 334          last optimization: 330# --> Actions:\n",
      "mean: 0.03973775852547835 sdev: 0.0005800699458554343\n",
      "Training iteration: 335          last optimization: 335+ --> Actions:\n",
      "mean: 0.03915886510856522 sdev: 0.0013373451592305326\n",
      "Training iteration: 336          last optimization: 335# --> Actions:\n",
      "mean: 0.03913814211681426 sdev: 0.0013902843631317843\n",
      "Training iteration: 337          last optimization: 335+ --> Actions:\n",
      "mean: 0.0391217940651972 sdev: 0.0014318991589332077\n",
      "Training iteration: 338          last optimization: 335# --> Actions:\n",
      "mean: 0.03910931271895671 sdev: 0.0014624552387460864\n",
      "Training iteration: 339          last optimization: 335+ --> Actions:\n",
      "mean: 0.039099822100018944 sdev: 0.0014836963174483055\n",
      "Training iteration: 340          last optimization: 340# --> Actions:\n",
      "mean: 0.03904429885739244 sdev: 0.0016371768191332187\n",
      "Training iteration: 341          last optimization: 340+ --> Actions:\n",
      "mean: 0.03903858590330889 sdev: 0.0016468278723543986\n",
      "Training iteration: 342          last optimization: 340# --> Actions:\n",
      "mean: 0.039033559031993625 sdev: 0.0016550132804343453\n",
      "Training iteration: 343          last optimization: 340+ --> Actions:\n",
      "mean: 0.039028088012723 sdev: 0.0016622740153975904\n",
      "Training iteration: 344          last optimization: 340# --> Actions:\n",
      "mean: 0.03902143779817568 sdev: 0.0016706351536558332\n",
      "Training iteration: 345          last optimization: 345+ --> Actions:\n",
      "mean: 0.03937964610229976 sdev: 0.0008326699335827213\n",
      "Training iteration: 346          last optimization: 345# --> Actions:\n",
      "mean: 0.039368441070229715 sdev: 0.0008437493886203512\n",
      "Training iteration: 347          last optimization: 345+ --> Actions:\n",
      "mean: 0.03935730647158815 sdev: 0.0008567553263482357\n",
      "Training iteration: 348          last optimization: 345# --> Actions:\n",
      "mean: 0.039347356447129236 sdev: 0.0008698264734689615\n",
      "Training iteration: 349          last optimization: 345+ --> Actions:\n",
      "mean: 0.039338938453805955 sdev: 0.0008805274511718572\n",
      "Training iteration: 350          last optimization: 350# --> Actions:\n",
      "mean: 0.04003019554569231 sdev: 0.001133717901694093\n",
      "Training iteration: 351          last optimization: 350+ --> Actions:\n",
      "mean: 0.0400282170145304 sdev: 0.0011399657505866464\n",
      "Training iteration: 352          last optimization: 350# --> Actions:\n",
      "mean: 0.04003116450623913 sdev: 0.001159288834774911\n",
      "Training iteration: 353          last optimization: 350+ --> Actions:\n",
      "mean: 0.040038478432178295 sdev: 0.0011895409147558655\n",
      "Training iteration: 354          last optimization: 350# --> Actions:\n",
      "mean: 0.04004874071209537 sdev: 0.00122667468997179\n",
      "Training iteration: 355          last optimization: 355+ --> Actions:\n",
      "mean: 0.04021677199039495 sdev: 0.0017615862268581552\n",
      "Training iteration: 356          last optimization: 355# --> Actions:\n",
      "mean: 0.04023063999664925 sdev: 0.0018000174122067675\n",
      "Training iteration: 357          last optimization: 355+ --> Actions:\n",
      "mean: 0.04024389653581025 sdev: 0.0018348263855526713\n",
      "Training iteration: 358          last optimization: 355# --> Actions:\n",
      "mean: 0.04025591888957063 sdev: 0.0018633049615265735\n",
      "Training iteration: 359          last optimization: 355+ --> Actions:\n",
      "mean: 0.04026623789143852 sdev: 0.001884134278862507\n",
      "Training iteration: 360          last optimization: 360# --> Actions:\n",
      "mean: 0.039923432310700835 sdev: 0.0011616153160437612\n",
      "Training iteration: 361          last optimization: 360+ --> Actions:\n",
      "mean: 0.039929481112629436 sdev: 0.0011686173346750757\n",
      "Training iteration: 362          last optimization: 360# --> Actions:\n",
      "mean: 0.03993410609355481 sdev: 0.0011712994883464423\n",
      "Training iteration: 363          last optimization: 360+ --> Actions:\n",
      "mean: 0.03993761636079783 sdev: 0.0011724809085833891\n",
      "Training iteration: 364          last optimization: 360# --> Actions:\n",
      "mean: 0.0399400476248562 sdev: 0.0011747710303066977\n",
      "Training iteration: 365          last optimization: 365+ --> Actions:\n",
      "mean: 0.03919050009888281 sdev: 0.000745886120195677\n",
      "Training iteration: 366          last optimization: 365# --> Actions:\n",
      "mean: 0.039194691216263886 sdev: 0.0007368655601822456\n",
      "Training iteration: 367          last optimization: 365+ --> Actions:\n",
      "mean: 0.03920051655632156 sdev: 0.0007241402079033942\n",
      "Training iteration: 368          last optimization: 365# --> Actions:\n",
      "mean: 0.03920740166281304 sdev: 0.0007089942439682808\n",
      "Training iteration: 369          last optimization: 365+ --> Actions:\n",
      "mean: 0.0392144775602556 sdev: 0.0006924105185252212\n",
      "Training iteration: 370          last optimization: 370# --> Actions:\n",
      "mean: 0.03897892385816418 sdev: 0.0011593823915552336\n",
      "Training iteration: 371          last optimization: 370+ --> Actions:\n",
      "mean: 0.03898334807930773 sdev: 0.001138322735673344\n",
      "Training iteration: 372          last optimization: 370# --> Actions:\n",
      "mean: 0.03898629320996082 sdev: 0.0011180788872676261\n",
      "Training iteration: 373          last optimization: 370+ --> Actions:\n",
      "mean: 0.038988192388641686 sdev: 0.0011003926169448506\n",
      "Training iteration: 374          last optimization: 370# --> Actions:\n",
      "mean: 0.03898942550302336 sdev: 0.0010856156022029915\n",
      "Training iteration: 375          last optimization: 375+ --> Actions:\n",
      "mean: 0.03919496692760226 sdev: 0.0005197130138205259\n",
      "Training iteration: 376          last optimization: 375# --> Actions:\n",
      "mean: 0.03919762969671267 sdev: 0.0005093279862607868\n",
      "Training iteration: 377          last optimization: 375+ --> Actions:\n",
      "mean: 0.03920087888982373 sdev: 0.0005000711701232028\n",
      "Training iteration: 378          last optimization: 375# --> Actions:\n",
      "mean: 0.0392072578039543 sdev: 0.000490508553599347\n",
      "Training iteration: 379          last optimization: 375+ --> Actions:\n",
      "mean: 0.039216370103720796 sdev: 0.0004779678900191992\n",
      "Training iteration: 380          last optimization: 380# --> Actions:\n",
      "mean: 0.03979969064833437 sdev: 0.001208035990897824\n",
      "Training iteration: 381          last optimization: 380+ --> Actions:\n",
      "mean: 0.03981622072167422 sdev: 0.0012432896169597533\n",
      "Training iteration: 382          last optimization: 380# --> Actions:\n",
      "mean: 0.03983706820639209 sdev: 0.0012889668572352785\n",
      "Training iteration: 383          last optimization: 380+ --> Actions:\n",
      "mean: 0.039860850527859856 sdev: 0.0013435243073494853\n",
      "Training iteration: 384          last optimization: 380# --> Actions:\n",
      "mean: 0.03988665541206257 sdev: 0.0014044612716721586\n",
      "Training iteration: 385          last optimization: 385+ --> Actions:\n",
      "mean: 0.03995162458347303 sdev: 0.0017059309932478642\n",
      "Training iteration: 386          last optimization: 385# --> Actions:\n",
      "mean: 0.03997730665292012 sdev: 0.0017636782898787647\n",
      "Training iteration: 387          last optimization: 385+ --> Actions:\n",
      "mean: 0.04000065233361424 sdev: 0.0018156562174135153\n",
      "Training iteration: 388          last optimization: 385# --> Actions:\n",
      "mean: 0.04002089643659072 sdev: 0.0018592378501535555\n",
      "Training iteration: 389          last optimization: 385+ --> Actions:\n",
      "mean: 0.0400374083314715 sdev: 0.0018922692830815706\n",
      "Training iteration: 390          last optimization: 390# --> Actions:\n",
      "mean: 0.0395932709065772 sdev: 0.0009024782548721883\n",
      "Training iteration: 391          last optimization: 390+ --> Actions:\n",
      "mean: 0.03960255954033885 sdev: 0.0009117317275007651\n",
      "Training iteration: 392          last optimization: 390# --> Actions:\n",
      "mean: 0.039608134711709306 sdev: 0.0009117799583492377\n",
      "Training iteration: 393          last optimization: 390+ --> Actions:\n",
      "mean: 0.03961027709419028 sdev: 0.0009050490401249694\n",
      "Training iteration: 394          last optimization: 390# --> Actions:\n",
      "mean: 0.03961013152158974 sdev: 0.0008948329660785771\n",
      "Training iteration: 395          last optimization: 395+ --> Actions:\n",
      "mean: 0.0387576428726707 sdev: 0.001163057573515343\n",
      "Training iteration: 396          last optimization: 395# --> Actions:\n",
      "mean: 0.03875638562192413 sdev: 0.001170995019703382\n",
      "Training iteration: 397          last optimization: 395+ --> Actions:\n",
      "mean: 0.03875454587291469 sdev: 0.0011787609854465794\n",
      "Training iteration: 398          last optimization: 395# --> Actions:\n",
      "mean: 0.03875135637415261 sdev: 0.0011864949928806813\n",
      "Training iteration: 399          last optimization: 395+ --> Actions:\n",
      "mean: 0.038746456843366125 sdev: 0.0011957198401840827\n",
      "Training iteration: 400          last optimization: 400# --> Actions:\n",
      "mean: 0.03842676860918824 sdev: 0.0018709093591235007\n",
      "Training iteration: 401          last optimization: 400+ --> Actions:\n",
      "mean: 0.03842184974178275 sdev: 0.0018837920365773952\n",
      "Training iteration: 402          last optimization: 400# --> Actions:\n",
      "mean: 0.03841468638061692 sdev: 0.0019031699650647641\n",
      "Training iteration: 403          last optimization: 400+ --> Actions:\n",
      "mean: 0.03840481918408808 sdev: 0.0019304611522033466\n",
      "Training iteration: 404          last optimization: 400# --> Actions:\n",
      "mean: 0.038392579616287184 sdev: 0.0019665132783087034\n",
      "Training iteration: 405          last optimization: 405+ --> Actions:\n",
      "mean: 0.03850092167771454 sdev: 0.0015691086725060288\n",
      "Training iteration: 406          last optimization: 405# --> Actions:\n",
      "mean: 0.038483801640169124 sdev: 0.0016198910458710245\n",
      "Training iteration: 407          last optimization: 405+ --> Actions:\n",
      "mean: 0.038465789346860846 sdev: 0.0016722902827168622\n",
      "Training iteration: 408          last optimization: 405# --> Actions:\n",
      "mean: 0.03844933101821353 sdev: 0.0017218026783350463\n",
      "Training iteration: 409          last optimization: 405+ --> Actions:\n",
      "mean: 0.03843575381173773 sdev: 0.0017632151731048719\n",
      "Training iteration: 410          last optimization: 410# --> Actions:\n",
      "mean: 0.03893987635752415 sdev: 0.00038730463223615914\n",
      "Training iteration: 411          last optimization: 410+ --> Actions:\n",
      "mean: 0.03893268370171142 sdev: 0.0004075741685672917\n",
      "Training iteration: 412          last optimization: 410# --> Actions:\n",
      "mean: 0.03892842572297065 sdev: 0.00041782526706405466\n",
      "Training iteration: 413          last optimization: 410+ --> Actions:\n",
      "mean: 0.038927325422001405 sdev: 0.00042063629260708196\n",
      "Training iteration: 414          last optimization: 410# --> Actions:\n",
      "mean: 0.03892865114124829 sdev: 0.0004183312631168454\n",
      "Training iteration: 415          last optimization: 415+ --> Actions:\n",
      "mean: 0.03981222400236531 sdev: 0.001994851159258746\n",
      "Training iteration: 416          last optimization: 415# --> Actions:\n",
      "mean: 0.039812242997535205 sdev: 0.0019952898367270253\n",
      "Training iteration: 417          last optimization: 415+ --> Actions:\n",
      "mean: 0.03981146099569287 sdev: 0.001990057894007188\n",
      "Training iteration: 418          last optimization: 415# --> Actions:\n",
      "mean: 0.03980924738222575 sdev: 0.001977223877244795\n",
      "Training iteration: 419          last optimization: 415+ --> Actions:\n",
      "mean: 0.03980452639453545 sdev: 0.0019554074539461907\n",
      "Training iteration: 420          last optimization: 420# --> Actions:\n",
      "mean: 0.0401301099563717 sdev: 0.0028970713363568085\n",
      "Training iteration: 421          last optimization: 420+ --> Actions:\n",
      "mean: 0.040117965591065556 sdev: 0.0028565595617774855\n",
      "Training iteration: 422          last optimization: 420# --> Actions:\n",
      "mean: 0.040104601332989716 sdev: 0.002813865453720894\n",
      "Training iteration: 423          last optimization: 420+ --> Actions:\n",
      "mean: 0.04009106408971673 sdev: 0.0027735030227281124\n",
      "Training iteration: 424          last optimization: 420# --> Actions:\n",
      "mean: 0.04007914976719638 sdev: 0.0027381653559665794\n",
      "Training iteration: 425          last optimization: 425+ --> Actions:\n",
      "mean: 0.039888772466632805 sdev: 0.0023875927269184564\n",
      "Training iteration: 426          last optimization: 425# --> Actions:\n",
      "mean: 0.03988094949279819 sdev: 0.002370618225878215\n",
      "Training iteration: 427          last optimization: 425+ --> Actions:\n",
      "mean: 0.039873799485585754 sdev: 0.0023586323340759755\n",
      "Training iteration: 428          last optimization: 425# --> Actions:\n",
      "mean: 0.03986705833709543 sdev: 0.002348996518072712\n",
      "Training iteration: 429          last optimization: 425+ --> Actions:\n",
      "mean: 0.03985899074388931 sdev: 0.002338798061380806\n",
      "Training iteration: 430          last optimization: 430# --> Actions:\n",
      "mean: 0.03926180057183547 sdev: 0.0009710823563804982\n",
      "Training iteration: 431          last optimization: 430+ --> Actions:\n",
      "mean: 0.0392549451314322 sdev: 0.0009636854623492731\n",
      "Training iteration: 432          last optimization: 430# --> Actions:\n",
      "mean: 0.03924658714528011 sdev: 0.0009513929652430583\n",
      "Training iteration: 433          last optimization: 430+ --> Actions:\n",
      "mean: 0.03923563663780502 sdev: 0.0009338630193858912\n",
      "Training iteration: 434          last optimization: 430# --> Actions:\n",
      "mean: 0.039221232757050715 sdev: 0.0009101750152896976\n",
      "Training iteration: 435          last optimization: 435+ --> Actions:\n",
      "mean: 0.03833761278645929 sdev: 0.0013377060740581963\n",
      "Training iteration: 436          last optimization: 435# --> Actions:\n",
      "mean: 0.0383224734218284 sdev: 0.0013669934000519262\n",
      "Training iteration: 437          last optimization: 435+ --> Actions:\n",
      "mean: 0.038308055720924564 sdev: 0.0013979773353712877\n",
      "Training iteration: 438          last optimization: 435# --> Actions:\n",
      "mean: 0.03829499591475053 sdev: 0.0014259234847523454\n",
      "Training iteration: 439          last optimization: 435+ --> Actions:\n",
      "mean: 0.038284427525915876 sdev: 0.0014481179271861248\n",
      "Training iteration: 440          last optimization: 440# --> Actions:\n",
      "mean: 0.03789485979628275 sdev: 0.002337022916577043\n",
      "Training iteration: 441          last optimization: 440+ --> Actions:\n",
      "mean: 0.037892198786109596 sdev: 0.002341146774249761\n",
      "Training iteration: 442          last optimization: 440# --> Actions:\n",
      "mean: 0.037892323356589486 sdev: 0.002336438013529271\n",
      "Training iteration: 443          last optimization: 440+ --> Actions:\n",
      "mean: 0.03789591588187705 sdev: 0.0023241302929697294\n",
      "Training iteration: 444          last optimization: 440# --> Actions:\n",
      "mean: 0.03790274936323691 sdev: 0.0023062674882218595\n",
      "Training iteration: 445          last optimization: 445+ --> Actions:\n",
      "mean: 0.03790759125325 sdev: 0.002180178188119195\n",
      "Training iteration: 446          last optimization: 445# --> Actions:\n",
      "mean: 0.037916550807093094 sdev: 0.0021585545684001265\n",
      "Training iteration: 447          last optimization: 445+ --> Actions:\n",
      "mean: 0.03792686385666803 sdev: 0.002136056477473153\n",
      "Training iteration: 448          last optimization: 445# --> Actions:\n",
      "mean: 0.037938617555181235 sdev: 0.0021131424251031898\n",
      "Training iteration: 449          last optimization: 445+ --> Actions:\n",
      "mean: 0.03795149598224544 sdev: 0.0020883820060667233\n",
      "Training iteration: 450          last optimization: 450# --> Actions:\n",
      "mean: 0.03830035149303031 sdev: 0.001091767499611543\n",
      "Training iteration: 451          last optimization: 450+ --> Actions:\n",
      "mean: 0.03831570825161913 sdev: 0.0010600851862618845\n",
      "Training iteration: 452          last optimization: 450# --> Actions:\n",
      "mean: 0.038331598711877565 sdev: 0.001023157764259447\n",
      "Training iteration: 453          last optimization: 450+ --> Actions:\n",
      "mean: 0.03834878542804068 sdev: 0.0009807860796040167\n",
      "Training iteration: 454          last optimization: 450# --> Actions:\n",
      "mean: 0.03836696672857415 sdev: 0.0009341780509958298\n",
      "Training iteration: 455          last optimization: 455+ --> Actions:\n",
      "mean: 0.03904685136190708 sdev: 0.0011989634100740283\n",
      "Training iteration: 456          last optimization: 455# --> Actions:\n",
      "mean: 0.03906574301338654 sdev: 0.001254343883658003\n",
      "Training iteration: 457          last optimization: 455+ --> Actions:\n",
      "mean: 0.03908471407669706 sdev: 0.0013102447293288644\n",
      "Training iteration: 458          last optimization: 455# --> Actions:\n",
      "mean: 0.039102895520231246 sdev: 0.0013653111574267365\n",
      "Training iteration: 459          last optimization: 455+ --> Actions:\n",
      "mean: 0.039120224723073325 sdev: 0.0014184513523257081\n",
      "Training iteration: 460          last optimization: 460# --> Actions:\n",
      "mean: 0.039338577256880156 sdev: 0.002105313357330447\n",
      "Training iteration: 461          last optimization: 460+ --> Actions:\n",
      "mean: 0.039353869420034736 sdev: 0.0021519636744929643\n",
      "Training iteration: 462          last optimization: 460# --> Actions:\n",
      "mean: 0.039368019755223214 sdev: 0.0021932463629809134\n",
      "Training iteration: 463          last optimization: 460+ --> Actions:\n",
      "mean: 0.03938119590999968 sdev: 0.002228181320181015\n",
      "Training iteration: 464          last optimization: 460# --> Actions:\n",
      "mean: 0.03939210876381685 sdev: 0.0022565426043756544\n",
      "Training iteration: 465          last optimization: 465+ --> Actions:\n",
      "mean: 0.039171175356462765 sdev: 0.0017799479489672048\n",
      "Training iteration: 466          last optimization: 465# --> Actions:\n",
      "mean: 0.039179845486908935 sdev: 0.001794645524509306\n",
      "Training iteration: 467          last optimization: 465+ --> Actions:\n",
      "mean: 0.03918678837831703 sdev: 0.0018032961765663657\n",
      "Training iteration: 468          last optimization: 465# --> Actions:\n",
      "mean: 0.03919299159553293 sdev: 0.0018066084962352206\n",
      "Training iteration: 469          last optimization: 465+ --> Actions:\n",
      "mean: 0.03919853865101794 sdev: 0.0018064019458953029\n",
      "Training iteration: 470          last optimization: 470# --> Actions:\n",
      "mean: 0.03861111484590172 sdev: 0.00041202948162585656\n",
      "Training iteration: 471          last optimization: 470+ --> Actions:\n",
      "mean: 0.03861628465695201 sdev: 0.0004144450528511378\n",
      "Training iteration: 472          last optimization: 470# --> Actions:\n",
      "mean: 0.03862207452488477 sdev: 0.0004181931939710538\n",
      "Training iteration: 473          last optimization: 470+ --> Actions:\n",
      "mean: 0.03862787451312552 sdev: 0.00042358636649517995\n",
      "Training iteration: 474          last optimization: 470# --> Actions:\n",
      "mean: 0.038633461886984986 sdev: 0.0004296391173161136\n",
      "Training iteration: 475          last optimization: 475+ --> Actions:\n",
      "mean: 0.03782964968622865 sdev: 0.00172378145512109\n",
      "Training iteration: 476          last optimization: 475# --> Actions:\n",
      "mean: 0.037833812351264796 sdev: 0.0017259845076428913\n",
      "Training iteration: 477          last optimization: 475+ --> Actions:\n",
      "mean: 0.037835503329923394 sdev: 0.0017326524073844453\n",
      "Training iteration: 478          last optimization: 475# --> Actions:\n",
      "mean: 0.03783487276266603 sdev: 0.0017444739005488662\n",
      "Training iteration: 479          last optimization: 475+ --> Actions:\n",
      "mean: 0.03783287900427021 sdev: 0.0017620575456307839\n",
      "Training iteration: 480          last optimization: 480# --> Actions:\n",
      "mean: 0.03746484373184662 sdev: 0.0026372687017935524\n",
      "Training iteration: 481          last optimization: 480+ --> Actions:\n",
      "mean: 0.037461710893090215 sdev: 0.002657706236766119\n",
      "Training iteration: 482          last optimization: 480# --> Actions:\n",
      "mean: 0.037457612110360014 sdev: 0.002677583556589358\n",
      "Training iteration: 483          last optimization: 480+ --> Actions:\n",
      "mean: 0.03745434902955621 sdev: 0.0026950048174944857\n",
      "Training iteration: 484          last optimization: 480# --> Actions:\n",
      "mean: 0.03745249734439295 sdev: 0.002708514042737054\n",
      "Training iteration: 485          last optimization: 485+ --> Actions:\n",
      "mean: 0.03744360505154355 sdev: 0.002621047669174144\n",
      "Training iteration: 486          last optimization: 485# --> Actions:\n",
      "mean: 0.037443760353570846 sdev: 0.002627556534298728\n",
      "Training iteration: 487          last optimization: 485+ --> Actions:\n",
      "mean: 0.03744450701216943 sdev: 0.0026312449353272215\n",
      "Training iteration: 488          last optimization: 485# --> Actions:\n",
      "mean: 0.037445775023236656 sdev: 0.0026331075253961268\n",
      "Training iteration: 489          last optimization: 485+ --> Actions:\n",
      "mean: 0.03744713987538703 sdev: 0.002634985645221427\n",
      "Training iteration: 490          last optimization: 490# --> Actions:\n",
      "mean: 0.03775723668607866 sdev: 0.0017330852199581638\n",
      "Training iteration: 491          last optimization: 490+ --> Actions:\n",
      "mean: 0.037754911066456356 sdev: 0.0017451149512751733\n",
      "Training iteration: 492          last optimization: 490# --> Actions:\n",
      "mean: 0.03775146133427701 sdev: 0.0017613855772180497\n",
      "Training iteration: 493          last optimization: 490+ --> Actions:\n",
      "mean: 0.037746801057968134 sdev: 0.0017829718457138216\n",
      "Training iteration: 494          last optimization: 490# --> Actions:\n",
      "mean: 0.03774027947394027 sdev: 0.001808910518775931\n",
      "Training iteration: 495          last optimization: 495+ --> Actions:\n",
      "mean: 0.038334639126995494 sdev: 0.000563871417192402\n",
      "Training iteration: 496          last optimization: 495# --> Actions:\n",
      "mean: 0.03832317570174277 sdev: 0.000574417024178034\n",
      "Training iteration: 497          last optimization: 495+ --> Actions:\n",
      "mean: 0.03831104413402893 sdev: 0.0005865164682519966\n",
      "Training iteration: 498          last optimization: 495# --> Actions:\n",
      "mean: 0.03829949933385692 sdev: 0.0005988867750991409\n",
      "Training iteration: 499          last optimization: 495+ --> Actions:\n",
      "mean: 0.038289569027321946 sdev: 0.0006100031442307105\n",
      "Training iteration: 500          last optimization: 500#\n",
      "***--> Total Elapsed Runtime: 00:00:02 for training the agent\n"
     ]
    }
   ],
   "source": [
    "# Thx2: https://discuss.pytorch.org/t/how-to-check-if-model-is-on-cuda/180/2?u=ferenc_acs\n",
    "start_time = time()\n",
    "\n",
    "agent.train()\n",
    "\n",
    "end_time = time()\n",
    "\n",
    "print_elapsed_time(start_time, end_time, \"for training the agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***--> Total Elapsed Runtime: 00:00:00 for observing the trained agent\n",
      "#\n",
      "Total score (averaged over agents) this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Some reminders about lambda functions\n",
    "# Thx2: https://realpython.com/python-lambda/\n",
    "# Thx2: https://thispointer.com/python-how-to-use-if-else-elif-in-lambda-functions/\n",
    "\n",
    "RANDOMRUN = False\n",
    "\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "#env_info = env.reset(train_mode=True)[brain_name] # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "avg100sum = np.zeros(num_agents)\n",
    "exectime = 0\n",
    "\n",
    "scores100 = deque(avg100sum, 100)\n",
    "time100 = list()\n",
    "epc = 0\n",
    "\n",
    "\n",
    "#import pdb; pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "start_time = time()\n",
    "\n",
    "while RANDOMRUN: #== True:\n",
    "    epc += 1\n",
    "    #print(f'\\r#{epc}', end = ' ')\n",
    "    print(f'\\r#{str(epc).rjust(6)}', end = ' ')\n",
    "    #actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = agent.a2c_net.select_action(states)\n",
    "    #actions = np.clip(actions.detach().cpu().numpy(), -1, 1)                  # all actions between -1 and 1\n",
    "        \n",
    "    t_step_b = time()\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    t_step_e = time()\n",
    "    time100.append(t_step_e - t_step_b)\n",
    "    \n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    rewards = env_info.rewards\n",
    "    nprewards = np.array(rewards)\n",
    "    scores += rewards                         # update the score (for each agent)\n",
    "    scores100.append(rewards)\n",
    "    if np.sum(nprewards) > 0:\n",
    "        #for x in scores100:\n",
    "        #    avg100sum += x\n",
    "        print(f'\\r#{epc} Avg 100 Rewards = {np.mean(scores100)}')  \n",
    "        avg100sum = np.zeros(num_agents)\n",
    "        maskagent = nprewards > 0\n",
    "        \n",
    "    if epc%100 == 0:\n",
    "        print(f'Exec time Avg 100: {np.mean(time100)}')\n",
    "        time100 = []\n",
    "        \n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "        \n",
    "end_time = time()\n",
    "\n",
    "print_elapsed_time(start_time, end_time, \"for observing the trained agent\")\n",
    "        \n",
    "print('#')\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-26 / 21-29-23  Notebook for Continuous Control ended.\n"
     ]
    }
   ],
   "source": [
    "print(get_time_string(sep=True), ' Notebook for Continuous Control ended.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
