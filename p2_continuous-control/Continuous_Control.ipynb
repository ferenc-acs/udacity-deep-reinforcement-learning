{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posix.uname_result(sysname='Linux', nodename='a28aa29a9bb6', release='4.15.0-1083-gcp', version='#94~16.04.1-Ubuntu SMP Sat Sep 5 22:53:03 UTC 2020', machine='x86_64')\n",
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 3.0.7 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.uname())\n",
    "\n",
    "# In the cloud environment?\n",
    "if 'root' in os.environ['HOME']:\n",
    "    UENVPATH = '/data/'\n",
    "    !pip -q install /home/workspace/python\n",
    "\n",
    "# In the standalone environment?\n",
    "if 'ferenc' in os.environ['HOME']:\n",
    "    UENVPATH = '/home/ferenc/Python/rl/udadrl/data/'\n",
    "\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "import pprint as pp\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "from time import time\n",
    "\n",
    "# Import the helper files\n",
    "from utilities import get_time_string, print_elapsed_time\n",
    "\n",
    "import pdb # Debug! Debug! Debug! Debug! Debug! Debug! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-28 / 19-09-32  Notebook for Continuous Control started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "print(get_time_string(sep=True), ' Notebook for Continuous Control started.')\n",
    "\n",
    "# ONE Agent, Standalone\n",
    "#UENVCHOICE = 'Reacher_Linux/Reacher.x86_64'\n",
    "\n",
    "# TWENTY Agents, Standalone\n",
    "#UENVCHOICE = 'Reacher_Linux_20/Reacher.x86_64'\n",
    "\n",
    "# ONE Agent, Cloud, No-Visuals \n",
    "#UENVCHOICE = 'Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64'\n",
    "\n",
    "# TWENTY Agents, Cloud, No-Visuals \n",
    "UENVCHOICE = 'Reacher_Linux_NoVis/Reacher.x86_64'\n",
    "\n",
    "env = UnityEnvironment( file_name=os.path.join( UENVPATH, UENVCHOICE ) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unityagents.environment.UnityEnvironment"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FA DEBUG! DEBUG! DEBUG! \n",
    "type(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ReacherBrain']\n",
      "<class 'unityagents.brain.BrainParameters'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ReacherBrain'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FA  DEBUG! DEBUG! DEBUG! \n",
    "print(env.brain_names)\n",
    "print( type(brain) )\n",
    "brain.brain_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space: 33 dimensions of continuous type\n",
      "Action Space: 4 dimensions of continuous type\n"
     ]
    }
   ],
   "source": [
    "# FA  DEBUG! DEBUG! DEBUG!\n",
    "print(f'Observation Space: {brain.vector_observation_space_size} dimensions of {brain.vector_observation_space_type} type') \n",
    "print(f'Action Space: {brain.vector_action_space_size} dimensions of {brain.vector_observation_space_type} type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "   1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   5.75471878e+00  -1.00000000e+00\n",
      "   5.55726624e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "  -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 20 active agents\n",
      "\n",
      "***--> Total Elapsed Runtime: 00:00:00 for choosing random actions\n",
      "#\n",
      "Total score (averaged over agents) this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Should a run with random actions be perfomed first?\n",
    "RANDOMRUN = False\n",
    "\n",
    "# Some reminders about lambda functions\n",
    "# Thx2: https://realpython.com/python-lambda/\n",
    "# Thx2: https://thispointer.com/python-how-to-use-if-else-elif-in-lambda-functions/\n",
    "# thx2: https://www.blog.pythonlibrary.org/2016/05/24/python-101-an-intro-to-benchmarking-your-code/\n",
    "import timeit\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "\n",
    "epc = 0\n",
    "print(f'We have {num_agents} active agent' + ( lambda x: 's' if x>1 else '' )(num_agents) )\n",
    "\n",
    "start_time = time()\n",
    "setup = \"from unityagents import UnityEnvironment\"\n",
    "\n",
    "while RANDOMRUN:\n",
    "    epc += 1\n",
    "    #print(f'\\r#{epc}', end = ' ')\n",
    "    print(f'\\r#{str(epc).rjust(6)}', end = ' ')\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    #pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    #print( timeit.timeit(\"env_info = env.step(actions)[brain_name]\", setup) )\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    rewards = env_info.rewards\n",
    "    nprewards = np.array(rewards)\n",
    "    scores += rewards                         # update the score (for each agent)\n",
    "    if np.sum(nprewards) > 0:\n",
    "        #print(f'\\r#{epc} Rewards = {rewards}')\n",
    "        maskagent = nprewards > 0\n",
    "        agentbefore = False\n",
    "        for (nagent, action) in enumerate(actions):\n",
    "            if maskagent[nagent]:\n",
    "                if agentbefore:\n",
    "                    print('\\r#' + '&'.rjust(6), end = ' ')\n",
    "                print(' -> Agent {:0>2d} got reward {:+.5f} for action: {}'.format(nagent+1, rewards[nagent], action))\n",
    "                agentbefore = True\n",
    "                #pp.pprint(list(action))\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "        \n",
    "end_time = time()\n",
    "\n",
    "print_elapsed_time(start_time, end_time, \"for choosing random actions\")\n",
    "\n",
    "print('#')\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re check running time (Random run)\n",
    "This time with the leanest code possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 20 active agents\n",
      "\n",
      "***--> Total Elapsed Runtime: 00:00:00 for choosing fast random actions\n",
      "#\n",
      "Total score (averaged over agents) this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Should another run with random actions be perfomed?\n",
    "RANDOMRUN = False\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "#env_info = env.reset(train_mode=True)[brain_name] # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "\n",
    "epc = 0\n",
    "print(f'We have {num_agents} active agent' + ( lambda x: 's' if x>1 else '' )(num_agents) )\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "while RANDOMRUN:\n",
    "    epc += 1\n",
    "    print(f'\\r#{str(epc).rjust(6)}', end = ' ')\n",
    "    #pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "        \n",
    "end_time = time()\n",
    "\n",
    "print_elapsed_time(start_time, end_time, \"for choosing fast random actions\")\n",
    "\n",
    "print('#')\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,  -4.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "         -4.37113883e-08,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -1.00000000e+01,\n",
       "          0.00000000e+00,   1.00000000e+00,  -0.00000000e+00,\n",
       "         -0.00000000e+00,  -4.37113883e-08,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   7.12805176e+00,\n",
       "         -1.00000000e+00,  -3.63192368e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   3.92812490e-02],\n",
       "       [  0.00000000e+00,  -4.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "         -4.37113883e-08,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -1.00000000e+01,\n",
       "          0.00000000e+00,   1.00000000e+00,  -0.00000000e+00,\n",
       "         -0.00000000e+00,  -4.37113883e-08,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   5.03456116e+00,\n",
       "         -1.00000000e+00,   6.21716690e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   9.63666677e-01],\n",
       "       [  0.00000000e+00,  -4.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "         -4.37113883e-08,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -1.00000000e+01,\n",
       "          0.00000000e+00,   1.00000000e+00,  -0.00000000e+00,\n",
       "         -0.00000000e+00,  -4.37113883e-08,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   5.24847412e+00,\n",
       "         -1.00000000e+00,   6.03767776e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,  -1.35212541e-01],\n",
       "       [  0.00000000e+00,  -4.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "         -4.37113883e-08,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -1.00000000e+01,\n",
       "          0.00000000e+00,   1.00000000e+00,  -0.00000000e+00,\n",
       "         -0.00000000e+00,  -4.37113883e-08,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -7.87846184e+00,\n",
       "         -1.00000000e+00,  -1.38918507e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,  -5.42254448e-01],\n",
       "       [  0.00000000e+00,  -4.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "         -4.37113883e-08,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -1.00000000e+01,\n",
       "          0.00000000e+00,   1.00000000e+00,  -0.00000000e+00,\n",
       "         -0.00000000e+00,  -4.37113883e-08,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -2.79192984e-01,\n",
       "         -1.00000000e+00,   7.99512672e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   7.49394178e-01],\n",
       "       [  0.00000000e+00,  -4.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "         -4.37113883e-08,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -1.00000000e+01,\n",
       "          0.00000000e+00,   1.00000000e+00,  -0.00000000e+00,\n",
       "         -0.00000000e+00,  -4.37113883e-08,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.70228195e+00,\n",
       "         -1.00000000e+00,  -6.47213650e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   2.25743055e-02],\n",
       "       [  0.00000000e+00,  -4.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "         -4.37113883e-08,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -1.00000000e+01,\n",
       "          0.00000000e+00,   1.00000000e+00,  -0.00000000e+00,\n",
       "         -0.00000000e+00,  -4.37113883e-08,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -3.75577545e+00,\n",
       "         -1.00000000e+00,  -7.06358004e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   5.07442713e-01],\n",
       "       [  0.00000000e+00,  -4.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "         -4.37113883e-08,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -1.00000000e+01,\n",
       "          0.00000000e+00,   1.00000000e+00,  -0.00000000e+00,\n",
       "         -0.00000000e+00,  -4.37113883e-08,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.38918495e+00,\n",
       "         -1.00000000e+00,   7.87846184e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,  -4.48411107e-01],\n",
       "       [  0.00000000e+00,  -4.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "         -4.37113883e-08,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -1.00000000e+01,\n",
       "          0.00000000e+00,   1.00000000e+00,  -0.00000000e+00,\n",
       "         -0.00000000e+00,  -4.37113883e-08,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   2.73616028e+00,\n",
       "         -1.00000000e+00,  -7.51754141e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,  -5.25649071e-01],\n",
       "       [  0.00000000e+00,  -4.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "         -4.37113883e-08,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -1.00000000e+01,\n",
       "          0.00000000e+00,   1.00000000e+00,  -0.00000000e+00,\n",
       "         -0.00000000e+00,  -4.37113883e-08,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -5.55726719e+00,\n",
       "         -1.00000000e+00,  -5.75471878e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   6.52894735e-01],\n",
       "       [  0.00000000e+00,  -4.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "         -4.37113883e-08,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -1.00000000e+01,\n",
       "          0.00000000e+00,   1.00000000e+00,  -0.00000000e+00,\n",
       "         -0.00000000e+00,  -4.37113883e-08,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -6.99695778e+00,\n",
       "         -1.00000000e+00,   3.87847900e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   8.39847088e-01],\n",
       "       [  0.00000000e+00,  -4.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "         -4.37113883e-08,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -1.00000000e+01,\n",
       "          0.00000000e+00,   1.00000000e+00,  -0.00000000e+00,\n",
       "         -0.00000000e+00,  -4.37113883e-08,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   2.60454559e+00,\n",
       "         -1.00000000e+00,  -7.56414795e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   8.63162279e-02],\n",
       "       [  0.00000000e+00,  -4.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "         -4.37113883e-08,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -1.00000000e+01,\n",
       "          0.00000000e+00,   1.00000000e+00,  -0.00000000e+00,\n",
       "         -0.00000000e+00,  -4.37113883e-08,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   7.30836487e+00,\n",
       "         -1.00000000e+00,   3.25389290e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   5.08338690e-01],\n",
       "       [  0.00000000e+00,  -4.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "         -4.37113883e-08,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -1.00000000e+01,\n",
       "          0.00000000e+00,   1.00000000e+00,  -0.00000000e+00,\n",
       "         -0.00000000e+00,  -4.37113883e-08,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   7.96955776e+00,\n",
       "         -1.00000000e+00,   6.97246552e-01,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   6.07460499e-01],\n",
       "       [  0.00000000e+00,  -4.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "         -4.37113883e-08,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -1.00000000e+01,\n",
       "          0.00000000e+00,   1.00000000e+00,  -0.00000000e+00,\n",
       "         -0.00000000e+00,  -4.37113883e-08,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   7.51754093e+00,\n",
       "         -1.00000000e+00,   2.73616028e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   5.45782328e-01],\n",
       "       [  0.00000000e+00,  -4.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "         -4.37113883e-08,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -1.00000000e+01,\n",
       "          0.00000000e+00,   1.00000000e+00,  -0.00000000e+00,\n",
       "         -0.00000000e+00,  -4.37113883e-08,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -7.25046158e+00,\n",
       "         -1.00000000e+00,  -3.38094544e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   2.36645341e-01],\n",
       "       [  0.00000000e+00,  -4.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "         -4.37113883e-08,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -1.00000000e+01,\n",
       "          0.00000000e+00,   1.00000000e+00,  -0.00000000e+00,\n",
       "         -0.00000000e+00,  -4.37113883e-08,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -2.79193878e-01,\n",
       "         -1.00000000e+00,   7.99512482e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   5.87887526e-01],\n",
       "       [  0.00000000e+00,  -4.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "         -4.37113883e-08,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -1.00000000e+01,\n",
       "          0.00000000e+00,   1.00000000e+00,  -0.00000000e+00,\n",
       "         -0.00000000e+00,  -4.37113883e-08,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   2.33897400e+00,\n",
       "         -1.00000000e+00,  -7.65043640e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   6.67207956e-01],\n",
       "       [  0.00000000e+00,  -4.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "         -4.37113883e-08,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -1.00000000e+01,\n",
       "          0.00000000e+00,   1.00000000e+00,  -0.00000000e+00,\n",
       "         -0.00000000e+00,  -4.37113883e-08,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -5.75471878e+00,\n",
       "         -1.00000000e+00,   5.55726624e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,  -5.25265932e-02],\n",
       "       [  0.00000000e+00,  -4.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "         -4.37113883e-08,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -1.00000000e+01,\n",
       "          0.00000000e+00,   1.00000000e+00,  -0.00000000e+00,\n",
       "         -0.00000000e+00,  -4.37113883e-08,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   5.94515800e+00,\n",
       "         -1.00000000e+00,  -5.35304642e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,  -8.03074121e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# thx2: https://github.com/udacity/deep-reinforcement-learning/blob/master/python/unityagents/brain.py\n",
    "env_info.vector_observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When finished, you can close the environment.\n",
    "#### Just not for now because unit testing below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FA: One BIG MISUNDERSTANDING & STACKS OF TENSORS (23-08-2020) --> #FA; BMSoT:\n",
    "It has cost me several days if not weeks to get behind the fact that the [A2C sample implementation of Miguel](https://github.com/mimoralea/gdrl/blob/master/notebooks/chapter_11/chapter-11.ipynb) is working with **stacks of tensors** instead of single tensors. Which was especially hard to find because the PyTorch code looks exactly the same for both.\n",
    "\n",
    "In the end, when I thought about it, it makes sense and is a nifty feature of PyTorch. It is just not obvious to people like me, without in deep insights in the inner workings of PyTorch. \n",
    "\n",
    "Furthermore the authors of the PyTorch documentation seem not to make it too visible, I had to dig it out of one of the function definitions I use, however inderectly over the layer defintion for a2cnet:\n",
    "\n",
    "https://pytorch.org/docs/0.4.0/_modules/torch/nn/functional.html#linear\n",
    "\n",
    "> def linear(input, weight, bias=None):\n",
    ">    \"\"\"\n",
    ">    Applies a linear transformation to the incoming data: :math:`y = xA^T + b`.\n",
    ">\n",
    ">    Shape:\n",
    ">        - Input: :math:`(N, *, in\\_features)` where `*` means any number of\n",
    ">          additional dimensions\n",
    ">        - Weight: :math:`(out\\_features, in\\_features)`\n",
    ">        - Bias: :math:`(out\\_features)`\n",
    ">        - Output: :math:`(N, *, out\\_features)`\n",
    ">    \"\"\"\n",
    ">    if input.dim() == 2 and bias is not None:\n",
    ">        # fused op is marginally faster\n",
    ">        return torch.addmm(bias, input, weight.t())\n",
    ">\n",
    ">    output = input.matmul(weight.t())\n",
    ">    if bias is not None:\n",
    ">        output += bias\n",
    ">    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracing the error in the 'mya2cnet' module code refactoring below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! \n",
    "#import pdb; pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(20200808) # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "#torch.manual_seed(456454618181) # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "\n",
    "# Format: IN_Num [Layer 1] (OUT_Num = IN_Num) [Layer 2] OUT_Num = ...\n",
    "HIDDEN_DIMS_DEFAULT = {\n",
    "    'shared' : (512, 512, 256, 256),\n",
    "    'actor' : (256, 128, 128, 64),\n",
    "    'critic' : (256, 128, 128, 64)\n",
    "}\n",
    "hidden_dims = HIDDEN_DIMS_DEFAULT\n",
    "\n",
    "hlayers = dict()\n",
    "\n",
    "hlayers['shared'] = nn.ModuleList()\n",
    "hlayers['actor'] = nn.ModuleList()\n",
    "hlayers['critic'] = nn.ModuleList()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "input_layer = nn.Linear( 33, hidden_dims['shared'][0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=33, out_features=512, bias=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layers shared\n",
    "for i in range( len(hidden_dims['shared']) -1 ):\n",
    "    hlayers['shared'].append( nn.Linear( hidden_dims['shared'][i], hidden_dims['shared'][i+1] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hlayers['shared']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actor layers\n",
    "for i in range( len(hidden_dims['actor']) ):\n",
    "    #import pdb; pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "    if i == 0:\n",
    "        hlayers['actor'].append( nn.Linear( hidden_dims['shared'][-1], hidden_dims['actor'][i] ) )\n",
    "    else:\n",
    "        # hlayers['actor'].append( nn.Linear( hidden_dims['actor'][i], hidden_dims['actor'][i+1] ERROR !!!\n",
    "        hlayers['actor'].append( nn.Linear( hidden_dims['actor'][i-1], hidden_dims['actor'][i] ) )\n",
    "    #print( i, hlayers['actor'] ) # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "        \n",
    "actor_out_layer = nn.Linear( hidden_dims['actor'][-1], 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (3): Linear(in_features=128, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hlayers['actor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=64, out_features=4, bias=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Critic layers\n",
    "for i in range( len(hidden_dims['critic']) ):\n",
    "    if i == 0:\n",
    "        hlayers['critic'].append( nn.Linear( hidden_dims['shared'][-1], hidden_dims['critic'][i] ) )\n",
    "    else:\n",
    "        hlayers['critic'].append( nn.Linear( hidden_dims['critic'][i-1], hidden_dims['critic'][i] ) )\n",
    "critic_out_layer = nn.Linear( hidden_dims['critic'][-1], 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (3): Linear(in_features=128, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hlayers['critic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=64, out_features=1, bias=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic_out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevents non Pytorch Tensor Object entering the processing stream\n",
    "def torch_format(state):\n",
    "    x = state\n",
    "    if not isinstance(x, torch.Tensor):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        if len(x.size()) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(state):\n",
    "    check_tensor = lambda x: isinstance(x, torch.Tensor)\n",
    "    x_act = True \n",
    "    x_crit = True\n",
    "\n",
    "    x = torch_format(state)\n",
    "    x = F.relu(  input_layer(x) )\n",
    "    for label in ['shared', 'actor', 'critic']:\n",
    "        for hlayer in  hlayers[label]:\n",
    "            if label == 'shared':\n",
    "                x = F.relu(  hlayer(x) )\n",
    "            if label == 'actor':\n",
    "                x_act = F.relu(  hlayer(x_act) )\n",
    "            if label == 'critic':\n",
    "                x_crit = F.relu(  hlayer(x_crit) )\n",
    "\n",
    "        # Thx2: https://discuss.pytorch.org/t/copy-deepcopy-vs-clone/55022\n",
    "        if ( type(x_act) == bool ):\n",
    "            x_act = x.clone()  # Create an Inplace copy...\n",
    "        if ( type(x_crit) == bool ):\n",
    "            x_crit = x.clone() # ...after processing shared layers\n",
    "\n",
    "    return  actor_out_layer(x_act),  critic_out_layer(x_crit) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if A STACK OF (BMSoT) states are propagated through the debug network\n",
    "And make a list of outputs of two A2C instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States [[  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "   -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "    1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   7.12805176e+00  -1.00000000e+00\n",
      "   -3.63192368e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    3.92812490e-02]\n",
      " [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "   -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "    1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   5.03456116e+00  -1.00000000e+00\n",
      "    6.21716690e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    9.63666677e-01]\n",
      " [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "   -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "    1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   5.24847412e+00  -1.00000000e+00\n",
      "    6.03767776e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "   -1.35212541e-01]\n",
      " [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "   -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "    1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -7.87846184e+00  -1.00000000e+00\n",
      "   -1.38918507e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "   -5.42254448e-01]\n",
      " [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "   -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "    1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -2.79192984e-01  -1.00000000e+00\n",
      "    7.99512672e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    7.49394178e-01]\n",
      " [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "   -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "    1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   4.70228195e+00  -1.00000000e+00\n",
      "   -6.47213650e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    2.25743055e-02]\n",
      " [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "   -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "    1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -3.75577545e+00  -1.00000000e+00\n",
      "   -7.06358004e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    5.07442713e-01]\n",
      " [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "   -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "    1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   1.38918495e+00  -1.00000000e+00\n",
      "    7.87846184e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "   -4.48411107e-01]\n",
      " [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "   -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "    1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   2.73616028e+00  -1.00000000e+00\n",
      "   -7.51754141e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "   -5.25649071e-01]\n",
      " [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "   -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "    1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -5.55726719e+00  -1.00000000e+00\n",
      "   -5.75471878e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    6.52894735e-01]\n",
      " [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "   -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "    1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -6.99695778e+00  -1.00000000e+00\n",
      "    3.87847900e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    8.39847088e-01]\n",
      " [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "   -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "    1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   2.60454559e+00  -1.00000000e+00\n",
      "   -7.56414795e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    8.63162279e-02]\n",
      " [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "   -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "    1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   7.30836487e+00  -1.00000000e+00\n",
      "    3.25389290e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    5.08338690e-01]\n",
      " [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "   -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "    1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   7.96955776e+00  -1.00000000e+00\n",
      "    6.97246552e-01   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    6.07460499e-01]\n",
      " [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "   -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "    1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   7.51754093e+00  -1.00000000e+00\n",
      "    2.73616028e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    5.45782328e-01]\n",
      " [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "   -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "    1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -7.25046158e+00  -1.00000000e+00\n",
      "   -3.38094544e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    2.36645341e-01]\n",
      " [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "   -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "    1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -2.79193878e-01  -1.00000000e+00\n",
      "    7.99512482e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    5.87887526e-01]\n",
      " [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "   -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "    1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   2.33897400e+00  -1.00000000e+00\n",
      "   -7.65043640e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    6.67207956e-01]\n",
      " [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "   -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "    1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -5.75471878e+00  -1.00000000e+00\n",
      "    5.55726624e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "   -5.25265932e-02]\n",
      " [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "   -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "    1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   5.94515800e+00  -1.00000000e+00\n",
      "   -5.35304642e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "   -8.03074121e-01]]\n",
      "Actor: tensor(1.00000e-02 *\n",
      "       [[ 4.6543,  4.9756, -4.4953,  4.2128],\n",
      "        [ 4.7037,  4.9775, -4.4215,  4.1041],\n",
      "        [ 4.7006,  4.9798, -4.4235,  4.1018],\n",
      "        [ 4.6981,  4.9901, -4.3603,  4.1175],\n",
      "        [ 4.7117,  4.9911, -4.4272,  4.1191],\n",
      "        [ 4.6864,  4.9768, -4.4898,  4.2664],\n",
      "        [ 4.7017,  5.0059, -4.4374,  4.2481],\n",
      "        [ 4.7107,  4.9870, -4.4269,  4.1114],\n",
      "        [ 4.6985,  4.9721, -4.4752,  4.2727],\n",
      "        [ 4.6935,  5.0025, -4.4124,  4.2141],\n",
      "        [ 4.7007,  4.9718, -4.3907,  4.1061],\n",
      "        [ 4.6997,  4.9750, -4.4772,  4.2800],\n",
      "        [ 4.6790,  4.9917, -4.4376,  4.1197],\n",
      "        [ 4.6685,  4.9951, -4.4505,  4.1421],\n",
      "        [ 4.6763,  4.9944, -4.4406,  4.1248],\n",
      "        [ 4.6967,  4.9936, -4.3724,  4.1618],\n",
      "        [ 4.7116,  4.9925, -4.4258,  4.1176],\n",
      "        [ 4.7030,  4.9784, -4.4800,  4.2864],\n",
      "        [ 4.7116,  4.9804, -4.4134,  4.1002],\n",
      "        [ 4.6749,  4.9665, -4.4912,  4.2393]])\n",
      "Critic: tensor(1.00000e-02 *\n",
      "       [[ 4.7572],\n",
      "        [ 4.8767],\n",
      "        [ 4.8752],\n",
      "        [ 4.8696],\n",
      "        [ 4.8610],\n",
      "        [ 4.7746],\n",
      "        [ 4.8414],\n",
      "        [ 4.8706],\n",
      "        [ 4.8107],\n",
      "        [ 4.8393],\n",
      "        [ 4.8479],\n",
      "        [ 4.8147],\n",
      "        [ 4.8553],\n",
      "        [ 4.8110],\n",
      "        [ 4.8488],\n",
      "        [ 4.8638],\n",
      "        [ 4.8612],\n",
      "        [ 4.8194],\n",
      "        [ 4.8508],\n",
      "        [ 4.7676]])\n"
     ]
    }
   ],
   "source": [
    "#al = []\n",
    "#bl = []\n",
    "\n",
    "#for (dc, st) in enumerate(states):\n",
    "#    al.append(a)\n",
    "#    bl.append(b)\n",
    "\n",
    "#import pdb; pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!    \n",
    "    \n",
    "#FA; BMSoT: No need to iterate through states any more!\n",
    "a,b = forward(states)\n",
    "print(f'States {states}')\n",
    "print(f'Actor: {a}')\n",
    "print(f'Critic: {b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if A STACK OF (BMSoT) states is propagated through the imported network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "\n",
    "#from mya2cnet import A2CNetwork\n",
    "import mya2cnet\n",
    "\n",
    "# Thx2: https://emacs.stackexchange.com/a/13483\n",
    "import imp\n",
    "imp.reload(mya2cnet)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tstnet1 = mya2cnet.A2CNetwork(33, 4).to(device) #FA; BMSoT: Looks exactly the same...\n",
    "tstnet2 = mya2cnet.A2CNetwork(33, 4).to(device) #FA; BMSoT: ...like without stacks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FA; BMSoT: OBSOLETE\n",
    "#for (dc, st) in enumerate(states):\n",
    "\n",
    "\n",
    "\n",
    "# pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "    \n",
    "#a1,b1 = tstnet1.forward(torch.tensor(states, dtype=torch.float, device=device))\n",
    "#a2,b2 = tstnet2.forward(torch.tensor(states).to(device))\n",
    "\n",
    "#print(f'Dist. Actor stacks 1-2: {torch.dist(a1, a2)}'.ljust(50) + ' # ' +\\\n",
    "#     f'Dist. Actor 1 stacks - Notebook stacks {torch.dist(a1, a)}'.rjust(50))\n",
    "#print(f'Dist. Critic stacks 1-2: {torch.dist(b1, b2)}'.ljust(50) + ' # ' +\\\n",
    "#     f'Dist. Critic 1 stacks - Notebook stacks {torch.dist(b1, b)}'.rjust(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next(tstnet1.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next(tstnet2.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FA; BMSoT: OBSOLETE\n",
    "#for (dc, st) in enumerate(states):\n",
    "#    print(f'({dc+1}) -> {tstnet1.fullpass(st)}')\n",
    "    \n",
    "#tstnet1.fullpass( torch.tensor(states, device = device, dtype = torch.float) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FA; BMSoT: OBSOLETE\n",
    "#for (dc, st) in enumerate(states):\n",
    "#    print(f'({dc+1})-> {tstnet1.select_action(st)}') #, end=' ')\n",
    "    \n",
    "#tstnet1.select_action(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the agent instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mya2cagent\n",
    "\n",
    "# Thx2: https://emacs.stackexchange.com/a/13483\n",
    "import imp\n",
    "imp.reload(mya2cagent)\n",
    "\n",
    "agent = mya2cagent.a2cagent(len(env_info.agents), env, brain, max_steps = 500, max_n_steps = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --> Actions:\n",
      "mean: 0.018259049152105748 sdev: 0.07094505470037758\n",
      "Training iteration: 1            last optimization: 0+ --> Actions:\n",
      "mean: 0.01825372022181406 sdev: 0.07096932655250542\n",
      "Training iteration: 2            last optimization: 0# --> Actions:\n",
      "mean: 0.018247686645869465 sdev: 0.07098687674324228\n",
      "Training iteration: 3            last optimization: 0+ --> Actions:\n",
      "mean: 0.018240053739600658 sdev: 0.07099738561178393\n",
      "Training iteration: 4            last optimization: 0# --> Actions:\n",
      "mean: 0.018233294376840917 sdev: 0.07099938421605297\n",
      "Training iteration: 5            last optimization: 0+ --> Actions:\n",
      "mean: 0.018227044948380455 sdev: 0.07099358442143934\n",
      "Training iteration: 6            last optimization: 0# --> Actions:\n",
      "mean: 0.01822013002126196 sdev: 0.0709828867211453\n",
      "Training iteration: 7            last optimization: 0+ --> Actions:\n",
      "mean: 0.018213339610558828 sdev: 0.0709692533062134\n",
      "Training iteration: 8            last optimization: 0# --> Actions:\n",
      "mean: 0.018205339082850693 sdev: 0.07095669943011411\n",
      "Training iteration: 9            last optimization: 0+ --> Actions:\n",
      "mean: 0.018195453764353227 sdev: 0.07094712912375023\n",
      "Training iteration: 10            last optimization: 0# --> Actions:\n",
      "mean: 0.018183944787518252 sdev: 0.07094067485155242\n",
      "Training iteration: 11            last optimization: 0+ --> Actions:\n",
      "mean: 0.018171361856471023 sdev: 0.07093753700693506\n",
      "Training iteration: 12            last optimization: 0# --> Actions:\n",
      "mean: 0.018158439759825933 sdev: 0.07093667292384877\n",
      "Training iteration: 13            last optimization: 0+ --> Actions:\n",
      "mean: 0.018145481330994518 sdev: 0.07093711317269047\n",
      "Training iteration: 14            last optimization: 0# --> Actions:\n",
      "mean: 0.018133138246918687 sdev: 0.07093920767399539\n",
      "Training iteration: 15            last optimization: 0+ --> Actions:\n",
      "mean: 0.018121374445036136 sdev: 0.07094175606435188\n",
      "Training iteration: 16            last optimization: 0# --> Actions:\n",
      "mean: 0.018109470427299528 sdev: 0.0709455569591641\n",
      "Training iteration: 17            last optimization: 0+ --> Actions:\n",
      "mean: 0.018097616584500483 sdev: 0.07095114876477658\n",
      "Training iteration: 18            last optimization: 0# --> Actions:\n",
      "mean: 0.018088052685970534 sdev: 0.07095653170254199\n",
      "Training iteration: 19            last optimization: 0+ --> Actions:\n",
      "mean: 0.018078080593571254 sdev: 0.07096257157768426\n",
      "Training iteration: 20            last optimization: 0# --> Actions:\n",
      "mean: 0.01807062613975554 sdev: 0.07096675727122756\n",
      "Training iteration: 21            last optimization: 0+ --> Actions:\n",
      "mean: 0.018065369615170725 sdev: 0.07096803149113373\n",
      "Training iteration: 22            last optimization: 0# --> Actions:\n",
      "mean: 0.018061614721493115 sdev: 0.07096658626338798\n",
      "Training iteration: 23            last optimization: 0+ --> Actions:\n",
      "mean: 0.018060970274499367 sdev: 0.07096219661343406\n",
      "Training iteration: 24            last optimization: 0# --> Actions:\n",
      "mean: 0.01806547380296447 sdev: 0.0709553510804015\n",
      "Training iteration: 25            last optimization: 0+ --> Actions:\n",
      "mean: 0.018074657928929788 sdev: 0.07094393497497967\n",
      "Training iteration: 26            last optimization: 0# --> Actions:\n",
      "mean: 0.01808656464179612 sdev: 0.07093084471709642\n",
      "Training iteration: 27            last optimization: 0+ --> Actions:\n",
      "mean: 0.018100491176868103 sdev: 0.0709169421877813\n",
      "Training iteration: 28            last optimization: 0# --> Actions:\n",
      "mean: 0.018115104721330093 sdev: 0.07090216712408026\n",
      "Training iteration: 29            last optimization: 0+ --> Actions:\n",
      "mean: 0.018128772838295216 sdev: 0.07089321427429884\n",
      "Training iteration: 30            last optimization: 0# --> Actions:\n",
      "mean: 0.018139071064603364 sdev: 0.07089343570770733\n",
      "Training iteration: 31            last optimization: 0+ --> Actions:\n",
      "mean: 0.018145612121643152 sdev: 0.07090326954991721\n",
      "Training iteration: 32            last optimization: 0# --> Actions:\n",
      "mean: 0.01814885626381778 sdev: 0.0709176166621446\n",
      "Training iteration: 33            last optimization: 0+ --> Actions:\n",
      "mean: 0.01814747534286594 sdev: 0.07093632290452118\n",
      "Training iteration: 34            last optimization: 0# --> Actions:\n",
      "mean: 0.018141808061454014 sdev: 0.07095707671412901\n",
      "Training iteration: 35            last optimization: 0+ --> Actions:\n",
      "mean: 0.01813431477101892 sdev: 0.07097542234142602\n",
      "Training iteration: 36            last optimization: 0# --> Actions:\n",
      "mean: 0.018128090843680205 sdev: 0.0709864657939994\n",
      "Training iteration: 37            last optimization: 0+ --> Actions:\n",
      "mean: 0.018123868573760527 sdev: 0.07099031877287702\n",
      "Training iteration: 38            last optimization: 0# --> Actions:\n",
      "mean: 0.018119371033336093 sdev: 0.07098777257876274\n",
      "Training iteration: 39            last optimization: 0+ --> Actions:\n",
      "mean: 0.018113162738746205 sdev: 0.07097848953938356\n",
      "Training iteration: 40            last optimization: 0# --> Actions:\n",
      "mean: 0.01810519383631216 sdev: 0.07096586910023732\n",
      "Training iteration: 41            last optimization: 0+ --> Actions:\n",
      "mean: 0.01809540602405954 sdev: 0.07095252073115117\n",
      "Training iteration: 42            last optimization: 0# --> Actions:\n",
      "mean: 0.018085528550346598 sdev: 0.07093948023660368\n",
      "Training iteration: 43            last optimization: 0+ --> Actions:\n",
      "mean: 0.01807259424441595 sdev: 0.07093013670400798\n",
      "Training iteration: 44            last optimization: 0# --> Actions:\n",
      "mean: 0.01805883243328206 sdev: 0.07092562435062584\n",
      "Training iteration: 45            last optimization: 0+ --> Actions:\n",
      "mean: 0.018044669648541293 sdev: 0.07092427510446261\n",
      "Training iteration: 46            last optimization: 0# --> Actions:\n",
      "mean: 0.018032530040474355 sdev: 0.07092527915890176\n",
      "Training iteration: 47            last optimization: 0+ --> Actions:\n",
      "mean: 0.018022413855936607 sdev: 0.07092815412658746\n",
      "Training iteration: 48            last optimization: 0# --> Actions:\n",
      "mean: 0.018013601142743217 sdev: 0.07093393414692838\n",
      "Training iteration: 49            last optimization: 0+ --> Actions:\n",
      "mean: 0.018004809080315792 sdev: 0.07094210191356229\n",
      "Training iteration: 50            last optimization: 0# --> Actions:\n",
      "mean: 0.017996813076023157 sdev: 0.07095178608169618\n",
      "Training iteration: 51            last optimization: 0+ --> Actions:\n",
      "mean: 0.01799125876209274 sdev: 0.07096190475231433\n",
      "Training iteration: 52            last optimization: 0# --> Actions:\n",
      "mean: 0.01798769112330799 sdev: 0.07097228976392163\n",
      "Training iteration: 53            last optimization: 0+ --> Actions:\n",
      "mean: 0.01798694008330753 sdev: 0.07098244401549646\n",
      "Training iteration: 54            last optimization: 0# --> Actions:\n",
      "mean: 0.017987991554206058 sdev: 0.0709916318277047\n",
      "Training iteration: 55            last optimization: 0+ --> Actions:\n",
      "mean: 0.017991491820879703 sdev: 0.07099977047656206\n",
      "Training iteration: 56            last optimization: 0# --> Actions:\n",
      "mean: 0.0179989790710156 sdev: 0.07100414863614543\n",
      "Training iteration: 57            last optimization: 0+ --> Actions:\n",
      "mean: 0.018009380051907355 sdev: 0.07100399797791442\n",
      "Training iteration: 58            last optimization: 0# --> Actions:\n",
      "mean: 0.018022573848303407 sdev: 0.07100020345934074\n",
      "Training iteration: 59            last optimization: 0+ --> Actions:\n",
      "mean: 0.01803855165766561 sdev: 0.07099333186277398\n",
      "Training iteration: 60            last optimization: 0# --> Actions:\n",
      "mean: 0.018056428462870474 sdev: 0.07098283410193618\n",
      "Training iteration: 61            last optimization: 0+ --> Actions:\n",
      "mean: 0.018075138329034533 sdev: 0.07097137844469968\n",
      "Training iteration: 62            last optimization: 0# --> Actions:\n",
      "mean: 0.018092992502278585 sdev: 0.07096153937672783\n",
      "Training iteration: 63            last optimization: 0+ --> Actions:\n",
      "mean: 0.01810878034723528 sdev: 0.0709573392754249\n",
      "Training iteration: 64            last optimization: 0# --> Actions:\n",
      "mean: 0.018122245630547325 sdev: 0.0709599273535611\n",
      "Training iteration: 65            last optimization: 0+ --> Actions:\n",
      "mean: 0.01813467689333998 sdev: 0.07096824331723872\n",
      "Training iteration: 66            last optimization: 0# --> Actions:\n",
      "mean: 0.018144353977565968 sdev: 0.07098130790373974\n",
      "Training iteration: 67            last optimization: 0+ --> Actions:\n",
      "mean: 0.01814948943420516 sdev: 0.07099763012900831\n",
      "Training iteration: 68            last optimization: 0# --> Actions:\n",
      "mean: 0.018150746915639566 sdev: 0.07101629582249705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration: 69            last optimization: 0+ --> Actions:\n",
      "mean: 0.018151375349339798 sdev: 0.07103251816630118\n",
      "Training iteration: 70            last optimization: 0# --> Actions:\n",
      "mean: 0.018153301963403624 sdev: 0.07103902877396293\n",
      "Training iteration: 71            last optimization: 0+ --> Actions:\n",
      "mean: 0.018158159205159684 sdev: 0.07103673193439547\n",
      "Training iteration: 72            last optimization: 0# --> Actions:\n",
      "mean: 0.018165646842032944 sdev: 0.07102631154504316\n",
      "Training iteration: 73            last optimization: 0+ --> Actions:\n",
      "mean: 0.018171987452889483 sdev: 0.0710097799357123\n",
      "Training iteration: 74            last optimization: 0# --> Actions:\n",
      "mean: 0.018176542125442823 sdev: 0.07099273851203244\n",
      "Training iteration: 75            last optimization: 0+ --> Actions:\n",
      "mean: 0.018179898596731782 sdev: 0.07097787750827914\n",
      "Training iteration: 76            last optimization: 0# --> Actions:\n",
      "mean: 0.018179691126526985 sdev: 0.07096543413919101\n",
      "Training iteration: 77            last optimization: 0+ --> Actions:\n",
      "mean: 0.01817702438325821 sdev: 0.0709555511170627\n",
      "Training iteration: 78            last optimization: 0# --> Actions:\n",
      "mean: 0.018172266339737744 sdev: 0.07094745484489871\n",
      "Training iteration: 79            last optimization: 0+ --> Actions:\n",
      "mean: 0.018164834195450442 sdev: 0.07094323871822598\n",
      "Training iteration: 80            last optimization: 0# --> Actions:\n",
      "mean: 0.018156312303797655 sdev: 0.07094161550870351\n",
      "Training iteration: 81            last optimization: 0+ --> Actions:\n",
      "mean: 0.018148587145330363 sdev: 0.07094102063760362\n",
      "Training iteration: 82            last optimization: 0# --> Actions:\n",
      "mean: 0.018141361668638056 sdev: 0.0709401921028308\n",
      "Training iteration: 83            last optimization: 0+ --> Actions:\n",
      "mean: 0.018135579361544973 sdev: 0.07093921953136602\n",
      "Training iteration: 84            last optimization: 0# --> Actions:\n",
      "mean: 0.018131800113588545 sdev: 0.0709372568030219\n",
      "Training iteration: 85            last optimization: 0+ --> Actions:\n",
      "mean: 0.018126943404445924 sdev: 0.07093640025904416\n",
      "Training iteration: 86            last optimization: 0# --> Actions:\n",
      "mean: 0.018120478645158 sdev: 0.0709363652856752\n",
      "Training iteration: 87            last optimization: 0+ --> Actions:\n",
      "mean: 0.018114348557574496 sdev: 0.07093607108837735\n",
      "Training iteration: 88            last optimization: 0# --> Actions:\n",
      "mean: 0.0181104548210965 sdev: 0.07093432697011529\n",
      "Training iteration: 89            last optimization: 0+ --> Actions:\n",
      "mean: 0.01810904528865875 sdev: 0.0709302375629425\n",
      "Training iteration: 90            last optimization: 0# --> Actions:\n",
      "mean: 0.01811060831765381 sdev: 0.07092299330271887\n",
      "Training iteration: 91            last optimization: 0+ --> Actions:\n",
      "mean: 0.018115915098082868 sdev: 0.07091314236602732\n",
      "Training iteration: 92            last optimization: 0# --> Actions:\n",
      "mean: 0.018125181119171475 sdev: 0.07090059677392596\n",
      "Training iteration: 93            last optimization: 0+ --> Actions:\n",
      "mean: 0.01813747111771347 sdev: 0.07088476203573406\n",
      "Training iteration: 94            last optimization: 0# --> Actions:\n",
      "mean: 0.018150700283818596 sdev: 0.07086842179536254\n",
      "Training iteration: 95            last optimization: 0+ --> Actions:\n",
      "mean: 0.018163795827738048 sdev: 0.07085595634904109\n",
      "Training iteration: 96            last optimization: 0# --> Actions:\n",
      "mean: 0.018174734274893196 sdev: 0.07084846343729594\n",
      "Training iteration: 97            last optimization: 0+ --> Actions:\n",
      "mean: 0.018183959383989153 sdev: 0.07084679653408671\n",
      "Training iteration: 98            last optimization: 0# --> Actions:\n",
      "mean: 0.0181896247911106 sdev: 0.07085229808309824\n",
      "Training iteration: 99            last optimization: 0+ --> Actions:\n",
      "mean: 0.018193594024631405 sdev: 0.07086331405366221\n",
      "Training iteration: 100          last optimization: 100# --> Actions:\n",
      "mean: 0.024122455338548156 sdev: 0.057429449946005004\n",
      "Training iteration: 101          last optimization: 100+ --> Actions:\n",
      "mean: 0.024112262961889154 sdev: 0.05743004090552713\n",
      "Training iteration: 102          last optimization: 100# --> Actions:\n",
      "mean: 0.024101236677424146 sdev: 0.05743058190058917\n",
      "Training iteration: 103          last optimization: 100+ --> Actions:\n",
      "mean: 0.024089102611708265 sdev: 0.05742900386718382\n",
      "Training iteration: 104          last optimization: 100# --> Actions:\n",
      "mean: 0.024077103879638143 sdev: 0.05742425067244177\n",
      "Training iteration: 105          last optimization: 100+ --> Actions:\n",
      "mean: 0.02406614724477269 sdev: 0.05741639645788507\n",
      "Training iteration: 106          last optimization: 100# --> Actions:\n",
      "mean: 0.024055203446935375 sdev: 0.05740661097985061\n",
      "Training iteration: 107          last optimization: 100+ --> Actions:\n",
      "mean: 0.02404414469462088 sdev: 0.05739554577129035\n",
      "Training iteration: 108          last optimization: 100# --> Actions:\n",
      "mean: 0.024034831892160966 sdev: 0.05738478393502262\n",
      "Training iteration: 109          last optimization: 100+ --> Actions:\n",
      "mean: 0.02402365958905672 sdev: 0.057374792216968284\n",
      "Training iteration: 110          last optimization: 100# --> Actions:\n",
      "mean: 0.02401220357311412 sdev: 0.05736599647287274\n",
      "Training iteration: 111          last optimization: 100+ --> Actions:\n",
      "mean: 0.02400183089876213 sdev: 0.05735903541335958\n",
      "Training iteration: 112          last optimization: 100# --> Actions:\n",
      "mean: 0.023992958336839763 sdev: 0.05735254963627871\n",
      "Training iteration: 113          last optimization: 100+ --> Actions:\n",
      "mean: 0.023983920736294226 sdev: 0.05734773335020863\n",
      "Training iteration: 114          last optimization: 100# --> Actions:\n",
      "mean: 0.023975584701085056 sdev: 0.05734591270641296\n",
      "Training iteration: 115          last optimization: 100+ --> Actions:\n",
      "mean: 0.023969455392112662 sdev: 0.05734451802439659\n",
      "Training iteration: 116          last optimization: 100# --> Actions:\n",
      "mean: 0.023964802319330552 sdev: 0.057344631214887636\n",
      "Training iteration: 117          last optimization: 100+ --> Actions:\n",
      "mean: 0.02395996694149913 sdev: 0.057346370996640604\n",
      "Training iteration: 118          last optimization: 100# --> Actions:\n",
      "mean: 0.023957225231806403 sdev: 0.057348094516717234\n",
      "Training iteration: 119          last optimization: 100+ --> Actions:\n",
      "mean: 0.023956000794220438 sdev: 0.05735119284477603\n",
      "Training iteration: 120          last optimization: 100# --> Actions:\n",
      "mean: 0.023955734998359974 sdev: 0.05735589595251509\n",
      "Training iteration: 121          last optimization: 100+ --> Actions:\n",
      "mean: 0.0239563909195346 sdev: 0.05736030260082939\n",
      "Training iteration: 122          last optimization: 100# --> Actions:\n",
      "mean: 0.023960030563397676 sdev: 0.05736342875971547\n",
      "Training iteration: 123          last optimization: 100+ --> Actions:\n",
      "mean: 0.023966806062826494 sdev: 0.05736482947119137\n",
      "Training iteration: 124          last optimization: 100# --> Actions:\n",
      "mean: 0.02397713921939259 sdev: 0.057364667875114995\n",
      "Training iteration: 125          last optimization: 100+ --> Actions:\n",
      "mean: 0.023989674865262607 sdev: 0.05736386232543257\n",
      "Training iteration: 126          last optimization: 100# --> Actions:\n",
      "mean: 0.024003608682694105 sdev: 0.05736223014437129\n",
      "Training iteration: 127          last optimization: 100+ --> Actions:\n",
      "mean: 0.024017328803341582 sdev: 0.05735978291834516\n",
      "Training iteration: 128          last optimization: 100# --> Actions:\n",
      "mean: 0.024030042161945105 sdev: 0.057358573059650524\n",
      "Training iteration: 129          last optimization: 100+ --> Actions:\n",
      "mean: 0.024041219201304368 sdev: 0.057359129836356375\n",
      "Training iteration: 130          last optimization: 100# --> Actions:\n",
      "mean: 0.024050238637810247 sdev: 0.05736129239213147\n",
      "Training iteration: 131          last optimization: 100+ --> Actions:\n",
      "mean: 0.02405805115508363 sdev: 0.057365656905087804\n",
      "Training iteration: 132          last optimization: 100# --> Actions:\n",
      "mean: 0.024063788673511943 sdev: 0.057369944440924824\n",
      "Training iteration: 133          last optimization: 100+ --> Actions:\n",
      "mean: 0.02406815330927597 sdev: 0.057374093423971456\n",
      "Training iteration: 134          last optimization: 100# --> Actions:\n",
      "mean: 0.024072291273420164 sdev: 0.05737765328884006\n",
      "Training iteration: 135          last optimization: 100+ --> Actions:\n",
      "mean: 0.02407799636686764 sdev: 0.05737897349941902\n",
      "Training iteration: 136          last optimization: 100# --> Actions:\n",
      "mean: 0.024085511199744197 sdev: 0.0573781442082316\n",
      "Training iteration: 137          last optimization: 100+ --> Actions:\n",
      "mean: 0.024092997595959523 sdev: 0.05737506631402528\n",
      "Training iteration: 138          last optimization: 100# --> Actions:\n",
      "mean: 0.02410030431813543 sdev: 0.057370229286139475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration: 139          last optimization: 100+ --> Actions:\n",
      "mean: 0.024106291686118518 sdev: 0.057365272712061544\n",
      "Training iteration: 140          last optimization: 100# --> Actions:\n",
      "mean: 0.024110724083350417 sdev: 0.057360506115064124\n",
      "Training iteration: 141          last optimization: 100+ --> Actions:\n",
      "mean: 0.02411449547313963 sdev: 0.057357519097861354\n",
      "Training iteration: 142          last optimization: 100# --> Actions:\n",
      "mean: 0.024117190456826164 sdev: 0.05735580967970884\n",
      "Training iteration: 143          last optimization: 100+ --> Actions:\n",
      "mean: 0.024118705857874588 sdev: 0.05735591207515842\n",
      "Training iteration: 144          last optimization: 100# --> Actions:\n",
      "mean: 0.02411911729399177 sdev: 0.05735860466893426\n",
      "Training iteration: 145          last optimization: 100+ --> Actions:\n",
      "mean: 0.024118540913101248 sdev: 0.057364007924196575\n",
      "Training iteration: 146          last optimization: 100# --> Actions:\n",
      "mean: 0.024117563955987697 sdev: 0.05737054800521498\n",
      "Training iteration: 147          last optimization: 100+ --> Actions:\n",
      "mean: 0.024117059791366698 sdev: 0.05737753131774758\n",
      "Training iteration: 148          last optimization: 100# --> Actions:\n",
      "mean: 0.024117505641506037 sdev: 0.05738633384852796\n",
      "Training iteration: 149          last optimization: 100+ --> Actions:\n",
      "mean: 0.02411853129343993 sdev: 0.057396429032308294\n",
      "Training iteration: 150          last optimization: 100# --> Actions:\n",
      "mean: 0.02412066127682976 sdev: 0.057405428908072306\n",
      "Training iteration: 151          last optimization: 100+ --> Actions:\n",
      "mean: 0.024123639249295687 sdev: 0.057411796936898615\n",
      "Training iteration: 152          last optimization: 100# --> Actions:\n",
      "mean: 0.02412813675136353 sdev: 0.05741744680711664\n",
      "Training iteration: 153          last optimization: 100+ --> Actions:\n",
      "mean: 0.02413398745735857 sdev: 0.05742215432391997\n",
      "Training iteration: 154          last optimization: 100# --> Actions:\n",
      "mean: 0.02414078891861098 sdev: 0.05742492534322114\n",
      "Training iteration: 155          last optimization: 100+ --> Actions:\n",
      "mean: 0.024150734544194738 sdev: 0.057426241587729354\n",
      "Training iteration: 156          last optimization: 100# --> Actions:\n",
      "mean: 0.024160518942695247 sdev: 0.05742720220966301\n",
      "Training iteration: 157          last optimization: 100+ --> Actions:\n",
      "mean: 0.02417184291240086 sdev: 0.057425488304868315\n",
      "Training iteration: 158          last optimization: 100# --> Actions:\n",
      "mean: 0.02418527967049631 sdev: 0.057422311702508125\n",
      "Training iteration: 159          last optimization: 100+ --> Actions:\n",
      "mean: 0.024198964638414668 sdev: 0.05741923821116219\n",
      "Training iteration: 160          last optimization: 100# --> Actions:\n",
      "mean: 0.024211459268606857 sdev: 0.05741696745870701\n",
      "Training iteration: 161          last optimization: 100+ --> Actions:\n",
      "mean: 0.024220881318515786 sdev: 0.057417585894740525\n",
      "Training iteration: 162          last optimization: 100# --> Actions:\n",
      "mean: 0.024226322423941717 sdev: 0.05741926655972701\n",
      "Training iteration: 163          last optimization: 100+ --> Actions:\n",
      "mean: 0.024229681703440604 sdev: 0.05742123323451132\n",
      "Training iteration: 164          last optimization: 100# --> Actions:\n",
      "mean: 0.024231921700079158 sdev: 0.05742096154241861\n",
      "Training iteration: 165          last optimization: 100+ --> Actions:\n",
      "mean: 0.024234284322054916 sdev: 0.05741880457125697\n",
      "Training iteration: 166          last optimization: 100# --> Actions:\n",
      "mean: 0.024235877127674315 sdev: 0.057415375057826325\n",
      "Training iteration: 167          last optimization: 100+ --> Actions:\n",
      "mean: 0.02423690084562671 sdev: 0.05741021624151679\n",
      "Training iteration: 168          last optimization: 100# --> Actions:\n",
      "mean: 0.024236154329084218 sdev: 0.05740341719864492\n",
      "Training iteration: 169          last optimization: 100+ --> Actions:\n",
      "mean: 0.02423386909742497 sdev: 0.05739633691248336\n",
      "Training iteration: 170          last optimization: 100# --> Actions:\n",
      "mean: 0.02422989979859816 sdev: 0.057388422000193076\n",
      "Training iteration: 171          last optimization: 100+ --> Actions:\n",
      "mean: 0.024224300752359894 sdev: 0.05738061339469454\n",
      "Training iteration: 172          last optimization: 100# --> Actions:\n",
      "mean: 0.024217372678278892 sdev: 0.05737378706415879\n",
      "Training iteration: 173          last optimization: 100+ --> Actions:\n",
      "mean: 0.02420944083760515 sdev: 0.05736775033433922\n",
      "Training iteration: 174          last optimization: 100# --> Actions:\n",
      "mean: 0.024202715774672014 sdev: 0.057363522235663406\n",
      "Training iteration: 175          last optimization: 100+ --> Actions:\n",
      "mean: 0.024196115383328682 sdev: 0.057360214128172174\n",
      "Training iteration: 176          last optimization: 100# --> Actions:\n",
      "mean: 0.02418874490179266 sdev: 0.057358215500975515\n",
      "Training iteration: 177          last optimization: 100+ --> Actions:\n",
      "mean: 0.024181906883136935 sdev: 0.05735718374901975\n",
      "Training iteration: 178          last optimization: 100# --> Actions:\n",
      "mean: 0.02417374187922746 sdev: 0.05735790683354363\n",
      "Training iteration: 179          last optimization: 100+ --> Actions:\n",
      "mean: 0.024163877103921594 sdev: 0.057358785006386664\n",
      "Training iteration: 180          last optimization: 100# --> Actions:\n",
      "mean: 0.02415381878481037 sdev: 0.05735993051977642\n",
      "Training iteration: 181          last optimization: 100+ --> Actions:\n",
      "mean: 0.02414445579845604 sdev: 0.057361428455546995\n",
      "Training iteration: 182          last optimization: 100# --> Actions:\n",
      "mean: 0.024136036445575552 sdev: 0.05736474476224547\n",
      "Training iteration: 183          last optimization: 100+ --> Actions:\n",
      "mean: 0.024128957418202167 sdev: 0.057369209722152543\n",
      "Training iteration: 184          last optimization: 100# --> Actions:\n",
      "mean: 0.02412345709763914 sdev: 0.057371919447882336\n",
      "Training iteration: 185          last optimization: 100+ --> Actions:\n",
      "mean: 0.02412050540074046 sdev: 0.05737406601767952\n",
      "Training iteration: 186          last optimization: 100# --> Actions:\n",
      "mean: 0.0241197912450751 sdev: 0.05737497002001653\n",
      "Training iteration: 187          last optimization: 100+ --> Actions:\n",
      "mean: 0.024119490417905516 sdev: 0.05737603142267941\n",
      "Training iteration: 188          last optimization: 100# --> Actions:\n",
      "mean: 0.024121101698975342 sdev: 0.0573759447972111\n",
      "Training iteration: 189          last optimization: 100+ --> Actions:\n",
      "mean: 0.024124025026343525 sdev: 0.05737592611234737\n",
      "Training iteration: 190          last optimization: 100# --> Actions:\n",
      "mean: 0.024127680131593325 sdev: 0.05737515661840092\n",
      "Training iteration: 191          last optimization: 100+ --> Actions:\n",
      "mean: 0.024129868662317956 sdev: 0.0573744776795852\n",
      "Training iteration: 192          last optimization: 100# --> Actions:\n",
      "mean: 0.024129204615278767 sdev: 0.05737474656754675\n",
      "Training iteration: 193          last optimization: 100+ --> Actions:\n",
      "mean: 0.02412529296094391 sdev: 0.0573774617341878\n",
      "Training iteration: 194          last optimization: 100# --> Actions:\n",
      "mean: 0.024118056158826208 sdev: 0.05738056160926589\n",
      "Training iteration: 195          last optimization: 100+ --> Actions:\n",
      "mean: 0.02410902133117786 sdev: 0.05738423810375658\n",
      "Training iteration: 196          last optimization: 100# --> Actions:\n",
      "mean: 0.024098649308929007 sdev: 0.05738955968058604\n",
      "Training iteration: 197          last optimization: 100+ --> Actions:\n",
      "mean: 0.024086860012257388 sdev: 0.05739396475023455\n",
      "Training iteration: 198          last optimization: 100# --> Actions:\n",
      "mean: 0.024075522679643253 sdev: 0.057396840377191304\n",
      "Training iteration: 199          last optimization: 100+ --> Actions:\n",
      "mean: 0.024063558724686233 sdev: 0.05739687879297155\n",
      "Training iteration: 200          last optimization: 200# --> Actions:\n",
      "mean: 0.030684638260883367 sdev: 0.04357701229278594\n",
      "Training iteration: 201          last optimization: 200+ --> Actions:\n",
      "mean: 0.030672033292277544 sdev: 0.043567255420943696\n",
      "Training iteration: 202          last optimization: 200# --> Actions:\n",
      "mean: 0.030660468090782038 sdev: 0.04355599808164007\n",
      "Training iteration: 203          last optimization: 200+ --> Actions:\n",
      "mean: 0.030647777851295917 sdev: 0.04354514110570216\n",
      "Training iteration: 204          last optimization: 200# --> Actions:\n",
      "mean: 0.0306348091995395 sdev: 0.04353497072496364\n",
      "Training iteration: 205          last optimization: 200+ --> Actions:\n",
      "mean: 0.030622609084598146 sdev: 0.04352590908420124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration: 206          last optimization: 200# --> Actions:\n",
      "mean: 0.030610831437623866 sdev: 0.04351800963407226\n",
      "Training iteration: 207          last optimization: 200+ --> Actions:\n",
      "mean: 0.030600630261725964 sdev: 0.04351195010494295\n",
      "Training iteration: 208          last optimization: 200# --> Actions:\n",
      "mean: 0.03059063593774906 sdev: 0.04350911217877111\n",
      "Training iteration: 209          last optimization: 200+ --> Actions:\n",
      "mean: 0.030580500457621416 sdev: 0.04350751585585413\n",
      "Training iteration: 210          last optimization: 200# --> Actions:\n",
      "mean: 0.030569824170499638 sdev: 0.043507594219729266\n",
      "Training iteration: 211          last optimization: 200+ --> Actions:\n",
      "mean: 0.030560733644043724 sdev: 0.04350884721713815\n",
      "Training iteration: 212          last optimization: 200# --> Actions:\n",
      "mean: 0.030554534805403672 sdev: 0.04351023079965511\n",
      "Training iteration: 213          last optimization: 200+ --> Actions:\n",
      "mean: 0.0305495157239973 sdev: 0.04351137977483283\n",
      "Training iteration: 214          last optimization: 200# --> Actions:\n",
      "mean: 0.030547625817895878 sdev: 0.04351223134523332\n",
      "Training iteration: 215          last optimization: 200+ --> Actions:\n",
      "mean: 0.030548077161553805 sdev: 0.04351281143530356\n",
      "Training iteration: 216          last optimization: 200# --> Actions:\n",
      "mean: 0.030549901859618082 sdev: 0.0435129522738178\n",
      "Training iteration: 217          last optimization: 200+ --> Actions:\n",
      "mean: 0.03055322949990543 sdev: 0.04351241661427436\n",
      "Training iteration: 218          last optimization: 200# --> Actions:\n",
      "mean: 0.03055773019728115 sdev: 0.04351256214769464\n",
      "Training iteration: 219          last optimization: 200+ --> Actions:\n",
      "mean: 0.030561842838786206 sdev: 0.04351440841339958\n",
      "Training iteration: 220          last optimization: 200# --> Actions:\n",
      "mean: 0.030564061798575036 sdev: 0.043517282127356324\n",
      "Training iteration: 221          last optimization: 200+ --> Actions:\n",
      "mean: 0.030563487537419887 sdev: 0.043522825057938086\n",
      "Training iteration: 222          last optimization: 200# --> Actions:\n",
      "mean: 0.030559257993283594 sdev: 0.0435308717417229\n",
      "Training iteration: 223          last optimization: 200+ --> Actions:\n",
      "mean: 0.030551694930995348 sdev: 0.04354067195051311\n",
      "Training iteration: 224          last optimization: 200# --> Actions:\n",
      "mean: 0.030540506732942136 sdev: 0.043551419595846255\n",
      "Training iteration: 225          last optimization: 200+ --> Actions:\n",
      "mean: 0.030527343442830368 sdev: 0.043563553830624865\n",
      "Training iteration: 226          last optimization: 200# --> Actions:\n",
      "mean: 0.030513421317415114 sdev: 0.0435743386846583\n",
      "Training iteration: 227          last optimization: 200+ --> Actions:\n",
      "mean: 0.030499876277000643 sdev: 0.04358168433588903\n",
      "Training iteration: 228          last optimization: 200# --> Actions:\n",
      "mean: 0.03048706473027953 sdev: 0.04358536307515173\n",
      "Training iteration: 229          last optimization: 200+ --> Actions:\n",
      "mean: 0.03047536654266379 sdev: 0.04358629933048641\n",
      "Training iteration: 230          last optimization: 200# --> Actions:\n",
      "mean: 0.030465936539540505 sdev: 0.04358428314067311\n",
      "Training iteration: 231          last optimization: 200+ --> Actions:\n",
      "mean: 0.030457870163174333 sdev: 0.04357991325620519\n",
      "Training iteration: 232          last optimization: 200# --> Actions:\n",
      "mean: 0.03045082567527585 sdev: 0.043573475194532696\n",
      "Training iteration: 233          last optimization: 200+ --> Actions:\n",
      "mean: 0.030443273433268823 sdev: 0.043565402876117314\n",
      "Training iteration: 234          last optimization: 200# --> Actions:\n",
      "mean: 0.030437066237259232 sdev: 0.04355763249415478\n",
      "Training iteration: 235          last optimization: 200+ --> Actions:\n",
      "mean: 0.030433264912611824 sdev: 0.04355042670893691\n",
      "Training iteration: 236          last optimization: 200# --> Actions:\n",
      "mean: 0.03042954401613473 sdev: 0.043544855883914095\n",
      "Training iteration: 237          last optimization: 200+ --> Actions:\n",
      "mean: 0.03042588946169562 sdev: 0.0435413736544396\n",
      "Training iteration: 238          last optimization: 200# --> Actions:\n",
      "mean: 0.030423628879801306 sdev: 0.04353902300408167\n",
      "Training iteration: 239          last optimization: 200+ --> Actions:\n",
      "mean: 0.03042191165107184 sdev: 0.043537338082574886\n",
      "Training iteration: 240          last optimization: 200# --> Actions:\n",
      "mean: 0.030422237102149897 sdev: 0.04353670208824789\n",
      "Training iteration: 241          last optimization: 200+ --> Actions:\n",
      "mean: 0.030425344162439378 sdev: 0.0435381463793438\n",
      "Training iteration: 242          last optimization: 200# --> Actions:\n",
      "mean: 0.030430878129834478 sdev: 0.04354015779971816\n",
      "Training iteration: 243          last optimization: 200+ --> Actions:\n",
      "mean: 0.030439606812788268 sdev: 0.04354134322354829\n",
      "Training iteration: 244          last optimization: 200# --> Actions:\n",
      "mean: 0.030451232060968576 sdev: 0.04354178580524588\n",
      "Training iteration: 245          last optimization: 200+ --> Actions:\n",
      "mean: 0.030463868645998038 sdev: 0.043542033172388556\n",
      "Training iteration: 246          last optimization: 200# --> Actions:\n",
      "mean: 0.030478641699565913 sdev: 0.043541966697760774\n",
      "Training iteration: 247          last optimization: 200+ --> Actions:\n",
      "mean: 0.03049454911850872 sdev: 0.04354214729616809\n",
      "Training iteration: 248          last optimization: 200# --> Actions:\n",
      "mean: 0.030510931848133076 sdev: 0.04354232171331561\n",
      "Training iteration: 249          last optimization: 200+ --> Actions:\n",
      "mean: 0.03052790141348074 sdev: 0.043542150801703455\n",
      "Training iteration: 250          last optimization: 200# --> Actions:\n",
      "mean: 0.03054388809477297 sdev: 0.04354367114022309\n",
      "Training iteration: 251          last optimization: 200+ --> Actions:\n",
      "mean: 0.030557061306157634 sdev: 0.04354748310214813\n",
      "Training iteration: 252          last optimization: 200# --> Actions:\n",
      "mean: 0.030567209301783655 sdev: 0.04355258122915612\n",
      "Training iteration: 253          last optimization: 200+ --> Actions:\n",
      "mean: 0.030573694452377686 sdev: 0.04355923574570395\n",
      "Training iteration: 254          last optimization: 200# --> Actions:\n",
      "mean: 0.03057665857657385 sdev: 0.04356768135359813\n",
      "Training iteration: 255          last optimization: 200+ --> Actions:\n",
      "mean: 0.030576927276261295 sdev: 0.043576168316112884\n",
      "Training iteration: 256          last optimization: 200# --> Actions:\n",
      "mean: 0.030575953681343682 sdev: 0.04358318458714505\n",
      "Training iteration: 257          last optimization: 200+ --> Actions:\n",
      "mean: 0.03057544022956208 sdev: 0.04358695608826716\n",
      "Training iteration: 258          last optimization: 200# --> Actions:\n",
      "mean: 0.030575299811240176 sdev: 0.04358722594824001\n",
      "Training iteration: 259          last optimization: 200+ --> Actions:\n",
      "mean: 0.030575931909212643 sdev: 0.0435852298620372\n",
      "Training iteration: 260          last optimization: 200# --> Actions:\n",
      "mean: 0.030576964446292765 sdev: 0.0435806044684329\n",
      "Training iteration: 261          last optimization: 200+ --> Actions:\n",
      "mean: 0.030577852318813204 sdev: 0.04357299679431105\n",
      "Training iteration: 262          last optimization: 200# --> Actions:\n",
      "mean: 0.030578092578213256 sdev: 0.04356489478097944\n",
      "Training iteration: 263          last optimization: 200+ --> Actions:\n",
      "mean: 0.030577166259612237 sdev: 0.043555723932618355\n",
      "Training iteration: 264          last optimization: 200# --> Actions:\n",
      "mean: 0.030575478646080477 sdev: 0.04354675955061707\n",
      "Training iteration: 265          last optimization: 200+ --> Actions:\n",
      "mean: 0.0305750673256542 sdev: 0.04353881309053287\n",
      "Training iteration: 266          last optimization: 200# --> Actions:\n",
      "mean: 0.030573813323439114 sdev: 0.043532824151000744\n",
      "Training iteration: 267          last optimization: 200+ --> Actions:\n",
      "mean: 0.0305726205144355 sdev: 0.043527963327178266\n",
      "Training iteration: 268          last optimization: 200# --> Actions:\n",
      "mean: 0.030571673169181614 sdev: 0.04352482359396881\n",
      "Training iteration: 269          last optimization: 200+ --> Actions:\n",
      "mean: 0.03057105361747604 sdev: 0.043523971622437575\n",
      "Training iteration: 270          last optimization: 200# --> Actions:\n",
      "mean: 0.03057248871418116 sdev: 0.04352450157161133\n",
      "Training iteration: 271          last optimization: 200+ --> Actions:\n",
      "mean: 0.03057398858637243 sdev: 0.043526310556396046\n",
      "Training iteration: 272          last optimization: 200# --> Actions:\n",
      "mean: 0.03057600486793242 sdev: 0.04352896133088168\n",
      "Training iteration: 273          last optimization: 200+ --> Actions:\n",
      "mean: 0.030580925302617395 sdev: 0.04353200903920978\n",
      "Training iteration: 274          last optimization: 200# --> Actions:\n",
      "mean: 0.030589253819474534 sdev: 0.04353435091611714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration: 275          last optimization: 200+ --> Actions:\n",
      "mean: 0.03059893262345913 sdev: 0.04353719248494961\n",
      "Training iteration: 276          last optimization: 200# --> Actions:\n",
      "mean: 0.03061236523390547 sdev: 0.04353927569087552\n",
      "Training iteration: 277          last optimization: 200+ --> Actions:\n",
      "mean: 0.030627916367587042 sdev: 0.04354000997343241\n",
      "Training iteration: 278          last optimization: 200# --> Actions:\n",
      "mean: 0.030643474042188562 sdev: 0.04354009486401553\n",
      "Training iteration: 279          last optimization: 200+ --> Actions:\n",
      "mean: 0.030659198810887793 sdev: 0.04353943582311081\n",
      "Training iteration: 280          last optimization: 200# --> Actions:\n",
      "mean: 0.030674431038577005 sdev: 0.043539235627698486\n",
      "Training iteration: 281          last optimization: 200+ --> Actions:\n",
      "mean: 0.030687041312449165 sdev: 0.043540048988178925\n",
      "Training iteration: 282          last optimization: 200# --> Actions:\n",
      "mean: 0.030695024317603188 sdev: 0.04354204221991552\n",
      "Training iteration: 283          last optimization: 200+ --> Actions:\n",
      "mean: 0.030699146391311403 sdev: 0.043545883157424185\n",
      "Training iteration: 284          last optimization: 200# --> Actions:\n",
      "mean: 0.03069887710090542 sdev: 0.04355130734879257\n",
      "Training iteration: 285          last optimization: 200+ --> Actions:\n",
      "mean: 0.030695815163771373 sdev: 0.04355717697915481\n",
      "Training iteration: 286          last optimization: 200# --> Actions:\n",
      "mean: 0.03068910662296003 sdev: 0.04356339169128574\n",
      "Training iteration: 287          last optimization: 200+ --> Actions:\n",
      "mean: 0.03068129354473399 sdev: 0.043567777965183664\n",
      "Training iteration: 288          last optimization: 200# --> Actions:\n",
      "mean: 0.030671204763264803 sdev: 0.04357193021491957\n",
      "Training iteration: 289          last optimization: 200+ --> Actions:\n",
      "mean: 0.030660502744289962 sdev: 0.04357336051197312\n",
      "Training iteration: 290          last optimization: 200# --> Actions:\n",
      "mean: 0.030649901927467277 sdev: 0.043571051426101313\n",
      "Training iteration: 291          last optimization: 200+ --> Actions:\n",
      "mean: 0.03064086881129511 sdev: 0.04356576682628944\n",
      "Training iteration: 292          last optimization: 200# --> Actions:\n",
      "mean: 0.030632353373905637 sdev: 0.0435585917176764\n",
      "Training iteration: 293          last optimization: 200+ --> Actions:\n",
      "mean: 0.03062574354293542 sdev: 0.04355018434521631\n",
      "Training iteration: 294          last optimization: 200# --> Actions:\n",
      "mean: 0.030620130230335642 sdev: 0.043541195442965065\n",
      "Training iteration: 295          last optimization: 200+ --> Actions:\n",
      "mean: 0.030614623372555532 sdev: 0.04353290988317495\n",
      "Training iteration: 296          last optimization: 200# --> Actions:\n",
      "mean: 0.03060905463447282 sdev: 0.043526734353170775\n",
      "Training iteration: 297          last optimization: 200+ --> Actions:\n",
      "mean: 0.030602941636538317 sdev: 0.0435224657268337\n",
      "Training iteration: 298          last optimization: 200# --> Actions:\n",
      "mean: 0.030596657558858303 sdev: 0.043519411721549446\n",
      "Training iteration: 299          last optimization: 200+ --> Actions:\n",
      "mean: 0.030591703319956427 sdev: 0.04351759627123188\n",
      "Training iteration: 300          last optimization: 300# --> Actions:\n",
      "mean: 0.03778690731084727 sdev: 0.02922411200969195\n",
      "Training iteration: 301          last optimization: 300+ --> Actions:\n",
      "mean: 0.037778400681538635 sdev: 0.029229917281888187\n",
      "Training iteration: 302          last optimization: 300# --> Actions:\n",
      "mean: 0.037771583942418877 sdev: 0.02923739634934966\n",
      "Training iteration: 303          last optimization: 300+ --> Actions:\n",
      "mean: 0.03776564214930848 sdev: 0.029246674644609397\n",
      "Training iteration: 304          last optimization: 300# --> Actions:\n",
      "mean: 0.03776086010614737 sdev: 0.029257218315341716\n",
      "Training iteration: 305          last optimization: 300+ --> Actions:\n",
      "mean: 0.03775771719815149 sdev: 0.029267294646026863\n",
      "Training iteration: 306          last optimization: 300# --> Actions:\n",
      "mean: 0.03775620271902748 sdev: 0.029277519427986377\n",
      "Training iteration: 307          last optimization: 300+ --> Actions:\n",
      "mean: 0.03775688630034239 sdev: 0.029286588508836277\n",
      "Training iteration: 308          last optimization: 300# --> Actions:\n",
      "mean: 0.03775976203366904 sdev: 0.029294194421292975\n",
      "Training iteration: 309          last optimization: 300+ --> Actions:\n",
      "mean: 0.03776405658919761 sdev: 0.029299519713093747\n",
      "Training iteration: 310          last optimization: 300# --> Actions:\n",
      "mean: 0.03776836956359979 sdev: 0.02930238461699664\n",
      "Training iteration: 311          last optimization: 300+ --> Actions:\n",
      "mean: 0.03777138568043616 sdev: 0.029303575801225147\n",
      "Training iteration: 312          last optimization: 300# --> Actions:\n",
      "mean: 0.037772167867054784 sdev: 0.029303269649421215\n",
      "Training iteration: 313          last optimization: 300+ --> Actions:\n",
      "mean: 0.03777019834551193 sdev: 0.029302461071559923\n",
      "Training iteration: 314          last optimization: 300# --> Actions:\n",
      "mean: 0.03776665527966454 sdev: 0.029300331744412652\n",
      "Training iteration: 315          last optimization: 300+ --> Actions:\n",
      "mean: 0.037760246689022926 sdev: 0.02929755272824888\n",
      "Training iteration: 316          last optimization: 300# --> Actions:\n",
      "mean: 0.03775140360186618 sdev: 0.029294436149143163\n",
      "Training iteration: 317          last optimization: 300+ --> Actions:\n",
      "mean: 0.03774200232063056 sdev: 0.029289746751045186\n",
      "Training iteration: 318          last optimization: 300# --> Actions:\n",
      "mean: 0.037732463843828626 sdev: 0.029283404318360528\n",
      "Training iteration: 319          last optimization: 300+ --> Actions:\n",
      "mean: 0.03772356202044187 sdev: 0.029275747312427578\n",
      "Training iteration: 320          last optimization: 300# --> Actions:\n",
      "mean: 0.037716292559693755 sdev: 0.029266521347826993\n",
      "Training iteration: 321          last optimization: 300+ --> Actions:\n",
      "mean: 0.03770977541200225 sdev: 0.02925693295625184\n",
      "Training iteration: 322          last optimization: 300# --> Actions:\n",
      "mean: 0.03770327957942493 sdev: 0.029247370864116426\n",
      "Training iteration: 323          last optimization: 300+ --> Actions:\n",
      "mean: 0.0376965581070539 sdev: 0.029239217082361723\n",
      "Training iteration: 324          last optimization: 300# --> Actions:\n",
      "mean: 0.0376907047631788 sdev: 0.029232444210722727\n",
      "Training iteration: 325          last optimization: 300+ --> Actions:\n",
      "mean: 0.03768547174952568 sdev: 0.02922742729976216\n",
      "Training iteration: 326          last optimization: 300# --> Actions:\n",
      "mean: 0.037680643545639894 sdev: 0.02922489898820537\n",
      "Training iteration: 327          last optimization: 300+ --> Actions:\n",
      "mean: 0.037675450230118104 sdev: 0.02922532813901187\n",
      "Training iteration: 328          last optimization: 300# --> Actions:\n",
      "mean: 0.03766967695045738 sdev: 0.029228091983726796\n",
      "Training iteration: 329          last optimization: 300+ --> Actions:\n",
      "mean: 0.03766537316376669 sdev: 0.029233370833976587\n",
      "Training iteration: 330          last optimization: 300# --> Actions:\n",
      "mean: 0.03766077270880618 sdev: 0.029243223128265123\n",
      "Training iteration: 331          last optimization: 300+ --> Actions:\n",
      "mean: 0.03765511704824688 sdev: 0.029256739032489626\n",
      "Training iteration: 332          last optimization: 300# --> Actions:\n",
      "mean: 0.03765001598098557 sdev: 0.02927258244303815\n",
      "Training iteration: 333          last optimization: 300+ --> Actions:\n",
      "mean: 0.037647321884968846 sdev: 0.029289541296301423\n",
      "Training iteration: 334          last optimization: 300# --> Actions:\n",
      "mean: 0.03764590202138807 sdev: 0.029306573579702722\n",
      "Training iteration: 335          last optimization: 300+ --> Actions:\n",
      "mean: 0.0376455942637801 sdev: 0.029324747773301282\n",
      "Training iteration: 336          last optimization: 300# --> Actions:\n",
      "mean: 0.03764740753525367 sdev: 0.029343288574833565\n",
      "Training iteration: 337          last optimization: 300+ --> Actions:\n",
      "mean: 0.03765227517818559 sdev: 0.029361533566695252\n",
      "Training iteration: 338          last optimization: 300# --> Actions:\n",
      "mean: 0.03766069912779429 sdev: 0.029377914866437666\n",
      "Training iteration: 339          last optimization: 300+ --> Actions:\n",
      "mean: 0.037671627181595085 sdev: 0.02939255333673041\n",
      "Training iteration: 340          last optimization: 300# --> Actions:\n",
      "mean: 0.03768452348845191 sdev: 0.0294050269847634\n",
      "Training iteration: 341          last optimization: 300+ --> Actions:\n",
      "mean: 0.037695897058327786 sdev: 0.02941520502026835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration: 342          last optimization: 300# --> Actions:\n",
      "mean: 0.037706171440007416 sdev: 0.029422440044517776\n",
      "Training iteration: 343          last optimization: 300+ --> Actions:\n",
      "mean: 0.0377152390618921 sdev: 0.029427427528685608\n",
      "Training iteration: 344          last optimization: 300# --> Actions:\n",
      "mean: 0.037724029669267314 sdev: 0.029430059453812385\n",
      "Training iteration: 345          last optimization: 300+ --> Actions:\n",
      "mean: 0.037732354154572 sdev: 0.029430502600010844\n",
      "Training iteration: 346          last optimization: 300# --> Actions:\n",
      "mean: 0.037739778913140246 sdev: 0.029428015204605\n",
      "Training iteration: 347          last optimization: 300+ --> Actions:\n",
      "mean: 0.03774691824445062 sdev: 0.029424153543383846\n",
      "Training iteration: 348          last optimization: 300# --> Actions:\n",
      "mean: 0.03775454541782953 sdev: 0.029419483986610182\n",
      "Training iteration: 349          last optimization: 300+ --> Actions:\n",
      "mean: 0.03776349691602732 sdev: 0.02941332891059797\n",
      "Training iteration: 350          last optimization: 300# --> Actions:\n",
      "mean: 0.03777338960908442 sdev: 0.029406104956851895\n",
      "Training iteration: 351          last optimization: 300+ --> Actions:\n",
      "mean: 0.037784379045540356 sdev: 0.029398412909163132\n",
      "Training iteration: 352          last optimization: 300# --> Actions:\n",
      "mean: 0.037795405393050006 sdev: 0.02939160791914107\n",
      "Training iteration: 353          last optimization: 300+ --> Actions:\n",
      "mean: 0.037805882134331406 sdev: 0.029386523832662437\n",
      "Training iteration: 354          last optimization: 300# --> Actions:\n",
      "mean: 0.03781605757502697 sdev: 0.029383588876392735\n",
      "Training iteration: 355          last optimization: 300+ --> Actions:\n",
      "mean: 0.037825113730963415 sdev: 0.029382590555177713\n",
      "Training iteration: 356          last optimization: 300# --> Actions:\n",
      "mean: 0.037832580611112054 sdev: 0.029383605098656434\n",
      "Training iteration: 357          last optimization: 300+ --> Actions:\n",
      "mean: 0.03783884477719115 sdev: 0.029386814004974764\n",
      "Training iteration: 358          last optimization: 300# --> Actions:\n",
      "mean: 0.0378453551674065 sdev: 0.029392777537034447\n",
      "Training iteration: 359          last optimization: 300+ --> Actions:\n",
      "mean: 0.03785254563526653 sdev: 0.02940177779852002\n",
      "Training iteration: 360          last optimization: 300# --> Actions:\n",
      "mean: 0.037857484662135746 sdev: 0.029414325440857602\n",
      "Training iteration: 361          last optimization: 300+ --> Actions:\n",
      "mean: 0.03786083953627238 sdev: 0.029430467591965\n",
      "Training iteration: 362          last optimization: 300# --> Actions:\n",
      "mean: 0.03786430511091589 sdev: 0.02944871044751425\n",
      "Training iteration: 363          last optimization: 300+ --> Actions:\n",
      "mean: 0.03786765035865761 sdev: 0.02946822742542873\n",
      "Training iteration: 364          last optimization: 300# --> Actions:\n",
      "mean: 0.0378716370751992 sdev: 0.029489396730512082\n",
      "Training iteration: 365          last optimization: 300+ --> Actions:\n",
      "mean: 0.03787794078110296 sdev: 0.029510572756169407\n",
      "Training iteration: 366          last optimization: 300# --> Actions:\n",
      "mean: 0.03788624652581451 sdev: 0.02953269971679597\n",
      "Training iteration: 367          last optimization: 300+ --> Actions:\n",
      "mean: 0.03789760361662724 sdev: 0.02955409939472156\n",
      "Training iteration: 368          last optimization: 300# --> Actions:\n",
      "mean: 0.03791142349763471 sdev: 0.02957414232331004\n",
      "Training iteration: 369          last optimization: 300+ --> Actions:\n",
      "mean: 0.03792762643287073 sdev: 0.029591743218787516\n",
      "Training iteration: 370          last optimization: 300# --> Actions:\n",
      "mean: 0.03794495058807264 sdev: 0.029607116654596356\n",
      "Training iteration: 371          last optimization: 300+ --> Actions:\n",
      "mean: 0.03796250994630173 sdev: 0.029620684309077466\n",
      "Training iteration: 372          last optimization: 300# --> Actions:\n",
      "mean: 0.03797946809948469 sdev: 0.02963212770528399\n",
      "Training iteration: 373          last optimization: 300+ --> Actions:\n",
      "mean: 0.037993737735391823 sdev: 0.02964242970451479\n",
      "Training iteration: 374          last optimization: 300# --> Actions:\n",
      "mean: 0.038003982044022985 sdev: 0.02965134350418933\n",
      "Training iteration: 375          last optimization: 300+ --> Actions:\n",
      "mean: 0.03801117304805696 sdev: 0.029658586221230757\n",
      "Training iteration: 376          last optimization: 300# --> Actions:\n",
      "mean: 0.03801511606759238 sdev: 0.029664128568817345\n",
      "Training iteration: 377          last optimization: 300+ --> Actions:\n",
      "mean: 0.03801690537932874 sdev: 0.029668780084910095\n",
      "Training iteration: 378          last optimization: 300# --> Actions:\n",
      "mean: 0.038017934213878946 sdev: 0.029673355338093604\n",
      "Training iteration: 379          last optimization: 300+ --> Actions:\n",
      "mean: 0.038019271261109336 sdev: 0.02967650309104028\n",
      "Training iteration: 380          last optimization: 300# --> Actions:\n",
      "mean: 0.03802038963618499 sdev: 0.029678270492758844\n",
      "Training iteration: 381          last optimization: 300+ --> Actions:\n",
      "mean: 0.03802086576454243 sdev: 0.029678380780552065\n",
      "Training iteration: 382          last optimization: 300# --> Actions:\n",
      "mean: 0.038020883085943515 sdev: 0.02967769476177063\n",
      "Training iteration: 383          last optimization: 300+ --> Actions:\n",
      "mean: 0.038021671212809235 sdev: 0.029677267841350462\n",
      "Training iteration: 384          last optimization: 300# --> Actions:\n",
      "mean: 0.03802093506780373 sdev: 0.029677837474730198\n",
      "Training iteration: 385          last optimization: 300+ --> Actions:\n",
      "mean: 0.038017566570889796 sdev: 0.029680411382467273\n",
      "Training iteration: 386          last optimization: 300# --> Actions:\n",
      "mean: 0.03801279620394907 sdev: 0.02968501704019719\n",
      "Training iteration: 387          last optimization: 300+ --> Actions:\n",
      "mean: 0.03800661527294468 sdev: 0.029690730970776916\n",
      "Training iteration: 388          last optimization: 300# --> Actions:\n",
      "mean: 0.0379978036688865 sdev: 0.029698709642621217\n",
      "Training iteration: 389          last optimization: 300+ --> Actions:\n",
      "mean: 0.03798661117804267 sdev: 0.029709511459263347\n",
      "Training iteration: 390          last optimization: 300# --> Actions:\n",
      "mean: 0.037973703763678715 sdev: 0.029722257425393736\n",
      "Training iteration: 391          last optimization: 300+ --> Actions:\n",
      "mean: 0.03796018877541294 sdev: 0.02973622700374567\n",
      "Training iteration: 392          last optimization: 300# --> Actions:\n",
      "mean: 0.03794635141497353 sdev: 0.029750285503364806\n",
      "Training iteration: 393          last optimization: 300+ --> Actions:\n",
      "mean: 0.03793254945109175 sdev: 0.029765577689404233\n",
      "Training iteration: 394          last optimization: 300# --> Actions:\n",
      "mean: 0.03791948909339873 sdev: 0.029781046432365007\n",
      "Training iteration: 395          last optimization: 300+ --> Actions:\n",
      "mean: 0.03790803583419871 sdev: 0.02979604813224915\n",
      "Training iteration: 396          last optimization: 300# --> Actions:\n",
      "mean: 0.03789833402445052 sdev: 0.029810783707567085\n",
      "Training iteration: 397          last optimization: 300+ --> Actions:\n",
      "mean: 0.037891369158023755 sdev: 0.029825338059865425\n",
      "Training iteration: 398          last optimization: 300# --> Actions:\n",
      "mean: 0.03788672399381041 sdev: 0.02983831574292685\n",
      "Training iteration: 399          last optimization: 300+ --> Actions:\n",
      "mean: 0.03788468019622211 sdev: 0.029849742105751607\n",
      "Training iteration: 400          last optimization: 400# --> Actions:\n",
      "mean: 0.04408669765758988 sdev: 0.017489219075804658\n",
      "Training iteration: 401          last optimization: 400+ --> Actions:\n",
      "mean: 0.04408835042873021 sdev: 0.01749649765698057\n",
      "Training iteration: 402          last optimization: 400# --> Actions:\n",
      "mean: 0.044093503677031826 sdev: 0.01750135985584162\n",
      "Training iteration: 403          last optimization: 400+ --> Actions:\n",
      "mean: 0.04410172514040726 sdev: 0.017503168568625976\n",
      "Training iteration: 404          last optimization: 400# --> Actions:\n",
      "mean: 0.04411159653640419 sdev: 0.017501992083210523\n",
      "Training iteration: 405          last optimization: 400+ --> Actions:\n",
      "mean: 0.044122011556979944 sdev: 0.017497905650728618\n",
      "Training iteration: 406          last optimization: 400# --> Actions:\n",
      "mean: 0.044131986914280184 sdev: 0.01749142833089778\n",
      "Training iteration: 407          last optimization: 400+ --> Actions:\n",
      "mean: 0.044141864901386565 sdev: 0.017482193392933984\n",
      "Training iteration: 408          last optimization: 400# --> Actions:\n",
      "mean: 0.04415169816849292 sdev: 0.01747108550105258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration: 409          last optimization: 400+ --> Actions:\n",
      "mean: 0.04416083930120174 sdev: 0.01745768702889754\n",
      "Training iteration: 410          last optimization: 400# --> Actions:\n",
      "mean: 0.04416865632349947 sdev: 0.017441975783785122\n",
      "Training iteration: 411          last optimization: 400+ --> Actions:\n",
      "mean: 0.04417546609095975 sdev: 0.017424201768562242\n",
      "Training iteration: 412          last optimization: 400# --> Actions:\n",
      "mean: 0.04418097403247567 sdev: 0.017404447047875107\n",
      "Training iteration: 413          last optimization: 400+ --> Actions:\n",
      "mean: 0.044183583891660515 sdev: 0.01738421208391406\n",
      "Training iteration: 414          last optimization: 400# --> Actions:\n",
      "mean: 0.0441837185670802 sdev: 0.01736456283989043\n",
      "Training iteration: 415          last optimization: 400+ --> Actions:\n",
      "mean: 0.04418165730504629 sdev: 0.017346508708906323\n",
      "Training iteration: 416          last optimization: 400# --> Actions:\n",
      "mean: 0.044177676296292795 sdev: 0.017332018804728434\n",
      "Training iteration: 417          last optimization: 400+ --> Actions:\n",
      "mean: 0.04417244577038784 sdev: 0.017321290069788838\n",
      "Training iteration: 418          last optimization: 400# --> Actions:\n",
      "mean: 0.04416589162046201 sdev: 0.017314172102435632\n",
      "Training iteration: 419          last optimization: 400+ --> Actions:\n",
      "mean: 0.044158089305276794 sdev: 0.017310613588227927\n",
      "Training iteration: 420          last optimization: 400# --> Actions:\n",
      "mean: 0.04415004354110681 sdev: 0.017310830340392252\n",
      "Training iteration: 421          last optimization: 400+ --> Actions:\n",
      "mean: 0.044140943869821835 sdev: 0.017315234855405735\n",
      "Training iteration: 422          last optimization: 400# --> Actions:\n",
      "mean: 0.044131341830218725 sdev: 0.017324339879700647\n",
      "Training iteration: 423          last optimization: 400+ --> Actions:\n",
      "mean: 0.044121906220677146 sdev: 0.017336639963266322\n",
      "Training iteration: 424          last optimization: 400# --> Actions:\n",
      "mean: 0.0441134411909342 sdev: 0.01735228889621079\n",
      "Training iteration: 425          last optimization: 400+ --> Actions:\n",
      "mean: 0.04410377767117986 sdev: 0.01736987933407357\n",
      "Training iteration: 426          last optimization: 400# --> Actions:\n",
      "mean: 0.04409567032355884 sdev: 0.017389168498330474\n",
      "Training iteration: 427          last optimization: 400+ --> Actions:\n",
      "mean: 0.04409046092953633 sdev: 0.0174086007488889\n",
      "Training iteration: 428          last optimization: 400# --> Actions:\n",
      "mean: 0.044088436317209774 sdev: 0.017427160766928473\n",
      "Training iteration: 429          last optimization: 400+ --> Actions:\n",
      "mean: 0.04408943700388507 sdev: 0.01744456753350147\n",
      "Training iteration: 430          last optimization: 400# --> Actions:\n",
      "mean: 0.04409402949278366 sdev: 0.01746176484492813\n",
      "Training iteration: 431          last optimization: 400+ --> Actions:\n",
      "mean: 0.04410095018345798 sdev: 0.0174776353018633\n",
      "Training iteration: 432          last optimization: 400# --> Actions:\n",
      "mean: 0.0441102669772746 sdev: 0.017490566664089536\n",
      "Training iteration: 433          last optimization: 400+ --> Actions:\n",
      "mean: 0.04412058699301759 sdev: 0.017498918280894598\n",
      "Training iteration: 434          last optimization: 400# --> Actions:\n",
      "mean: 0.04413084901944756 sdev: 0.017503604380622973\n",
      "Training iteration: 435          last optimization: 400+ --> Actions:\n",
      "mean: 0.04414154376543765 sdev: 0.017506388574913687\n",
      "Training iteration: 436          last optimization: 400# --> Actions:\n",
      "mean: 0.04415146040887575 sdev: 0.017507090891365852\n",
      "Training iteration: 437          last optimization: 400+ --> Actions:\n",
      "mean: 0.044160367060486906 sdev: 0.017505654973080313\n",
      "Training iteration: 438          last optimization: 400# --> Actions:\n",
      "mean: 0.044167788562688236 sdev: 0.01750260982681307\n",
      "Training iteration: 439          last optimization: 400+ --> Actions:\n",
      "mean: 0.044174040422410424 sdev: 0.01749868461743056\n",
      "Training iteration: 440          last optimization: 400# --> Actions:\n",
      "mean: 0.04417922687095392 sdev: 0.017493945175178185\n",
      "Training iteration: 441          last optimization: 400+ --> Actions:\n",
      "mean: 0.044182402643717325 sdev: 0.01748969233777036\n",
      "Training iteration: 442          last optimization: 400# --> Actions:\n",
      "mean: 0.04418395626161191 sdev: 0.017484871949498333\n",
      "Training iteration: 443          last optimization: 400+ --> Actions:\n",
      "mean: 0.044185137358341314 sdev: 0.01748023891448463\n",
      "Training iteration: 444          last optimization: 400# --> Actions:\n",
      "mean: 0.04418605762105037 sdev: 0.017476147602647527\n",
      "Training iteration: 445          last optimization: 400+ --> Actions:\n",
      "mean: 0.04418632230149135 sdev: 0.01747349529146904\n",
      "Training iteration: 446          last optimization: 400# --> Actions:\n",
      "mean: 0.04418609188274307 sdev: 0.01747230649077339\n",
      "Training iteration: 447          last optimization: 400+ --> Actions:\n",
      "mean: 0.04418651103570643 sdev: 0.01747360216242368\n",
      "Training iteration: 448          last optimization: 400# --> Actions:\n",
      "mean: 0.04418678444157923 sdev: 0.017477149913803933\n",
      "Training iteration: 449          last optimization: 400+ --> Actions:\n",
      "mean: 0.044186553529495194 sdev: 0.017483472963528264\n",
      "Training iteration: 450          last optimization: 400# --> Actions:\n",
      "mean: 0.044186616530750164 sdev: 0.01749223254119538\n",
      "Training iteration: 451          last optimization: 400+ --> Actions:\n",
      "mean: 0.04418674628725784 sdev: 0.017503836955354284\n",
      "Training iteration: 452          last optimization: 400# --> Actions:\n",
      "mean: 0.04418674486492198 sdev: 0.017518665798426706\n",
      "Training iteration: 453          last optimization: 400+ --> Actions:\n",
      "mean: 0.04418661257864961 sdev: 0.017534660173337758\n",
      "Training iteration: 454          last optimization: 400# --> Actions:\n",
      "mean: 0.04418669357378653 sdev: 0.017551137615428956\n",
      "Training iteration: 455          last optimization: 400+ --> Actions:\n",
      "mean: 0.04418846261900126 sdev: 0.017568116079702628\n",
      "Training iteration: 456          last optimization: 400# --> Actions:\n",
      "mean: 0.04419192410431445 sdev: 0.0175845171027377\n",
      "Training iteration: 457          last optimization: 400+ --> Actions:\n",
      "mean: 0.04419704078305931 sdev: 0.017600315896468145\n",
      "Training iteration: 458          last optimization: 400# --> Actions:\n",
      "mean: 0.044203782772371455 sdev: 0.017614423337458503\n",
      "Training iteration: 459          last optimization: 400+ --> Actions:\n",
      "mean: 0.04421328874227613 sdev: 0.017626276201824848\n",
      "Training iteration: 460          last optimization: 400# --> Actions:\n",
      "mean: 0.04422501016004255 sdev: 0.01763564571139412\n",
      "Training iteration: 461          last optimization: 400+ --> Actions:\n",
      "mean: 0.04423778063993529 sdev: 0.01764166994835962\n",
      "Training iteration: 462          last optimization: 400# --> Actions:\n",
      "mean: 0.04425223177702224 sdev: 0.01764470803544825\n",
      "Training iteration: 463          last optimization: 400+ --> Actions:\n",
      "mean: 0.044267720215761926 sdev: 0.017645547698096332\n",
      "Training iteration: 464          last optimization: 400# --> Actions:\n",
      "mean: 0.04428334364927643 sdev: 0.017644572732362633\n",
      "Training iteration: 465          last optimization: 400+ --> Actions:\n",
      "mean: 0.0442984408364148 sdev: 0.017641870836444407\n",
      "Training iteration: 466          last optimization: 400# --> Actions:\n",
      "mean: 0.044312000788762254 sdev: 0.0176377975549993\n",
      "Training iteration: 467          last optimization: 400+ --> Actions:\n",
      "mean: 0.044323768275863165 sdev: 0.017631362502871683\n",
      "Training iteration: 468          last optimization: 400# --> Actions:\n",
      "mean: 0.044334287865282915 sdev: 0.017622439825390558\n",
      "Training iteration: 469          last optimization: 400+ --> Actions:\n",
      "mean: 0.04434430652406439 sdev: 0.017611872429445816\n",
      "Training iteration: 470          last optimization: 400# --> Actions:\n",
      "mean: 0.04435264425554695 sdev: 0.01760049882488121\n",
      "Training iteration: 471          last optimization: 400+ --> Actions:\n",
      "mean: 0.04435978801822711 sdev: 0.017588270529143656\n",
      "Training iteration: 472          last optimization: 400# --> Actions:\n",
      "mean: 0.04436578872634846 sdev: 0.01757604550121159\n",
      "Training iteration: 473          last optimization: 400+ --> Actions:\n",
      "mean: 0.04437115669308718 sdev: 0.017565644740314176\n",
      "Training iteration: 474          last optimization: 400# --> Actions:\n",
      "mean: 0.04437499562998295 sdev: 0.01755643053267804\n",
      "Training iteration: 475          last optimization: 400+ --> Actions:\n",
      "mean: 0.044377964351580014 sdev: 0.017548349043694178\n",
      "Training iteration: 476          last optimization: 400# --> Actions:\n",
      "mean: 0.044379923543149985 sdev: 0.017543676101279573\n",
      "Training iteration: 477          last optimization: 400+ --> Actions:\n",
      "mean: 0.04437986901877702 sdev: 0.017542364429017136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration: 478          last optimization: 400# --> Actions:\n",
      "mean: 0.04437844591569757 sdev: 0.01754363300184681\n",
      "Training iteration: 479          last optimization: 400+ --> Actions:\n",
      "mean: 0.04437575346940795 sdev: 0.017547484986955023\n",
      "Training iteration: 480          last optimization: 400# --> Actions:\n",
      "mean: 0.044370767465099374 sdev: 0.017553622011127767\n",
      "Training iteration: 481          last optimization: 400+ --> Actions:\n",
      "mean: 0.04436402518457618 sdev: 0.017561216005576752\n",
      "Training iteration: 482          last optimization: 400# --> Actions:\n",
      "mean: 0.04435630453468228 sdev: 0.01757016051402669\n",
      "Training iteration: 483          last optimization: 400+ --> Actions:\n",
      "mean: 0.04434796362852809 sdev: 0.017581353804208694\n",
      "Training iteration: 484          last optimization: 400# --> Actions:\n",
      "mean: 0.04433948996568997 sdev: 0.0175936555737852\n",
      "Training iteration: 485          last optimization: 400+ --> Actions:\n",
      "mean: 0.04433146020658228 sdev: 0.0176068869746589\n",
      "Training iteration: 486          last optimization: 400# --> Actions:\n",
      "mean: 0.0443251144593017 sdev: 0.01762005467619039\n",
      "Training iteration: 487          last optimization: 400+ --> Actions:\n",
      "mean: 0.04432009019317771 sdev: 0.01763283065958809\n",
      "Training iteration: 488          last optimization: 400# --> Actions:\n",
      "mean: 0.044317233513495126 sdev: 0.01764467225901036\n",
      "Training iteration: 489          last optimization: 400+ --> Actions:\n",
      "mean: 0.044316867867292456 sdev: 0.017655640022067324\n",
      "Training iteration: 490          last optimization: 400# --> Actions:\n",
      "mean: 0.04431857038201637 sdev: 0.017664017101482438\n",
      "Training iteration: 491          last optimization: 400+ --> Actions:\n",
      "mean: 0.044321219397427655 sdev: 0.017670406086128614\n",
      "Training iteration: 492          last optimization: 400# --> Actions:\n",
      "mean: 0.04432512615649461 sdev: 0.01767437034701292\n",
      "Training iteration: 493          last optimization: 400+ --> Actions:\n",
      "mean: 0.044329244278420825 sdev: 0.017675020899186492\n",
      "Training iteration: 494          last optimization: 400# --> Actions:\n",
      "mean: 0.04433259735624397 sdev: 0.017672973649914565\n",
      "Training iteration: 495          last optimization: 400+ --> Actions:\n",
      "mean: 0.044336001398592555 sdev: 0.017668417861429506\n",
      "Training iteration: 496          last optimization: 400# --> Actions:\n",
      "mean: 0.04433778509708105 sdev: 0.017661591976518565\n",
      "Training iteration: 497          last optimization: 400+ --> Actions:\n",
      "mean: 0.04433784235849581 sdev: 0.017652898569147844\n",
      "Training iteration: 498          last optimization: 400# --> Actions:\n",
      "mean: 0.044337683833362784 sdev: 0.017642857783322766\n",
      "Training iteration: 499          last optimization: 400+ --> Actions:\n",
      "mean: 0.044336320775324366 sdev: 0.017630856568099335\n",
      "Training iteration: 500          last optimization: 500#\n",
      "***--> Total Elapsed Runtime: 00:00:39 for training the agent\n"
     ]
    }
   ],
   "source": [
    "# Thx2: https://discuss.pytorch.org/t/how-to-check-if-model-is-on-cuda/180/2?u=ferenc_acs\n",
    "start_time = time()\n",
    "\n",
    "agent.train()\n",
    "\n",
    "end_time = time()\n",
    "\n",
    "print_elapsed_time(start_time, end_time, \"for training the agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***--> Total Elapsed Runtime: 00:00:00 for observing the trained agent\n",
      "#\n",
      "Total score (averaged over agents) this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Some reminders about lambda functions\n",
    "# Thx2: https://realpython.com/python-lambda/\n",
    "# Thx2: https://thispointer.com/python-how-to-use-if-else-elif-in-lambda-functions/\n",
    "\n",
    "RANDOMRUN = False\n",
    "\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "#env_info = env.reset(train_mode=True)[brain_name] # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "avg100sum = np.zeros(num_agents)\n",
    "exectime = 0\n",
    "\n",
    "scores100 = deque(avg100sum, 100)\n",
    "time100 = list()\n",
    "epc = 0\n",
    "\n",
    "\n",
    "#import pdb; pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "start_time = time()\n",
    "\n",
    "while RANDOMRUN: #== True:\n",
    "    epc += 1\n",
    "    #print(f'\\r#{epc}', end = ' ')\n",
    "    print(f'\\r#{str(epc).rjust(6)}', end = ' ')\n",
    "    #actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = agent.a2c_net.select_action(states)\n",
    "    #actions = np.clip(actions.detach().cpu().numpy(), -1, 1)                  # all actions between -1 and 1\n",
    "        \n",
    "    t_step_b = time()\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    t_step_e = time()\n",
    "    time100.append(t_step_e - t_step_b)\n",
    "    \n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    rewards = env_info.rewards\n",
    "    nprewards = np.array(rewards)\n",
    "    scores += rewards                         # update the score (for each agent)\n",
    "    scores100.append(rewards)\n",
    "    if np.sum(nprewards) > 0:\n",
    "        #for x in scores100:\n",
    "        #    avg100sum += x\n",
    "        print(f'\\r#{epc} Avg 100 Rewards = {np.mean(scores100)}')  \n",
    "        avg100sum = np.zeros(num_agents)\n",
    "        maskagent = nprewards > 0\n",
    "        \n",
    "    if epc%100 == 0:\n",
    "        print(f'Exec time Avg 100: {np.mean(time100)}')\n",
    "        time100 = []\n",
    "        \n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "        \n",
    "end_time = time()\n",
    "\n",
    "print_elapsed_time(start_time, end_time, \"for observing the trained agent\")\n",
    "        \n",
    "print('#')\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-28 / 19-10-19  Notebook for Continuous Control ended.\n"
     ]
    }
   ],
   "source": [
    "print(get_time_string(sep=True), ' Notebook for Continuous Control ended.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
