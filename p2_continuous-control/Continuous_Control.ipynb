{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posix.uname_result(sysname='Linux', nodename='Anubis-Linux', release='5.4.0-48-generic', version='#52-Ubuntu SMP Thu Sep 10 10:58:49 UTC 2020', machine='x86_64')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.uname())\n",
    "\n",
    "# In the cloud environment?\n",
    "if 'root' in os.environ['HOME']:\n",
    "    UENVPATH = '/data/'\n",
    "    !pip -q install /home/workspace/python\n",
    "\n",
    "# In the standalone environment?\n",
    "if 'ferenc' in os.environ['HOME']:\n",
    "    UENVPATH = '/home/ferenc/Python/rl/udadrl/data/'\n",
    "\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "import pprint as pp\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "from time import time\n",
    "\n",
    "# Import the helper files\n",
    "from utilities import get_time_string, print_elapsed_time\n",
    "\n",
    "import pdb # Debug! Debug! Debug! Debug! Debug! Debug! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-27 / 16-32-05  Notebook for Continuous Control started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_size -> 5.0\n",
      "\t\tgoal_speed -> 1.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "print(get_time_string(sep=True), ' Notebook for Continuous Control started.')\n",
    "\n",
    "# ONE Agent, Standalone\n",
    "#UENVCHOICE = 'Reacher_Linux/Reacher.x86_64'\n",
    "\n",
    "# TWENTY Agents, Standalone\n",
    "#UENVCHOICE = 'Reacher_Linux_20/Reacher.x86_64'\n",
    "\n",
    "# ONE Agent, Cloud, No-Visuals \n",
    "#UENVCHOICE = 'Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64'\n",
    "\n",
    "# TWENTY Agents, Cloud, No-Visuals \n",
    "UENVCHOICE = 'Reacher_Linux_NoVis/Reacher.x86_64'\n",
    "\n",
    "env = UnityEnvironment( file_name=os.path.join( UENVPATH, UENVCHOICE ) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unityagents.environment.UnityEnvironment"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FA DEBUG! DEBUG! DEBUG! \n",
    "type(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ReacherBrain']\n",
      "<class 'unityagents.brain.BrainParameters'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ReacherBrain'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FA  DEBUG! DEBUG! DEBUG! \n",
    "print(env.brain_names)\n",
    "print( type(brain) )\n",
    "brain.brain_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space: 33 dimensions of continuous type\n",
      "Action Space: 4 dimensions of continuous type\n"
     ]
    }
   ],
   "source": [
    "# FA  DEBUG! DEBUG! DEBUG!\n",
    "print(f'Observation Space: {brain.vector_observation_space_size} dimensions of {brain.vector_observation_space_type} type') \n",
    "print(f'Action Space: {brain.vector_action_space_size} dimensions of {brain.vector_observation_space_type} type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 20 active agents\n",
      "\n",
      "***--> Total Elapsed Runtime: 00:00:00 for choosing random actions\n",
      "#\n",
      "Total score (averaged over agents) this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Should a run with random actions be perfomed first?\n",
    "RANDOMRUN = False\n",
    "\n",
    "# Some reminders about lambda functions\n",
    "# Thx2: https://realpython.com/python-lambda/\n",
    "# Thx2: https://thispointer.com/python-how-to-use-if-else-elif-in-lambda-functions/\n",
    "# thx2: https://www.blog.pythonlibrary.org/2016/05/24/python-101-an-intro-to-benchmarking-your-code/\n",
    "import timeit\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "\n",
    "epc = 0\n",
    "print(f'We have {num_agents} active agent' + ( lambda x: 's' if x>1 else '' )(num_agents) )\n",
    "\n",
    "start_time = time()\n",
    "setup = \"from unityagents import UnityEnvironment\"\n",
    "\n",
    "while RANDOMRUN:\n",
    "    epc += 1\n",
    "    #print(f'\\r#{epc}', end = ' ')\n",
    "    print(f'\\r#{str(epc).rjust(6)}', end = ' ')\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    #pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    #print( timeit.timeit(\"env_info = env.step(actions)[brain_name]\", setup) )\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    rewards = env_info.rewards\n",
    "    nprewards = np.array(rewards)\n",
    "    scores += rewards                         # update the score (for each agent)\n",
    "    if np.sum(nprewards) > 0:\n",
    "        #print(f'\\r#{epc} Rewards = {rewards}')\n",
    "        maskagent = nprewards > 0\n",
    "        agentbefore = False\n",
    "        for (nagent, action) in enumerate(actions):\n",
    "            if maskagent[nagent]:\n",
    "                if agentbefore:\n",
    "                    print('\\r#' + '&'.rjust(6), end = ' ')\n",
    "                print(' -> Agent {:0>2d} got reward {:+.5f} for action: {}'.format(nagent+1, rewards[nagent], action))\n",
    "                agentbefore = True\n",
    "                #pp.pprint(list(action))\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "        \n",
    "end_time = time()\n",
    "\n",
    "print_elapsed_time(start_time, end_time, \"for choosing random actions\")\n",
    "\n",
    "print('#')\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re check running time (Random run)\n",
    "This time with the leanest code possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 20 active agents\n",
      "\n",
      "***--> Total Elapsed Runtime: 00:00:00 for choosing fast random actions\n",
      "#\n",
      "Total score (averaged over agents) this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Should another run with random actions be perfomed?\n",
    "RANDOMRUN = False\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "#env_info = env.reset(train_mode=True)[brain_name] # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "\n",
    "epc = 0\n",
    "print(f'We have {num_agents} active agent' + ( lambda x: 's' if x>1 else '' )(num_agents) )\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "while RANDOMRUN:\n",
    "    epc += 1\n",
    "    print(f'\\r#{str(epc).rjust(6)}', end = ' ')\n",
    "    #pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "        \n",
    "end_time = time()\n",
    "\n",
    "print_elapsed_time(start_time, end_time, \"for choosing fast random actions\")\n",
    "\n",
    "print('#')\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.12805176e+00,\n",
       "        -1.00000000e+00, -3.63192368e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  3.92812490e-02],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  5.03456116e+00,\n",
       "        -1.00000000e+00,  6.21716690e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  9.63666677e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  5.24847412e+00,\n",
       "        -1.00000000e+00,  6.03767776e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00, -1.35212541e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -7.87846184e+00,\n",
       "        -1.00000000e+00, -1.38918507e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00, -5.42254448e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -2.79192984e-01,\n",
       "        -1.00000000e+00,  7.99512672e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  7.49394178e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  4.70228195e+00,\n",
       "        -1.00000000e+00, -6.47213650e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  2.25743055e-02],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -3.75577545e+00,\n",
       "        -1.00000000e+00, -7.06358004e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  5.07442713e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.38918495e+00,\n",
       "        -1.00000000e+00,  7.87846184e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00, -4.48411107e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.73616028e+00,\n",
       "        -1.00000000e+00, -7.51754141e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00, -5.25649071e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -5.55726719e+00,\n",
       "        -1.00000000e+00, -5.75471878e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  6.52894735e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -6.99695778e+00,\n",
       "        -1.00000000e+00,  3.87847900e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  8.39847088e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.60454559e+00,\n",
       "        -1.00000000e+00, -7.56414795e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  8.63162279e-02],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.30836487e+00,\n",
       "        -1.00000000e+00,  3.25389290e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  5.08338690e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.96955776e+00,\n",
       "        -1.00000000e+00,  6.97246552e-01,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  6.07460499e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.51754093e+00,\n",
       "        -1.00000000e+00,  2.73616028e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  5.45782328e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -7.25046158e+00,\n",
       "        -1.00000000e+00, -3.38094544e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  2.36645341e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -2.79193878e-01,\n",
       "        -1.00000000e+00,  7.99512482e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  5.87887526e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.33897400e+00,\n",
       "        -1.00000000e+00, -7.65043640e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  6.67207956e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -5.75471878e+00,\n",
       "        -1.00000000e+00,  5.55726624e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00, -5.25265932e-02],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  5.94515800e+00,\n",
       "        -1.00000000e+00, -5.35304642e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00, -8.03074121e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# thx2: https://github.com/udacity/deep-reinforcement-learning/blob/master/python/unityagents/brain.py\n",
    "env_info.vector_observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When finished, you can close the environment.\n",
    "#### Just not for now because unit testing below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FA: One BIG MISUNDERSTANDING & STACKS OF TENSORS (23-08-2020) --> #FA; BMSoT:\n",
    "It has cost me several days if not weeks to get behind the fact that the [A2C sample implementation of Miguel](https://github.com/mimoralea/gdrl/blob/master/notebooks/chapter_11/chapter-11.ipynb) is working with **stacks of tensors** instead of single tensors. Which was especially hard to find because the PyTorch code looks exactly the same for both.\n",
    "\n",
    "In the end, when I thought about it, it makes sense and is a nifty feature of PyTorch. It is just not obvious to people like me, without in deep insights in the inner workings of PyTorch. \n",
    "\n",
    "Furthermore the authors of the PyTorch documentation seem not to make it too visible, I had to dig it out of one of the function definitions I use, however inderectly over the layer defintion for a2cnet:\n",
    "\n",
    "https://pytorch.org/docs/0.4.0/_modules/torch/nn/functional.html#linear\n",
    "\n",
    "> def linear(input, weight, bias=None):\n",
    ">    \"\"\"\n",
    ">    Applies a linear transformation to the incoming data: :math:`y = xA^T + b`.\n",
    ">\n",
    ">    Shape:\n",
    ">        - Input: :math:`(N, *, in\\_features)` where `*` means any number of\n",
    ">          additional dimensions\n",
    ">        - Weight: :math:`(out\\_features, in\\_features)`\n",
    ">        - Bias: :math:`(out\\_features)`\n",
    ">        - Output: :math:`(N, *, out\\_features)`\n",
    ">    \"\"\"\n",
    ">    if input.dim() == 2 and bias is not None:\n",
    ">        # fused op is marginally faster\n",
    ">        return torch.addmm(bias, input, weight.t())\n",
    ">\n",
    ">    output = input.matmul(weight.t())\n",
    ">    if bias is not None:\n",
    ">        output += bias\n",
    ">    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracing the error in the 'mya2cnet' module code refactoring below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! \n",
    "#import pdb; pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(20200808) # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "#torch.manual_seed(456454618181) # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "\n",
    "# Format: IN_Num [Layer 1] (OUT_Num = IN_Num) [Layer 2] OUT_Num = ...\n",
    "HIDDEN_DIMS_DEFAULT = {\n",
    "    'shared' : (512, 512, 256, 256),\n",
    "    'actor' : (256, 128, 128, 64),\n",
    "    'critic' : (256, 128, 128, 64)\n",
    "}\n",
    "hidden_dims = HIDDEN_DIMS_DEFAULT\n",
    "\n",
    "hlayers = dict()\n",
    "\n",
    "hlayers['shared'] = nn.ModuleList()\n",
    "hlayers['actor'] = nn.ModuleList()\n",
    "hlayers['critic'] = nn.ModuleList()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "input_layer = nn.Linear( 33, hidden_dims['shared'][0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=33, out_features=512, bias=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layers shared\n",
    "for i in range( len(hidden_dims['shared']) -1 ):\n",
    "    hlayers['shared'].append( nn.Linear( hidden_dims['shared'][i], hidden_dims['shared'][i+1] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hlayers['shared']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actor layers\n",
    "for i in range( len(hidden_dims['actor']) ):\n",
    "    #import pdb; pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "    if i == 0:\n",
    "        hlayers['actor'].append( nn.Linear( hidden_dims['shared'][-1], hidden_dims['actor'][i] ) )\n",
    "    else:\n",
    "        # hlayers['actor'].append( nn.Linear( hidden_dims['actor'][i], hidden_dims['actor'][i+1] ERROR !!!\n",
    "        hlayers['actor'].append( nn.Linear( hidden_dims['actor'][i-1], hidden_dims['actor'][i] ) )\n",
    "    #print( i, hlayers['actor'] ) # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "        \n",
    "actor_out_layer = nn.Linear( hidden_dims['actor'][-1], 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (3): Linear(in_features=128, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hlayers['actor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=64, out_features=4, bias=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Critic layers\n",
    "for i in range( len(hidden_dims['critic']) ):\n",
    "    if i == 0:\n",
    "        hlayers['critic'].append( nn.Linear( hidden_dims['shared'][-1], hidden_dims['critic'][i] ) )\n",
    "    else:\n",
    "        hlayers['critic'].append( nn.Linear( hidden_dims['critic'][i-1], hidden_dims['critic'][i] ) )\n",
    "critic_out_layer = nn.Linear( hidden_dims['critic'][-1], 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (3): Linear(in_features=128, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hlayers['critic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=64, out_features=1, bias=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic_out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevents non Pytorch Tensor Object entering the processing stream\n",
    "def torch_format(state):\n",
    "    x = state\n",
    "    if not isinstance(x, torch.Tensor):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        if len(x.size()) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(state):\n",
    "    check_tensor = lambda x: isinstance(x, torch.Tensor)\n",
    "    x_act = True \n",
    "    x_crit = True\n",
    "\n",
    "    x = torch_format(state)\n",
    "    x = F.relu(  input_layer(x) )\n",
    "    for label in ['shared', 'actor', 'critic']:\n",
    "        for hlayer in  hlayers[label]:\n",
    "            if label == 'shared':\n",
    "                x = F.relu(  hlayer(x) )\n",
    "            if label == 'actor':\n",
    "                x_act = F.relu(  hlayer(x_act) )\n",
    "            if label == 'critic':\n",
    "                x_crit = F.relu(  hlayer(x_crit) )\n",
    "\n",
    "        # Thx2: https://discuss.pytorch.org/t/copy-deepcopy-vs-clone/55022\n",
    "        if ( type(x_act) == bool ):\n",
    "            x_act = x.clone()  # Create an Inplace copy...\n",
    "        if ( type(x_crit) == bool ):\n",
    "            x_crit = x.clone() # ...after processing shared layers\n",
    "\n",
    "    return  actor_out_layer(x_act),  critic_out_layer(x_crit) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if A STACK OF (BMSoT) states are propagated through the debug network\n",
    "And make a list of outputs of two A2C instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States [[ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  7.12805176e+00 -1.00000000e+00\n",
      "  -3.63192368e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   3.92812490e-02]\n",
      " [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  5.03456116e+00 -1.00000000e+00\n",
      "   6.21716690e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   9.63666677e-01]\n",
      " [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  5.24847412e+00 -1.00000000e+00\n",
      "   6.03767776e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "  -1.35212541e-01]\n",
      " [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -7.87846184e+00 -1.00000000e+00\n",
      "  -1.38918507e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "  -5.42254448e-01]\n",
      " [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -2.79192984e-01 -1.00000000e+00\n",
      "   7.99512672e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   7.49394178e-01]\n",
      " [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  4.70228195e+00 -1.00000000e+00\n",
      "  -6.47213650e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   2.25743055e-02]\n",
      " [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -3.75577545e+00 -1.00000000e+00\n",
      "  -7.06358004e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   5.07442713e-01]\n",
      " [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.38918495e+00 -1.00000000e+00\n",
      "   7.87846184e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "  -4.48411107e-01]\n",
      " [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  2.73616028e+00 -1.00000000e+00\n",
      "  -7.51754141e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "  -5.25649071e-01]\n",
      " [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -5.55726719e+00 -1.00000000e+00\n",
      "  -5.75471878e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   6.52894735e-01]\n",
      " [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -6.99695778e+00 -1.00000000e+00\n",
      "   3.87847900e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   8.39847088e-01]\n",
      " [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  2.60454559e+00 -1.00000000e+00\n",
      "  -7.56414795e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   8.63162279e-02]\n",
      " [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  7.30836487e+00 -1.00000000e+00\n",
      "   3.25389290e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   5.08338690e-01]\n",
      " [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  7.96955776e+00 -1.00000000e+00\n",
      "   6.97246552e-01  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   6.07460499e-01]\n",
      " [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  7.51754093e+00 -1.00000000e+00\n",
      "   2.73616028e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   5.45782328e-01]\n",
      " [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -7.25046158e+00 -1.00000000e+00\n",
      "  -3.38094544e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   2.36645341e-01]\n",
      " [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -2.79193878e-01 -1.00000000e+00\n",
      "   7.99512482e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   5.87887526e-01]\n",
      " [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  2.33897400e+00 -1.00000000e+00\n",
      "  -7.65043640e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   6.67207956e-01]\n",
      " [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -5.75471878e+00 -1.00000000e+00\n",
      "   5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "  -5.25265932e-02]\n",
      " [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  5.94515800e+00 -1.00000000e+00\n",
      "  -5.35304642e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "  -8.03074121e-01]]\n",
      "Actor: tensor(1.00000e-02 *\n",
      "       [[ 4.6543,  4.9756, -4.4953,  4.2128],\n",
      "        [ 4.7037,  4.9775, -4.4215,  4.1041],\n",
      "        [ 4.7006,  4.9798, -4.4235,  4.1018],\n",
      "        [ 4.6981,  4.9901, -4.3603,  4.1175],\n",
      "        [ 4.7117,  4.9911, -4.4272,  4.1191],\n",
      "        [ 4.6864,  4.9768, -4.4898,  4.2664],\n",
      "        [ 4.7017,  5.0059, -4.4374,  4.2481],\n",
      "        [ 4.7107,  4.9870, -4.4269,  4.1114],\n",
      "        [ 4.6985,  4.9721, -4.4752,  4.2727],\n",
      "        [ 4.6935,  5.0025, -4.4124,  4.2141],\n",
      "        [ 4.7007,  4.9718, -4.3907,  4.1061],\n",
      "        [ 4.6997,  4.9750, -4.4772,  4.2800],\n",
      "        [ 4.6790,  4.9917, -4.4376,  4.1197],\n",
      "        [ 4.6685,  4.9951, -4.4505,  4.1421],\n",
      "        [ 4.6763,  4.9944, -4.4406,  4.1248],\n",
      "        [ 4.6967,  4.9936, -4.3724,  4.1618],\n",
      "        [ 4.7116,  4.9925, -4.4258,  4.1176],\n",
      "        [ 4.7030,  4.9784, -4.4800,  4.2864],\n",
      "        [ 4.7116,  4.9804, -4.4134,  4.1002],\n",
      "        [ 4.6749,  4.9665, -4.4912,  4.2393]])\n",
      "Critic: tensor(1.00000e-02 *\n",
      "       [[ 4.7572],\n",
      "        [ 4.8767],\n",
      "        [ 4.8752],\n",
      "        [ 4.8696],\n",
      "        [ 4.8610],\n",
      "        [ 4.7746],\n",
      "        [ 4.8414],\n",
      "        [ 4.8706],\n",
      "        [ 4.8107],\n",
      "        [ 4.8393],\n",
      "        [ 4.8479],\n",
      "        [ 4.8147],\n",
      "        [ 4.8553],\n",
      "        [ 4.8110],\n",
      "        [ 4.8488],\n",
      "        [ 4.8638],\n",
      "        [ 4.8612],\n",
      "        [ 4.8194],\n",
      "        [ 4.8508],\n",
      "        [ 4.7676]])\n"
     ]
    }
   ],
   "source": [
    "#al = []\n",
    "#bl = []\n",
    "\n",
    "#for (dc, st) in enumerate(states):\n",
    "#    al.append(a)\n",
    "#    bl.append(b)\n",
    "\n",
    "#import pdb; pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!    \n",
    "    \n",
    "#FA; BMSoT: No need to iterate through states any more!\n",
    "a,b = forward(states)\n",
    "print(f'States {states}')\n",
    "print(f'Actor: {a}')\n",
    "print(f'Critic: {b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if A STACK OF (BMSoT) states is propagated through the imported network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "\n",
    "#from mya2cnet import A2CNetwork\n",
    "import mya2cnet\n",
    "\n",
    "# Thx2: https://emacs.stackexchange.com/a/13483\n",
    "import imp\n",
    "imp.reload(mya2cnet)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tstnet1 = mya2cnet.A2CNetwork(33, 4).to(device) #FA; BMSoT: Looks exactly the same...\n",
    "tstnet2 = mya2cnet.A2CNetwork(33, 4).to(device) #FA; BMSoT: ...like without stacks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FA; BMSoT: OBSOLETE\n",
    "#for (dc, st) in enumerate(states):\n",
    "\n",
    "\n",
    "\n",
    "# pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "    \n",
    "#a1,b1 = tstnet1.forward(torch.tensor(states, dtype=torch.float, device=device))\n",
    "#a2,b2 = tstnet2.forward(torch.tensor(states).to(device))\n",
    "\n",
    "#print(f'Dist. Actor stacks 1-2: {torch.dist(a1, a2)}'.ljust(50) + ' # ' +\\\n",
    "#     f'Dist. Actor 1 stacks - Notebook stacks {torch.dist(a1, a)}'.rjust(50))\n",
    "#print(f'Dist. Critic stacks 1-2: {torch.dist(b1, b2)}'.ljust(50) + ' # ' +\\\n",
    "#     f'Dist. Critic 1 stacks - Notebook stacks {torch.dist(b1, b)}'.rjust(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next(tstnet1.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next(tstnet2.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FA; BMSoT: OBSOLETE\n",
    "#for (dc, st) in enumerate(states):\n",
    "#    print(f'({dc+1}) -> {tstnet1.fullpass(st)}')\n",
    "    \n",
    "#tstnet1.fullpass( torch.tensor(states, device = device, dtype = torch.float) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FA; BMSoT: OBSOLETE\n",
    "#for (dc, st) in enumerate(states):\n",
    "#    print(f'({dc+1})-> {tstnet1.select_action(st)}') #, end=' ')\n",
    "    \n",
    "#tstnet1.select_action(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the agent instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mya2cagent\n",
    "\n",
    "# Thx2: https://emacs.stackexchange.com/a/13483\n",
    "import imp\n",
    "imp.reload(mya2cagent)\n",
    "\n",
    "agent = mya2cagent.a2cagent(len(env_info.agents), env, brain, max_steps = 500, max_n_steps = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --> Actions:\n",
      "mean: 0.018259049152105748 sdev: 0.07094505470037758\n",
      "Training iteration: 1            last optimization: 0+ --> Actions:\n",
      "mean: 0.01825372022181406 sdev: 0.07096932655250542\n",
      "Training iteration: 2            last optimization: 0# --> Actions:\n",
      "mean: 0.018247686645869465 sdev: 0.07098687674324228\n",
      "Training iteration: 3            last optimization: 0+ --> Actions:\n",
      "mean: 0.018240053739600658 sdev: 0.07099738561178393\n",
      "Training iteration: 4            last optimization: 0# --> Actions:\n",
      "mean: 0.018233294376840917 sdev: 0.07099938421605297\n",
      "Training iteration: 5            last optimization: 5+ --> Actions:\n",
      "mean: 0.02407496066569181 sdev: 0.05761002703708406\n",
      "Training iteration: 6            last optimization: 5# --> Actions:\n",
      "mean: 0.024065437670415673 sdev: 0.05761029971278512\n",
      "Training iteration: 7            last optimization: 5+ --> Actions:\n",
      "mean: 0.024052968344571546 sdev: 0.0576117417247655\n",
      "Training iteration: 8            last optimization: 5# --> Actions:\n",
      "mean: 0.02404086071920884 sdev: 0.05761391939696922\n",
      "Training iteration: 9            last optimization: 5+ --> Actions:\n",
      "mean: 0.024029397090368672 sdev: 0.057617574585003654\n",
      "Training iteration: 10           last optimization: 10# --> Actions:\n",
      "mean: 0.030640854510169742 sdev: 0.04476668380845793\n",
      "Training iteration: 11           last optimization: 10+ --> Actions:\n",
      "mean: 0.03061840606911897 sdev: 0.04476847366333185\n",
      "Training iteration: 12           last optimization: 10# --> Actions:\n",
      "mean: 0.030595415908411562 sdev: 0.04477147095413326\n",
      "Training iteration: 13           last optimization: 10+ --> Actions:\n",
      "mean: 0.030570767663405257 sdev: 0.0447768530266077\n",
      "Training iteration: 14           last optimization: 10# --> Actions:\n",
      "mean: 0.030546013199566617 sdev: 0.04478316762701605\n",
      "Training iteration: 15           last optimization: 15+ --> Actions:\n",
      "mean: 0.037559770080971874 sdev: 0.031002961159829704\n",
      "Training iteration: 16           last optimization: 15# --> Actions:\n",
      "mean: 0.03751281207426025 sdev: 0.0310384216052272\n",
      "Training iteration: 17           last optimization: 15+ --> Actions:\n",
      "mean: 0.03746740710147593 sdev: 0.031077141622747172\n",
      "Training iteration: 18           last optimization: 15# --> Actions:\n",
      "mean: 0.03742665473434072 sdev: 0.03111765262118093\n",
      "Training iteration: 19           last optimization: 15+ --> Actions:\n",
      "mean: 0.03739189975171463 sdev: 0.0311592820413968\n",
      "Training iteration: 20           last optimization: 20# --> Actions:\n",
      "mean: 0.04352991529974439 sdev: 0.019085042799242023\n",
      "Training iteration: 21           last optimization: 20+ --> Actions:\n",
      "mean: 0.04349490521179811 sdev: 0.019122913948506553\n",
      "Training iteration: 22           last optimization: 20# --> Actions:\n",
      "mean: 0.04347340300314108 sdev: 0.019163560931105127\n",
      "Training iteration: 23           last optimization: 20+ --> Actions:\n",
      "mean: 0.04346831020341611 sdev: 0.019201762051071113\n",
      "Training iteration: 24           last optimization: 20# --> Actions:\n",
      "mean: 0.043480161616342126 sdev: 0.019232441896552408\n",
      "Training iteration: 25           last optimization: 25+ --> Actions:\n",
      "mean: 0.04852479778189702 sdev: 0.009454098111002384\n",
      "Training iteration: 26           last optimization: 25# --> Actions:\n",
      "mean: 0.048540677496552234 sdev: 0.009431888430840467\n",
      "Training iteration: 27           last optimization: 25+ --> Actions:\n",
      "mean: 0.04855726417121077 sdev: 0.009411527205976409\n",
      "Training iteration: 28           last optimization: 25# --> Actions:\n",
      "mean: 0.04857138407931997 sdev: 0.009394138258262933\n",
      "Training iteration: 29           last optimization: 25+ --> Actions:\n",
      "mean: 0.048581381517496094 sdev: 0.009381737437258444\n",
      "Training iteration: 30           last optimization: 30# --> Actions:\n",
      "mean: 0.05100162333707847 sdev: 0.0158104797431207\n",
      "Training iteration: 31           last optimization: 30+ --> Actions:\n",
      "mean: 0.05100718066005362 sdev: 0.015813031676946487\n",
      "Training iteration: 32           last optimization: 30# --> Actions:\n",
      "mean: 0.05100912752820023 sdev: 0.015826365144822396\n",
      "Training iteration: 33           last optimization: 30+ --> Actions:\n",
      "mean: 0.05100624082602685 sdev: 0.01584863486571042\n",
      "Training iteration: 34           last optimization: 30# --> Actions:\n",
      "mean: 0.05100020487582765 sdev: 0.01587577128105137\n",
      "Training iteration: 35           last optimization: 35+ --> Actions:\n",
      "mean: 0.050940047128619124 sdev: 0.016659362311154325\n",
      "Training iteration: 36           last optimization: 35# --> Actions:\n",
      "mean: 0.05094003117198154 sdev: 0.016699134454369834\n",
      "Training iteration: 37           last optimization: 35+ --> Actions:\n",
      "mean: 0.050940857558913644 sdev: 0.016743073918661967\n",
      "Training iteration: 38           last optimization: 35# --> Actions:\n",
      "mean: 0.05094394373429717 sdev: 0.01679024275457512\n",
      "Training iteration: 39           last optimization: 35+ --> Actions:\n",
      "mean: 0.050948887352767626 sdev: 0.016840267504598595\n",
      "Training iteration: 40           last optimization: 40# --> Actions:\n",
      "mean: 0.04950228172829771 sdev: 0.012245144259729803\n",
      "Training iteration: 41           last optimization: 40+ --> Actions:\n",
      "mean: 0.04951230513801297 sdev: 0.012287408320537076\n",
      "Training iteration: 42           last optimization: 40# --> Actions:\n",
      "mean: 0.049520810554626316 sdev: 0.012329393093995944\n",
      "Training iteration: 43           last optimization: 40+ --> Actions:\n",
      "mean: 0.049523613625190574 sdev: 0.012364586831196062\n",
      "Training iteration: 44           last optimization: 40# --> Actions:\n",
      "mean: 0.049515625087688316 sdev: 0.012386483978611012\n",
      "Training iteration: 45           last optimization: 45+ --> Actions:\n",
      "mean: 0.04739478585137695 sdev: 0.006444288858510625\n",
      "Training iteration: 46           last optimization: 45# --> Actions:\n",
      "mean: 0.04737124235268107 sdev: 0.00645022564399758\n",
      "Training iteration: 47           last optimization: 45+ --> Actions:\n",
      "mean: 0.047337422476694854 sdev: 0.006448966296909702\n",
      "Training iteration: 48           last optimization: 45# --> Actions:\n",
      "mean: 0.04729725722851508 sdev: 0.006440399003642722\n",
      "Training iteration: 49           last optimization: 45+ --> Actions:\n",
      "mean: 0.04725232404868252 sdev: 0.006426036676997171\n",
      "Training iteration: 50           last optimization: 50# --> Actions:\n",
      "mean: 0.04518318831683403 sdev: 0.004875448608996819\n",
      "Training iteration: 51           last optimization: 50+ --> Actions:\n",
      "mean: 0.04514669030716466 sdev: 0.004869019861844649\n",
      "Training iteration: 52           last optimization: 50# --> Actions:\n",
      "mean: 0.04511175424993182 sdev: 0.004866458172588244\n",
      "Training iteration: 53           last optimization: 50+ --> Actions:\n",
      "mean: 0.04507921775519174 sdev: 0.004868221010723346\n",
      "Training iteration: 54           last optimization: 50# --> Actions:\n",
      "mean: 0.04505031669365533 sdev: 0.004875397683234986\n",
      "Training iteration: 55           last optimization: 55+ --> Actions:\n",
      "mean: 0.04341136063366312 sdev: 0.0068468619761439834\n",
      "Training iteration: 56           last optimization: 55# --> Actions:\n",
      "mean: 0.04340155366147178 sdev: 0.0068615002665939175\n",
      "Training iteration: 57           last optimization: 55+ --> Actions:\n",
      "mean: 0.04339902124229809 sdev: 0.006877245522851694\n",
      "Training iteration: 58           last optimization: 55# --> Actions:\n",
      "mean: 0.04340334872024727 sdev: 0.006892560101172735\n",
      "Training iteration: 59           last optimization: 55+ --> Actions:\n",
      "mean: 0.04341536050127637 sdev: 0.006905561580885781\n",
      "Training iteration: 60           last optimization: 60# --> Actions:\n",
      "mean: 0.04220951194141198 sdev: 0.00709104994667877\n",
      "Training iteration: 61           last optimization: 60+ --> Actions:\n",
      "mean: 0.042226097383540016 sdev: 0.007099170819314028\n",
      "Training iteration: 62           last optimization: 60# --> Actions:\n",
      "mean: 0.04224580444773121 sdev: 0.007103663111620735\n",
      "Training iteration: 63           last optimization: 60+ --> Actions:\n",
      "mean: 0.042268730906596386 sdev: 0.007104314662362142\n",
      "Training iteration: 64           last optimization: 60# --> Actions:\n",
      "mean: 0.04229474737103737 sdev: 0.007100918199259579\n",
      "Training iteration: 65           last optimization: 65+ --> Actions:\n",
      "mean: 0.04155691860450912 sdev: 0.005765211270722678\n",
      "Training iteration: 66           last optimization: 65# --> Actions:\n",
      "mean: 0.0415820654240966 sdev: 0.005755011477650376\n",
      "Training iteration: 67           last optimization: 65+ --> Actions:\n",
      "mean: 0.04161085821196882 sdev: 0.0057428822772407845\n",
      "Training iteration: 68           last optimization: 65# --> Actions:\n",
      "mean: 0.04164260703679981 sdev: 0.005728937713702473\n",
      "Training iteration: 69           last optimization: 65+ --> Actions:\n",
      "mean: 0.04167734753800241 sdev: 0.005713094688956731\n",
      "Training iteration: 70           last optimization: 70# --> Actions:\n",
      "mean: 0.04120371102738697 sdev: 0.003937419924257317\n",
      "Training iteration: 71           last optimization: 70+ --> Actions:\n",
      "mean: 0.04124012925022956 sdev: 0.003914438816580315\n",
      "Training iteration: 72           last optimization: 70# --> Actions:\n",
      "mean: 0.04127917840461494 sdev: 0.0038902480259660837\n",
      "Training iteration: 73           last optimization: 70+ --> Actions:\n",
      "mean: 0.04131821396633966 sdev: 0.0038656084821692494\n",
      "Training iteration: 74           last optimization: 70# --> Actions:\n",
      "mean: 0.04135494726378346 sdev: 0.0038408799753560353\n",
      "Training iteration: 75           last optimization: 75+ --> Actions:\n",
      "mean: 0.0411046753135982 sdev: 0.003963045816558892\n",
      "Training iteration: 76           last optimization: 75# --> Actions:\n",
      "mean: 0.04112373658280271 sdev: 0.0039892736058039675\n",
      "Training iteration: 77           last optimization: 75+ --> Actions:\n",
      "mean: 0.04113597760613831 sdev: 0.004019116572856384\n",
      "Training iteration: 78           last optimization: 75# --> Actions:\n",
      "mean: 0.041140699525867803 sdev: 0.0040501613741807385\n",
      "Training iteration: 79           last optimization: 75+ --> Actions:\n",
      "mean: 0.0411396956115681 sdev: 0.0040802504939990185\n",
      "Training iteration: 80           last optimization: 80# --> Actions:\n",
      "mean: 0.04110543835877613 sdev: 0.004721185495142828\n",
      "Training iteration: 81           last optimization: 80+ --> Actions:\n",
      "mean: 0.04109373274659055 sdev: 0.004746464718950727\n",
      "Training iteration: 82           last optimization: 80# --> Actions:\n",
      "mean: 0.041079739811737556 sdev: 0.0047614900229927285\n",
      "Training iteration: 83           last optimization: 80+ --> Actions:\n",
      "mean: 0.04106226993215646 sdev: 0.004766674783607076\n",
      "Training iteration: 84           last optimization: 80# --> Actions:\n",
      "mean: 0.04104208407722783 sdev: 0.004761257838097255\n",
      "Training iteration: 85           last optimization: 85+ --> Actions:\n",
      "mean: 0.04093744726735996 sdev: 0.003851772602060854\n",
      "Training iteration: 86           last optimization: 85# --> Actions:\n",
      "mean: 0.040917724597714714 sdev: 0.003808333660750083\n",
      "Training iteration: 87           last optimization: 85+ --> Actions:\n",
      "mean: 0.040898674780241104 sdev: 0.003753965465136656\n",
      "Training iteration: 88           last optimization: 85# --> Actions:\n",
      "mean: 0.04088146762325161 sdev: 0.003691929338487256\n",
      "Training iteration: 89           last optimization: 85+ --> Actions:\n",
      "mean: 0.040867802568120545 sdev: 0.003626763361769173\n",
      "Training iteration: 90           last optimization: 90# --> Actions:\n",
      "mean: 0.040530826260388966 sdev: 0.0017174787356540942\n",
      "Training iteration: 91           last optimization: 90+ --> Actions:\n",
      "mean: 0.04052141405429895 sdev: 0.0016811946394663904\n",
      "Training iteration: 92           last optimization: 90# --> Actions:\n",
      "mean: 0.04051484489855837 sdev: 0.001655009772193127\n",
      "Training iteration: 93           last optimization: 90+ --> Actions:\n",
      "mean: 0.04050959902879218 sdev: 0.001637286133389931\n",
      "Training iteration: 94           last optimization: 90# --> Actions:\n",
      "mean: 0.04050552678372245 sdev: 0.0016256599848298568\n",
      "Training iteration: 95           last optimization: 95+ --> Actions:\n",
      "mean: 0.039707021758228926 sdev: 0.002588225740963868\n",
      "Training iteration: 96           last optimization: 95# --> Actions:\n",
      "mean: 0.039706751287427476 sdev: 0.0026006393808769984\n",
      "Training iteration: 97           last optimization: 95+ --> Actions:\n",
      "mean: 0.03970686628782681 sdev: 0.0026119576255516056\n",
      "Training iteration: 98           last optimization: 95# --> Actions:\n",
      "mean: 0.03970670711037376 sdev: 0.0026233989520553377\n",
      "Training iteration: 99           last optimization: 95+ --> Actions:\n",
      "mean: 0.0397065223640248 sdev: 0.0026352006994650634\n",
      "Training iteration: 100          last optimization: 100# --> Actions:\n",
      "mean: 0.039193674496196595 sdev: 0.00376346947277308\n",
      "Training iteration: 101          last optimization: 100+ --> Actions:\n",
      "mean: 0.03919147642351556 sdev: 0.0037718002545669115\n",
      "Training iteration: 102          last optimization: 100# --> Actions:\n",
      "mean: 0.03918665161401566 sdev: 0.0037827210029978127\n",
      "Training iteration: 103          last optimization: 100+ --> Actions:\n",
      "mean: 0.03918001500215952 sdev: 0.003795245404571851\n",
      "Training iteration: 104          last optimization: 100# --> Actions:\n",
      "mean: 0.039170868633884415 sdev: 0.00380724722212512\n",
      "Training iteration: 105          last optimization: 105+ --> Actions:\n",
      "mean: 0.03897368820816022 sdev: 0.0035638914284643435\n",
      "Training iteration: 106          last optimization: 105# --> Actions:\n",
      "mean: 0.038957527741793896 sdev: 0.003574569881644811\n",
      "Training iteration: 107          last optimization: 105+ --> Actions:\n",
      "mean: 0.03894010174312008 sdev: 0.0035828093924202722\n",
      "Training iteration: 108          last optimization: 105# --> Actions:\n",
      "mean: 0.038921080851249394 sdev: 0.003589689750184175\n",
      "Training iteration: 109          last optimization: 105+ --> Actions:\n",
      "mean: 0.038902274076618136 sdev: 0.0035976633135957766\n",
      "Training iteration: 110          last optimization: 110# --> Actions:\n",
      "mean: 0.0390644095228368 sdev: 0.0021015914522430294\n",
      "Training iteration: 111          last optimization: 110+ --> Actions:\n",
      "mean: 0.039043884477893295 sdev: 0.002121584067172209\n",
      "Training iteration: 112          last optimization: 110# --> Actions:\n",
      "mean: 0.03902192522175178 sdev: 0.0021494718438245194\n",
      "Training iteration: 113          last optimization: 110+ --> Actions:\n",
      "mean: 0.039000191404632414 sdev: 0.002185316057864701\n",
      "Training iteration: 114          last optimization: 110# --> Actions:\n",
      "mean: 0.03897734340594722 sdev: 0.0022294567402696905\n",
      "Training iteration: 115          last optimization: 115+ --> Actions:\n",
      "mean: 0.03949736946547698 sdev: 0.0006868626352554986\n",
      "Training iteration: 116          last optimization: 115# --> Actions:\n",
      "mean: 0.03947128779190745 sdev: 0.0006062879945574886\n",
      "Training iteration: 117          last optimization: 115+ --> Actions:\n",
      "mean: 0.03944801334825928 sdev: 0.0005344851891118264\n",
      "Training iteration: 118          last optimization: 115# --> Actions:\n",
      "mean: 0.039429517627776106 sdev: 0.00047809476529461976\n",
      "Training iteration: 119          last optimization: 115+ --> Actions:\n",
      "mean: 0.03941641684787599 sdev: 0.0004415535398730327\n",
      "Training iteration: 120          last optimization: 120# --> Actions:\n",
      "mean: 0.03909362554825986 sdev: 0.001638288301305141\n",
      "Training iteration: 121          last optimization: 120+ --> Actions:\n",
      "mean: 0.03909212263755387 sdev: 0.0016097988580233435\n",
      "Training iteration: 122          last optimization: 120# --> Actions:\n",
      "mean: 0.03909488651198208 sdev: 0.0015872547552926765\n",
      "Training iteration: 123          last optimization: 120+ --> Actions:\n",
      "mean: 0.03910105824151476 sdev: 0.001572106128176665\n",
      "Training iteration: 124          last optimization: 120# --> Actions:\n",
      "mean: 0.0391109519081652 sdev: 0.001565059395059889\n",
      "Training iteration: 125          last optimization: 125+ --> Actions:\n",
      "mean: 0.03905744766781026 sdev: 0.0016122253303866405\n",
      "Training iteration: 126          last optimization: 125# --> Actions:\n",
      "mean: 0.039074032848883444 sdev: 0.001636586667449533\n",
      "Training iteration: 127          last optimization: 125+ --> Actions:\n",
      "mean: 0.03909248547144813 sdev: 0.0016687639241585973\n",
      "Training iteration: 128          last optimization: 125# --> Actions:\n",
      "mean: 0.039112196150526454 sdev: 0.0017073325213711724\n",
      "Training iteration: 129          last optimization: 125+ --> Actions:\n",
      "mean: 0.03913154844853099 sdev: 0.0017502617405267464\n",
      "Training iteration: 130          last optimization: 130# --> Actions:\n",
      "mean: 0.03899447253158328 sdev: 0.0010602208976166784\n",
      "Training iteration: 131          last optimization: 130+ --> Actions:\n",
      "mean: 0.0390139271156688 sdev: 0.0011198111850263363\n",
      "Training iteration: 132          last optimization: 130# --> Actions:\n",
      "mean: 0.03903274852206239 sdev: 0.0011774986551856994\n",
      "Training iteration: 133          last optimization: 130+ --> Actions:\n",
      "mean: 0.03905047621916465 sdev: 0.0012288963355241683\n",
      "Training iteration: 134          last optimization: 130# --> Actions:\n",
      "mean: 0.03906575826475708 sdev: 0.0012699777887900017\n",
      "Training iteration: 135          last optimization: 135+ --> Actions:\n",
      "mean: 0.03845070125779446 sdev: 0.0010336424888925323\n",
      "Training iteration: 136          last optimization: 135# --> Actions:\n",
      "mean: 0.03846218307318035 sdev: 0.0010109386834361717\n",
      "Training iteration: 137          last optimization: 135+ --> Actions:\n",
      "mean: 0.03847141500498252 sdev: 0.0009977955839611822\n",
      "Training iteration: 138          last optimization: 135# --> Actions:\n",
      "mean: 0.03847785074745115 sdev: 0.0009905062372556415\n",
      "Training iteration: 139          last optimization: 135+ --> Actions:\n",
      "mean: 0.03848246348253414 sdev: 0.0009880542119925695\n",
      "Training iteration: 140          last optimization: 140# --> Actions:\n",
      "mean: 0.038330645343174985 sdev: 0.0012879782912901551\n",
      "Training iteration: 141          last optimization: 140+ --> Actions:\n",
      "mean: 0.03832806264842239 sdev: 0.0012989012418592692\n",
      "Training iteration: 142          last optimization: 140# --> Actions:\n",
      "mean: 0.03832337513429428 sdev: 0.0013152468666097602\n",
      "Training iteration: 143          last optimization: 140+ --> Actions:\n",
      "mean: 0.038316795600329315 sdev: 0.001337939147662478\n",
      "Training iteration: 144          last optimization: 140# --> Actions:\n",
      "mean: 0.038309380298450865 sdev: 0.001367342293992287\n",
      "Training iteration: 145          last optimization: 145+ --> Actions:\n",
      "mean: 0.03861404395216505 sdev: 0.0009417122500321919\n",
      "Training iteration: 146          last optimization: 145# --> Actions:\n",
      "mean: 0.03860231867183529 sdev: 0.0009380822057152414\n",
      "Training iteration: 147          last optimization: 145+ --> Actions:\n",
      "mean: 0.03859256187344874 sdev: 0.0009413530172037059\n",
      "Training iteration: 148          last optimization: 145# --> Actions:\n",
      "mean: 0.03858691036176358 sdev: 0.0009493068363108402\n",
      "Training iteration: 149          last optimization: 145+ --> Actions:\n",
      "mean: 0.03858857651530424 sdev: 0.0009581882351609847\n",
      "Training iteration: 150          last optimization: 150# --> Actions:\n",
      "mean: 0.03880135410134145 sdev: 0.0011246842050090348\n",
      "Training iteration: 151          last optimization: 150+ --> Actions:\n",
      "mean: 0.03881630049521087 sdev: 0.0011432079669509976\n",
      "Training iteration: 152          last optimization: 150# --> Actions:\n",
      "mean: 0.03883779936238195 sdev: 0.0011832421677017443\n",
      "Training iteration: 153          last optimization: 150+ --> Actions:\n",
      "mean: 0.0388635562247641 sdev: 0.0012414593865618534\n",
      "Training iteration: 154          last optimization: 150# --> Actions:\n",
      "mean: 0.03889254497410944 sdev: 0.0013137546997072276\n",
      "Training iteration: 155          last optimization: 155+ --> Actions:\n",
      "mean: 0.03854333077486478 sdev: 0.0010301035004059707\n",
      "Training iteration: 156          last optimization: 155# --> Actions:\n",
      "mean: 0.038574584072159065 sdev: 0.0010916559272878034\n",
      "Training iteration: 157          last optimization: 155+ --> Actions:\n",
      "mean: 0.038606063167084315 sdev: 0.0011619840079870527\n",
      "Training iteration: 158          last optimization: 155# --> Actions:\n",
      "mean: 0.03863622891843753 sdev: 0.0012373586364480505\n",
      "Training iteration: 159          last optimization: 155+ --> Actions:\n",
      "mean: 0.03866491433346036 sdev: 0.0013144043993072666\n",
      "Training iteration: 160          last optimization: 160# --> Actions:\n",
      "mean: 0.038100532615055874 sdev: 0.0008797142122990463\n",
      "Training iteration: 161          last optimization: 160+ --> Actions:\n",
      "mean: 0.038127086727040446 sdev: 0.0008455781436447293\n",
      "Training iteration: 162          last optimization: 160# --> Actions:\n",
      "mean: 0.0381516874281235 sdev: 0.0008221415152182566\n",
      "Training iteration: 163          last optimization: 160+ --> Actions:\n",
      "mean: 0.038172011189702044 sdev: 0.0008071166395859461\n",
      "Training iteration: 164          last optimization: 160# --> Actions:\n",
      "mean: 0.038185835915982666 sdev: 0.0007979728300527542\n",
      "Training iteration: 165          last optimization: 165+ --> Actions:\n",
      "mean: 0.038055091553610976 sdev: 0.00112285815564583\n",
      "Training iteration: 166          last optimization: 165# --> Actions:\n",
      "mean: 0.03805223217700475 sdev: 0.0011370114639299139\n",
      "Training iteration: 167          last optimization: 165+ --> Actions:\n",
      "mean: 0.03803942574000073 sdev: 0.0011625483672213003\n",
      "Training iteration: 168          last optimization: 165# --> Actions:\n",
      "mean: 0.03801873140646644 sdev: 0.0011982069165700744\n",
      "Training iteration: 169          last optimization: 165+ --> Actions:\n",
      "mean: 0.03799227089637599 sdev: 0.0012422014712656396\n",
      "Training iteration: 170          last optimization: 170# --> Actions:\n",
      "mean: 0.03794988961220008 sdev: 0.0014391599122349809\n",
      "Training iteration: 171          last optimization: 170+ --> Actions:\n",
      "mean: 0.03791477482121826 sdev: 0.0014815494466092157\n",
      "Training iteration: 172          last optimization: 170# --> Actions:\n",
      "mean: 0.03787856966248576 sdev: 0.0015317030061470609\n",
      "Training iteration: 173          last optimization: 170+ --> Actions:\n",
      "mean: 0.037841644588976424 sdev: 0.0015914499753659596\n",
      "Training iteration: 174          last optimization: 170# --> Actions:\n",
      "mean: 0.037803333275910705 sdev: 0.0016617923730759447\n",
      "Training iteration: 175          last optimization: 175+ --> Actions:\n",
      "mean: 0.037892729998947675 sdev: 0.0009035198402404079\n",
      "Training iteration: 176          last optimization: 175# --> Actions:\n",
      "mean: 0.03784978530864893 sdev: 0.0009957493534175931\n",
      "Training iteration: 177          last optimization: 175+ --> Actions:\n",
      "mean: 0.03780961374888245 sdev: 0.0011031158927656594\n",
      "Training iteration: 178          last optimization: 175# --> Actions:\n",
      "mean: 0.037772220092766984 sdev: 0.0012182542802724387\n",
      "Training iteration: 179          last optimization: 175+ --> Actions:\n",
      "mean: 0.03774116001909449 sdev: 0.0013288974269160276\n",
      "Training iteration: 180          last optimization: 180# --> Actions:\n",
      "mean: 0.03810095159997724 sdev: 0.0005810195879246821\n",
      "Training iteration: 181          last optimization: 180+ --> Actions:\n",
      "mean: 0.0380867172849483 sdev: 0.0005290335161973797\n",
      "Training iteration: 182          last optimization: 180# --> Actions:\n",
      "mean: 0.03808462675415639 sdev: 0.0005087953288665945\n",
      "Training iteration: 183          last optimization: 180+ --> Actions:\n",
      "mean: 0.03809186468551259 sdev: 0.000514586972563208\n",
      "Training iteration: 184          last optimization: 180# --> Actions:\n",
      "mean: 0.0381059249270447 sdev: 0.0005427318325302708\n",
      "Training iteration: 185          last optimization: 185+ --> Actions:\n",
      "mean: 0.03812141182898808 sdev: 0.0011516279495447374\n",
      "Training iteration: 186          last optimization: 185# --> Actions:\n",
      "mean: 0.03814328216640618 sdev: 0.001211512672797132\n",
      "Training iteration: 187          last optimization: 185+ --> Actions:\n",
      "mean: 0.03816527523423806 sdev: 0.001283602653848658\n",
      "Training iteration: 188          last optimization: 185# --> Actions:\n",
      "mean: 0.038187325329201445 sdev: 0.0013640427344585938\n",
      "Training iteration: 189          last optimization: 185+ --> Actions:\n",
      "mean: 0.03820859807435644 sdev: 0.0014489485376159852\n",
      "Training iteration: 190          last optimization: 190# --> Actions:\n",
      "mean: 0.03793011038468565 sdev: 0.0009991209807344525\n",
      "Training iteration: 191          last optimization: 190+ --> Actions:\n",
      "mean: 0.03795166710602554 sdev: 0.0010658634575762434\n",
      "Training iteration: 192          last optimization: 190# --> Actions:\n",
      "mean: 0.03797121393498129 sdev: 0.0011337549477331344\n",
      "Training iteration: 193          last optimization: 190+ --> Actions:\n",
      "mean: 0.03798802876245068 sdev: 0.0011965614126426393\n",
      "Training iteration: 194          last optimization: 190# --> Actions:\n",
      "mean: 0.03799998702768833 sdev: 0.0012473717479743374\n",
      "Training iteration: 195          last optimization: 195+ --> Actions:\n",
      "mean: 0.03756687702725651 sdev: 0.0005092669956222798\n",
      "Training iteration: 196          last optimization: 195# --> Actions:\n",
      "mean: 0.03756626669221051 sdev: 0.0004915857869495332\n",
      "Training iteration: 197          last optimization: 195+ --> Actions:\n",
      "mean: 0.037557134540152345 sdev: 0.0005069550095244874\n",
      "Training iteration: 198          last optimization: 195# --> Actions:\n",
      "mean: 0.03753815300440768 sdev: 0.0005546895292813512\n",
      "Training iteration: 199          last optimization: 195+ --> Actions:\n",
      "mean: 0.037512607516385674 sdev: 0.0006268333767028717\n",
      "Training iteration: 200          last optimization: 200# --> Actions:\n",
      "mean: 0.03770572077690672 sdev: 0.0012862877656051072\n",
      "Training iteration: 201          last optimization: 200+ --> Actions:\n",
      "mean: 0.037670864033155 sdev: 0.001285608924581923\n",
      "Training iteration: 202          last optimization: 200# --> Actions:\n",
      "mean: 0.03763529607934573 sdev: 0.0012937434687885594\n",
      "Training iteration: 203          last optimization: 200+ --> Actions:\n",
      "mean: 0.03760039981222496 sdev: 0.0013119777409037199\n",
      "Training iteration: 204          last optimization: 200# --> Actions:\n",
      "mean: 0.03756665573594707 sdev: 0.001340995890864975\n",
      "Training iteration: 205          last optimization: 205+ --> Actions:\n",
      "mean: 0.037613999344769874 sdev: 0.0013239948708417444\n",
      "Training iteration: 206          last optimization: 205# --> Actions:\n",
      "mean: 0.037580682507613955 sdev: 0.0013468462835536667\n",
      "Training iteration: 207          last optimization: 205+ --> Actions:\n",
      "mean: 0.037551563602948354 sdev: 0.0013807220089457923\n",
      "Training iteration: 208          last optimization: 205# --> Actions:\n",
      "mean: 0.037530497194937486 sdev: 0.0014204770577358943\n",
      "Training iteration: 209          last optimization: 205+ --> Actions:\n",
      "mean: 0.037518999661394006 sdev: 0.0014568242837448568\n",
      "Training iteration: 210          last optimization: 210# --> Actions:\n",
      "mean: 0.03754860052147926 sdev: 0.0004696884549552388\n",
      "Training iteration: 211          last optimization: 210+ --> Actions:\n",
      "mean: 0.03756042354663973 sdev: 0.00047123741770716205\n",
      "Training iteration: 212          last optimization: 210# --> Actions:\n",
      "mean: 0.037584137482139554 sdev: 0.0004499300826436124\n",
      "Training iteration: 213          last optimization: 210+ --> Actions:\n",
      "mean: 0.03761648264013348 sdev: 0.00042310073834832674\n",
      "Training iteration: 214          last optimization: 210# --> Actions:\n",
      "mean: 0.037654246467998906 sdev: 0.0004150898817530418\n",
      "Training iteration: 215          last optimization: 215+ --> Actions:\n",
      "mean: 0.03780199567802838 sdev: 0.0017110017408573054\n",
      "Training iteration: 216          last optimization: 215# --> Actions:\n",
      "mean: 0.037844496368345464 sdev: 0.0018128972642641288\n",
      "Training iteration: 217          last optimization: 215+ --> Actions:\n",
      "mean: 0.037887758234963084 sdev: 0.001928743952310112\n",
      "Training iteration: 218          last optimization: 215# --> Actions:\n",
      "mean: 0.03793210363691167 sdev: 0.0020553238408644752\n",
      "Training iteration: 219          last optimization: 215+ --> Actions:\n",
      "mean: 0.03797621823225487 sdev: 0.002189280257293115\n",
      "Training iteration: 220          last optimization: 220# --> Actions:\n",
      "mean: 0.03785055356959373 sdev: 0.0028634644829677552\n",
      "Training iteration: 221          last optimization: 220+ --> Actions:\n",
      "mean: 0.037893577144909554 sdev: 0.0029777548726495754\n",
      "Training iteration: 222          last optimization: 220# --> Actions:\n",
      "mean: 0.03793744676009934 sdev: 0.0030954178545498172\n",
      "Training iteration: 223          last optimization: 220+ --> Actions:\n",
      "mean: 0.03798107809434327 sdev: 0.003211685265591706\n",
      "Training iteration: 224          last optimization: 220# --> Actions:\n",
      "mean: 0.03802336121031181 sdev: 0.0033223567445811006\n",
      "Training iteration: 225          last optimization: 225+ --> Actions:\n",
      "mean: 0.03766834631351283 sdev: 0.0027821927267112547\n",
      "Training iteration: 226          last optimization: 225# --> Actions:\n",
      "mean: 0.03770218140058744 sdev: 0.002843241464914354\n",
      "Training iteration: 227          last optimization: 225+ --> Actions:\n",
      "mean: 0.037728583604520416 sdev: 0.002885068898387582\n",
      "Training iteration: 228          last optimization: 225# --> Actions:\n",
      "mean: 0.03774376385703029 sdev: 0.0029010132561920077\n",
      "Training iteration: 229          last optimization: 225+ --> Actions:\n",
      "mean: 0.03774561362723948 sdev: 0.002890100389817551\n",
      "Training iteration: 230          last optimization: 230# --> Actions:\n",
      "mean: 0.037255067375961584 sdev: 0.0015770841087618126\n",
      "Training iteration: 231          last optimization: 230+ --> Actions:\n",
      "mean: 0.03723669668578622 sdev: 0.0015900430697723042\n",
      "Training iteration: 232          last optimization: 230# --> Actions:\n",
      "mean: 0.03721154006266454 sdev: 0.0016121973542308308\n",
      "Training iteration: 233          last optimization: 230+ --> Actions:\n",
      "mean: 0.03718247154427581 sdev: 0.001643018736083497\n",
      "Training iteration: 234          last optimization: 230# --> Actions:\n",
      "mean: 0.03715025311712139 sdev: 0.0016821334199247167\n",
      "Training iteration: 235          last optimization: 235+ --> Actions:\n",
      "mean: 0.03698851762819326 sdev: 0.0014819355796071721\n",
      "Training iteration: 236          last optimization: 235# --> Actions:\n",
      "mean: 0.036951006827848965 sdev: 0.001596802159771339\n",
      "Training iteration: 237          last optimization: 235+ --> Actions:\n",
      "mean: 0.03691280780253879 sdev: 0.0017197230515844076\n",
      "Training iteration: 238          last optimization: 235# --> Actions:\n",
      "mean: 0.036874715151268486 sdev: 0.0018491188911499267\n",
      "Training iteration: 239          last optimization: 235+ --> Actions:\n",
      "mean: 0.03683863168730679 sdev: 0.001979009089129772\n",
      "Training iteration: 240          last optimization: 240# --> Actions:\n",
      "mean: 0.03727819972603554 sdev: 0.0024789473958636314\n",
      "Training iteration: 241          last optimization: 240+ --> Actions:\n",
      "mean: 0.03725476940024897 sdev: 0.0025191199807506367\n",
      "Training iteration: 242          last optimization: 240# --> Actions:\n",
      "mean: 0.0372424544277253 sdev: 0.00255385897572646\n",
      "Training iteration: 243          last optimization: 240+ --> Actions:\n",
      "mean: 0.03724169919100213 sdev: 0.0025781483210581737\n",
      "Training iteration: 244          last optimization: 240# --> Actions:\n",
      "mean: 0.03725063646341488 sdev: 0.0025891548678702763\n",
      "Training iteration: 245          last optimization: 245+ --> Actions:\n",
      "mean: 0.0376992294922836 sdev: 0.003115064099136931\n",
      "Training iteration: 246          last optimization: 245# --> Actions:\n",
      "mean: 0.03772091923174206 sdev: 0.003136363803401516\n",
      "Training iteration: 247          last optimization: 245+ --> Actions:\n",
      "mean: 0.03774757272147823 sdev: 0.0031607393587014805\n",
      "Training iteration: 248          last optimization: 245# --> Actions:\n",
      "mean: 0.03777665531126169 sdev: 0.0031886565006927947\n",
      "Training iteration: 249          last optimization: 245+ --> Actions:\n",
      "mean: 0.037806965458539656 sdev: 0.003219158327280863\n",
      "Training iteration: 250          last optimization: 250# --> Actions:\n",
      "mean: 0.038036909641908034 sdev: 0.0029763483364880993\n",
      "Training iteration: 251          last optimization: 250+ --> Actions:\n",
      "mean: 0.03806677943437094 sdev: 0.0030306906328088413\n",
      "Training iteration: 252          last optimization: 250# --> Actions:\n",
      "mean: 0.03809425732850531 sdev: 0.0030850085711739534\n",
      "Training iteration: 253          last optimization: 250+ --> Actions:\n",
      "mean: 0.03811855735373275 sdev: 0.0031366645600302877\n",
      "Training iteration: 254          last optimization: 250# --> Actions:\n",
      "mean: 0.03813884680551047 sdev: 0.0031833773608477374\n",
      "Training iteration: 255          last optimization: 255+ --> Actions:\n",
      "mean: 0.03798942405698112 sdev: 0.0016049558312507932\n",
      "Training iteration: 256          last optimization: 255# --> Actions:\n",
      "mean: 0.03799417702742842 sdev: 0.0016271489628523828\n",
      "Training iteration: 257          last optimization: 255+ --> Actions:\n",
      "mean: 0.03798946636765786 sdev: 0.0016288661820419996\n",
      "Training iteration: 258          last optimization: 255# --> Actions:\n",
      "mean: 0.03797449940320515 sdev: 0.0016070777389314015\n",
      "Training iteration: 259          last optimization: 255+ --> Actions:\n",
      "mean: 0.03794924662698526 sdev: 0.0015656066137615682\n",
      "Training iteration: 260          last optimization: 260# --> Actions:\n",
      "mean: 0.037418809912059633 sdev: 0.0015569125987693396\n",
      "Training iteration: 261          last optimization: 260+ --> Actions:\n",
      "mean: 0.03738560528417336 sdev: 0.0016295034218288286\n",
      "Training iteration: 262          last optimization: 260# --> Actions:\n",
      "mean: 0.037349608437515634 sdev: 0.0017118075084728908\n",
      "Training iteration: 263          last optimization: 260+ --> Actions:\n",
      "mean: 0.037311727036505704 sdev: 0.0017987695280097683\n",
      "Training iteration: 264          last optimization: 260# --> Actions:\n",
      "mean: 0.0372729531504568 sdev: 0.0018889280296178336\n",
      "Training iteration: 265          last optimization: 265+ --> Actions:\n",
      "mean: 0.03720158943801292 sdev: 0.002888430646538666\n",
      "Training iteration: 266          last optimization: 265# --> Actions:\n",
      "mean: 0.03716081507173409 sdev: 0.0029598944091740733\n",
      "Training iteration: 267          last optimization: 265+ --> Actions:\n",
      "mean: 0.037121132201999224 sdev: 0.0030343871353653304\n",
      "Training iteration: 268          last optimization: 265# --> Actions:\n",
      "mean: 0.03708311764996992 sdev: 0.003109320178527511\n",
      "Training iteration: 269          last optimization: 265+ --> Actions:\n",
      "mean: 0.03704812930242675 sdev: 0.00318090560178155\n",
      "Training iteration: 270          last optimization: 270# --> Actions:\n",
      "mean: 0.03732592932871583 sdev: 0.002750930602211134\n",
      "Training iteration: 271          last optimization: 270+ --> Actions:\n",
      "mean: 0.037301653313078845 sdev: 0.002782249350226681\n",
      "Training iteration: 272          last optimization: 270# --> Actions:\n",
      "mean: 0.037288042393815814 sdev: 0.00279809814322209\n",
      "Training iteration: 273          last optimization: 270+ --> Actions:\n",
      "mean: 0.03728547160116555 sdev: 0.002795904653667954\n",
      "Training iteration: 274          last optimization: 270# --> Actions:\n",
      "mean: 0.0372928755840244 sdev: 0.0027762310134520816\n",
      "Training iteration: 275          last optimization: 275+ --> Actions:\n",
      "mean: 0.0378716515184889 sdev: 0.0016443078411960427\n",
      "Training iteration: 276          last optimization: 275# --> Actions:\n",
      "mean: 0.03788917812019203 sdev: 0.0016537229104206044\n",
      "Training iteration: 277          last optimization: 275+ --> Actions:\n",
      "mean: 0.03791108075692403 sdev: 0.0016731749361821844\n",
      "Training iteration: 278          last optimization: 275# --> Actions:\n",
      "mean: 0.03793528873353791 sdev: 0.0017021841480250627\n",
      "Training iteration: 279          last optimization: 275+ --> Actions:\n",
      "mean: 0.03796008083693432 sdev: 0.0017403341050891078\n",
      "Training iteration: 280          last optimization: 280# --> Actions:\n",
      "mean: 0.03835367336737421 sdev: 0.0022843010417454815\n",
      "Training iteration: 281          last optimization: 280+ --> Actions:\n",
      "mean: 0.03837952766046342 sdev: 0.0023886563653155255\n",
      "Training iteration: 282          last optimization: 280# --> Actions:\n",
      "mean: 0.038405618681718205 sdev: 0.002493107958433215\n",
      "Training iteration: 283          last optimization: 280+ --> Actions:\n",
      "mean: 0.038431211741778167 sdev: 0.0025964931945689647\n",
      "Training iteration: 284          last optimization: 280# --> Actions:\n",
      "mean: 0.03845620706482596 sdev: 0.002696070279606044\n",
      "Training iteration: 285          last optimization: 285+ --> Actions:\n",
      "mean: 0.03826166036534373 sdev: 0.002600873768918978\n",
      "Training iteration: 286          last optimization: 285# --> Actions:\n",
      "mean: 0.038284376190249506 sdev: 0.002676348139603158\n",
      "Training iteration: 287          last optimization: 285+ --> Actions:\n",
      "mean: 0.03830389521920809 sdev: 0.0027395920159191066\n",
      "Training iteration: 288          last optimization: 285# --> Actions:\n",
      "mean: 0.03831821671068877 sdev: 0.0027875555051423903\n",
      "Training iteration: 289          last optimization: 285+ --> Actions:\n",
      "mean: 0.03832664666828329 sdev: 0.002816883065006353\n",
      "Training iteration: 290          last optimization: 290# --> Actions:\n",
      "mean: 0.03765311122840089 sdev: 0.0016334838579229022\n",
      "Training iteration: 291          last optimization: 290+ --> Actions:\n",
      "mean: 0.037653908655056835 sdev: 0.0016301064565411422\n",
      "Training iteration: 292          last optimization: 290# --> Actions:\n",
      "mean: 0.03765075995709436 sdev: 0.0016193108989181616\n",
      "Training iteration: 293          last optimization: 290+ --> Actions:\n",
      "mean: 0.03764473166342216 sdev: 0.0016032149046822245\n",
      "Training iteration: 294          last optimization: 290# --> Actions:\n",
      "mean: 0.03763619245272884 sdev: 0.0015839446654596623\n",
      "Training iteration: 295          last optimization: 295+ --> Actions:\n",
      "mean: 0.03684359870911573 sdev: 0.002059311229451928\n",
      "Training iteration: 296          last optimization: 295# --> Actions:\n",
      "mean: 0.03683672968000249 sdev: 0.002079958376065334\n",
      "Training iteration: 297          last optimization: 295+ --> Actions:\n",
      "mean: 0.03682999385203249 sdev: 0.002103743552763979\n",
      "Training iteration: 298          last optimization: 295# --> Actions:\n",
      "mean: 0.03682300564884773 sdev: 0.0021288216117906784\n",
      "Training iteration: 299          last optimization: 295+ --> Actions:\n",
      "mean: 0.03681684026419023 sdev: 0.002152793652116273\n",
      "Training iteration: 300          last optimization: 300# --> Actions:\n",
      "mean: 0.03651183130687348 sdev: 0.002839538384024658\n",
      "Training iteration: 301          last optimization: 300+ --> Actions:\n",
      "mean: 0.03651218043216063 sdev: 0.0028519460148726614\n",
      "Training iteration: 302          last optimization: 300# --> Actions:\n",
      "mean: 0.036516281848306596 sdev: 0.0028550192869082397\n",
      "Training iteration: 303          last optimization: 300+ --> Actions:\n",
      "mean: 0.036524536021028425 sdev: 0.0028473378209468198\n",
      "Training iteration: 304          last optimization: 300# --> Actions:\n",
      "mean: 0.036536774513381456 sdev: 0.0028289801948115497\n",
      "Training iteration: 305          last optimization: 305+ --> Actions:\n",
      "mean: 0.03670135518090173 sdev: 0.0022960559360169835\n",
      "Training iteration: 306          last optimization: 305# --> Actions:\n",
      "mean: 0.03671907224572384 sdev: 0.0022650726803360153\n",
      "Training iteration: 307          last optimization: 305+ --> Actions:\n",
      "mean: 0.03673881173313404 sdev: 0.002228276018971648\n",
      "Training iteration: 308          last optimization: 305# --> Actions:\n",
      "mean: 0.036759553155186336 sdev: 0.0021872189334653275\n",
      "Training iteration: 309          last optimization: 305+ --> Actions:\n",
      "mean: 0.03678106575954621 sdev: 0.002142733219570018\n",
      "Training iteration: 310          last optimization: 310# --> Actions:\n",
      "mean: 0.0373759856275802 sdev: 0.000546752603455578\n",
      "Training iteration: 311          last optimization: 310+ --> Actions:\n",
      "mean: 0.037396252025356916 sdev: 0.0005201004106114114\n",
      "Training iteration: 312          last optimization: 310# --> Actions:\n",
      "mean: 0.0374153275227524 sdev: 0.000495724587667228\n",
      "Training iteration: 313          last optimization: 310+ --> Actions:\n",
      "mean: 0.037433060208731085 sdev: 0.0004741292066068625\n",
      "Training iteration: 314          last optimization: 310# --> Actions:\n",
      "mean: 0.037450278317391075 sdev: 0.00045743012806051845\n",
      "Training iteration: 315          last optimization: 315+ --> Actions:\n",
      "mean: 0.03831575431263372 sdev: 0.0023854073410610236\n",
      "Training iteration: 316          last optimization: 315# --> Actions:\n",
      "mean: 0.038328154480251765 sdev: 0.002402167477405691\n",
      "Training iteration: 317          last optimization: 315+ --> Actions:\n",
      "mean: 0.03833733119745092 sdev: 0.002409496486379612\n",
      "Training iteration: 318          last optimization: 315# --> Actions:\n",
      "mean: 0.038342482015370646 sdev: 0.0024063291156515105\n",
      "Training iteration: 319          last optimization: 315+ --> Actions:\n",
      "mean: 0.03834305966703217 sdev: 0.002392827804369818\n",
      "Training iteration: 320          last optimization: 320# --> Actions:\n",
      "mean: 0.038561793174178655 sdev: 0.0031703931246567264\n",
      "Training iteration: 321          last optimization: 320+ --> Actions:\n",
      "mean: 0.03855297563547011 sdev: 0.0031414669466772478\n",
      "Training iteration: 322          last optimization: 320# --> Actions:\n",
      "mean: 0.038540376763296746 sdev: 0.003107284916298828\n",
      "Training iteration: 323          last optimization: 320+ --> Actions:\n",
      "mean: 0.03852462349222576 sdev: 0.0030691057668955223\n",
      "Training iteration: 324          last optimization: 320# --> Actions:\n",
      "mean: 0.03850583407548994 sdev: 0.0030247247747197544\n",
      "Training iteration: 325          last optimization: 325+ --> Actions:\n",
      "mean: 0.03814538428703997 sdev: 0.002212856280615322\n",
      "Training iteration: 326          last optimization: 325# --> Actions:\n",
      "mean: 0.03812484635639824 sdev: 0.00216333538726945\n",
      "Training iteration: 327          last optimization: 325+ --> Actions:\n",
      "mean: 0.03810265670220224 sdev: 0.002106496021492831\n",
      "Training iteration: 328          last optimization: 325# --> Actions:\n",
      "mean: 0.03807811312406766 sdev: 0.0020427331728305716\n",
      "Training iteration: 329          last optimization: 325+ --> Actions:\n",
      "mean: 0.038051240893987634 sdev: 0.0019732666242415417\n",
      "Training iteration: 330          last optimization: 330# --> Actions:\n",
      "mean: 0.037253825927110094 sdev: 0.00034922450055922577\n",
      "Training iteration: 331          last optimization: 330+ --> Actions:\n",
      "mean: 0.03723078599696999 sdev: 0.0003711034113002094\n",
      "Training iteration: 332          last optimization: 330# --> Actions:\n",
      "mean: 0.03720876346661165 sdev: 0.00040112498532147403\n",
      "Training iteration: 333          last optimization: 330+ --> Actions:\n",
      "mean: 0.0371897295175931 sdev: 0.0004350334504495777\n",
      "Training iteration: 334          last optimization: 330# --> Actions:\n",
      "mean: 0.03717366195816213 sdev: 0.0004684571475331622\n",
      "Training iteration: 335          last optimization: 335+ --> Actions:\n",
      "mean: 0.036810244823401186 sdev: 0.0012658561531516854\n",
      "Training iteration: 336          last optimization: 335# --> Actions:\n",
      "mean: 0.0367988381361949 sdev: 0.0012982214449180954\n",
      "Training iteration: 337          last optimization: 335+ --> Actions:\n",
      "mean: 0.036790546831991684 sdev: 0.0013219804225651957\n",
      "Training iteration: 338          last optimization: 335# --> Actions:\n",
      "mean: 0.03678420924746306 sdev: 0.0013382898843871613\n",
      "Training iteration: 339          last optimization: 335+ --> Actions:\n",
      "mean: 0.036779830841745964 sdev: 0.0013487510161534408\n",
      "Training iteration: 340          last optimization: 340# --> Actions:\n",
      "mean: 0.03691420244019268 sdev: 0.0009641367801248717\n",
      "Training iteration: 341          last optimization: 340+ --> Actions:\n",
      "mean: 0.03691013674977566 sdev: 0.0009699873830248954\n",
      "Training iteration: 342          last optimization: 340# --> Actions:\n",
      "mean: 0.036906928460015136 sdev: 0.0009741327386755668\n",
      "Training iteration: 343          last optimization: 340+ --> Actions:\n",
      "mean: 0.036902775271960384 sdev: 0.0009782528140026697\n",
      "Training iteration: 344          last optimization: 340# --> Actions:\n",
      "mean: 0.03689802052090406 sdev: 0.0009826588669915495\n",
      "Training iteration: 345          last optimization: 345+ --> Actions:\n",
      "mean: 0.03737321869909064 sdev: 0.0007759742354056445\n",
      "Training iteration: 346          last optimization: 345# --> Actions:\n",
      "mean: 0.03736572264992195 sdev: 0.000769251713767184\n",
      "Training iteration: 347          last optimization: 345+ --> Actions:\n",
      "mean: 0.037358343408221396 sdev: 0.0007635164428230372\n",
      "Training iteration: 348          last optimization: 345# --> Actions:\n",
      "mean: 0.03735186769139728 sdev: 0.0007599507705539126\n",
      "Training iteration: 349          last optimization: 345+ --> Actions:\n",
      "mean: 0.03734672312800922 sdev: 0.0007591993119242814\n",
      "Training iteration: 350          last optimization: 350# --> Actions:\n",
      "mean: 0.037464096970888726 sdev: 0.0008858914795892532\n",
      "Training iteration: 351          last optimization: 350+ --> Actions:\n",
      "mean: 0.03746225405564925 sdev: 0.0008942103222183531\n",
      "Training iteration: 352          last optimization: 350# --> Actions:\n",
      "mean: 0.037461342275197124 sdev: 0.0009057344706698221\n",
      "Training iteration: 353          last optimization: 350+ --> Actions:\n",
      "mean: 0.037461574664740316 sdev: 0.0009187554507722321\n",
      "Training iteration: 354          last optimization: 350# --> Actions:\n",
      "mean: 0.037462361238934566 sdev: 0.000931548407876056\n",
      "Training iteration: 355          last optimization: 355+ --> Actions:\n",
      "mean: 0.037133412942147316 sdev: 0.0006691353483486377\n",
      "Training iteration: 356          last optimization: 355# --> Actions:\n",
      "mean: 0.037136082618271636 sdev: 0.0006689280667832386\n",
      "Training iteration: 357          last optimization: 355+ --> Actions:\n",
      "mean: 0.03713942187039781 sdev: 0.0006679456049384306\n",
      "Training iteration: 358          last optimization: 355# --> Actions:\n",
      "mean: 0.037142028337677956 sdev: 0.000666708874852659\n",
      "Training iteration: 359          last optimization: 355+ --> Actions:\n",
      "mean: 0.03714376302758333 sdev: 0.0006650049398598933\n",
      "Training iteration: 360          last optimization: 360# --> Actions:\n",
      "mean: 0.036833217930305244 sdev: 0.0007303579223938907\n",
      "Training iteration: 361          last optimization: 360+ --> Actions:\n",
      "mean: 0.0368352118988789 sdev: 0.0007211510773779653\n",
      "Training iteration: 362          last optimization: 360# --> Actions:\n",
      "mean: 0.036837947220026354 sdev: 0.0007109597690817844\n",
      "Training iteration: 363          last optimization: 360+ --> Actions:\n",
      "mean: 0.03684114024709227 sdev: 0.0007001326387901014\n",
      "Training iteration: 364          last optimization: 360# --> Actions:\n",
      "mean: 0.036844848913471305 sdev: 0.0006876123739635689\n",
      "Training iteration: 365          last optimization: 365+ --> Actions:\n",
      "mean: 0.03693544994708507 sdev: 0.0006222796955602493\n",
      "Training iteration: 366          last optimization: 365# --> Actions:\n",
      "mean: 0.03693855641813805 sdev: 0.0006150941360711257\n",
      "Training iteration: 367          last optimization: 365+ --> Actions:\n",
      "mean: 0.036941489416538756 sdev: 0.0006065826946850858\n",
      "Training iteration: 368          last optimization: 365# --> Actions:\n",
      "mean: 0.03694523704968143 sdev: 0.0005970284796270905\n",
      "Training iteration: 369          last optimization: 365+ --> Actions:\n",
      "mean: 0.03694945396394325 sdev: 0.0005875449454227463\n",
      "Training iteration: 370          last optimization: 370# --> Actions:\n",
      "mean: 0.03710181343148418 sdev: 0.0005830788797294501\n",
      "Training iteration: 371          last optimization: 370+ --> Actions:\n",
      "mean: 0.03710369609756804 sdev: 0.0005886215285865852\n",
      "Training iteration: 372          last optimization: 370# --> Actions:\n",
      "mean: 0.03710555644811657 sdev: 0.0005954921926938306\n",
      "Training iteration: 373          last optimization: 370+ --> Actions:\n",
      "mean: 0.03710830814811975 sdev: 0.0006039349243118129\n",
      "Training iteration: 374          last optimization: 370# --> Actions:\n",
      "mean: 0.03711236956515994 sdev: 0.0006149293512851902\n",
      "Training iteration: 375          last optimization: 375+ --> Actions:\n",
      "mean: 0.03689697470965583 sdev: 0.0005476565725421911\n",
      "Training iteration: 376          last optimization: 375# --> Actions:\n",
      "mean: 0.03690535360730582 sdev: 0.0005517128754771914\n",
      "Training iteration: 377          last optimization: 375+ --> Actions:\n",
      "mean: 0.036917259610530176 sdev: 0.000558416861248441\n",
      "Training iteration: 378          last optimization: 375# --> Actions:\n",
      "mean: 0.03693265715797981 sdev: 0.0005688777407560784\n",
      "Training iteration: 379          last optimization: 375+ --> Actions:\n",
      "mean: 0.036950765600239494 sdev: 0.0005845897529594776\n",
      "Training iteration: 380          last optimization: 380# --> Actions:\n",
      "mean: 0.036790839295279876 sdev: 0.0005114871675897116\n",
      "Training iteration: 381          last optimization: 380+ --> Actions:\n",
      "mean: 0.03681121616223203 sdev: 0.0004991029530555969\n",
      "Training iteration: 382          last optimization: 380# --> Actions:\n",
      "mean: 0.03683253065602689 sdev: 0.0004937834382750427\n",
      "Training iteration: 383          last optimization: 380+ --> Actions:\n",
      "mean: 0.036854109070917566 sdev: 0.0004966023951513195\n",
      "Training iteration: 384          last optimization: 380# --> Actions:\n",
      "mean: 0.03687484494395481 sdev: 0.0005050337687124597\n",
      "Training iteration: 385          last optimization: 385+ --> Actions:\n",
      "mean: 0.03688809801822219 sdev: 0.0005262775955693674\n",
      "Training iteration: 386          last optimization: 385# --> Actions:\n",
      "mean: 0.036907759754520694 sdev: 0.0005420963848923149\n",
      "Training iteration: 387          last optimization: 385+ --> Actions:\n",
      "mean: 0.036925288209380416 sdev: 0.0005586731515365669\n",
      "Training iteration: 388          last optimization: 385# --> Actions:\n",
      "mean: 0.03694026056604381 sdev: 0.000574065294386171\n",
      "Training iteration: 389          last optimization: 385+ --> Actions:\n",
      "mean: 0.036953066616969746 sdev: 0.0005858267732604935\n",
      "Training iteration: 390          last optimization: 390# --> Actions:\n",
      "mean: 0.036739047787305565 sdev: 0.0005858597035453704\n",
      "Training iteration: 391          last optimization: 390+ --> Actions:\n",
      "mean: 0.03674641794329619 sdev: 0.0005883782040079399\n",
      "Training iteration: 392          last optimization: 390# --> Actions:\n",
      "mean: 0.03674942790385845 sdev: 0.0005962237264951018\n",
      "Training iteration: 393          last optimization: 390+ --> Actions:\n",
      "mean: 0.03674835674579889 sdev: 0.0006087836972970998\n",
      "Training iteration: 394          last optimization: 390# --> Actions:\n",
      "mean: 0.03674332434255718 sdev: 0.0006252350085159196\n",
      "Training iteration: 395          last optimization: 395+ --> Actions:\n",
      "mean: 0.03671266784671111 sdev: 0.0004545839511514103\n",
      "Training iteration: 396          last optimization: 395# --> Actions:\n",
      "mean: 0.03670163697210954 sdev: 0.0004896540812422012\n",
      "Training iteration: 397          last optimization: 395+ --> Actions:\n",
      "mean: 0.03668957582973501 sdev: 0.0005286665043329181\n",
      "Training iteration: 398          last optimization: 395# --> Actions:\n",
      "mean: 0.03667687271952743 sdev: 0.0005712981709084048\n",
      "Training iteration: 399          last optimization: 395+ --> Actions:\n",
      "mean: 0.03666340268208633 sdev: 0.0006165846342172099\n",
      "Training iteration: 400          last optimization: 400# --> Actions:\n",
      "mean: 0.037041302002887154 sdev: 0.0006073638126988671\n",
      "Training iteration: 401          last optimization: 400+ --> Actions:\n",
      "mean: 0.03702527711898542 sdev: 0.000562184351488108\n",
      "Training iteration: 402          last optimization: 400# --> Actions:\n",
      "mean: 0.03700893558838529 sdev: 0.0005190509144342391\n",
      "Training iteration: 403          last optimization: 400+ --> Actions:\n",
      "mean: 0.03699370756758726 sdev: 0.00048048649816496183\n",
      "Training iteration: 404          last optimization: 400# --> Actions:\n",
      "mean: 0.03698011030070142 sdev: 0.0004484698351681668\n",
      "Training iteration: 405          last optimization: 405+ --> Actions:\n",
      "mean: 0.036988801016726164 sdev: 0.0004174276619716371\n",
      "Training iteration: 406          last optimization: 405# --> Actions:\n",
      "mean: 0.03698011577503073 sdev: 0.00039926522999738696\n",
      "Training iteration: 407          last optimization: 405+ --> Actions:\n",
      "mean: 0.036974253666141065 sdev: 0.00039226805288337897\n",
      "Training iteration: 408          last optimization: 405# --> Actions:\n",
      "mean: 0.036971583859543605 sdev: 0.00039463369770735324\n",
      "Training iteration: 409          last optimization: 405+ --> Actions:\n",
      "mean: 0.036972155538994425 sdev: 0.0004045713161221096\n",
      "Training iteration: 410          last optimization: 410# --> Actions:\n",
      "mean: 0.03660083136065222 sdev: 0.0006389920496735867\n",
      "Training iteration: 411          last optimization: 410+ --> Actions:\n",
      "mean: 0.03660702150482656 sdev: 0.0006158466507926867\n",
      "Training iteration: 412          last optimization: 410# --> Actions:\n",
      "mean: 0.03661441381532757 sdev: 0.0005905378282632833\n",
      "Training iteration: 413          last optimization: 410+ --> Actions:\n",
      "mean: 0.03662139618751014 sdev: 0.0005658732027365294\n",
      "Training iteration: 414          last optimization: 410# --> Actions:\n",
      "mean: 0.03662815410708558 sdev: 0.0005437402726479789\n",
      "Training iteration: 415          last optimization: 415+ --> Actions:\n",
      "mean: 0.036699511165527485 sdev: 0.0003707736135204525\n",
      "Training iteration: 416          last optimization: 415# --> Actions:\n",
      "mean: 0.03670337070919301 sdev: 0.00036319366185450966\n",
      "Training iteration: 417          last optimization: 415+ --> Actions:\n",
      "mean: 0.0367034507226798 sdev: 0.0003622682159502796\n",
      "Training iteration: 418          last optimization: 415# --> Actions:\n",
      "mean: 0.036699221503354425 sdev: 0.00036832596704357073\n",
      "Training iteration: 419          last optimization: 415+ --> Actions:\n",
      "mean: 0.03669064473748277 sdev: 0.00038301020461403837\n",
      "Training iteration: 420          last optimization: 420# --> Actions:\n",
      "mean: 0.036965244171297734 sdev: 0.0006392194494865878\n",
      "Training iteration: 421          last optimization: 420+ --> Actions:\n",
      "mean: 0.03694458500233942 sdev: 0.0005866309922978102\n",
      "Training iteration: 422          last optimization: 420# --> Actions:\n",
      "mean: 0.03691975840608065 sdev: 0.00052429636314718\n",
      "Training iteration: 423          last optimization: 420+ --> Actions:\n",
      "mean: 0.0368924895784795 sdev: 0.0004564545663468581\n",
      "Training iteration: 424          last optimization: 420# --> Actions:\n",
      "mean: 0.03686363614500583 sdev: 0.0003856807670237613\n",
      "Training iteration: 425          last optimization: 425+ --> Actions:\n",
      "mean: 0.03666876579963156 sdev: 0.00036817405784518267\n",
      "Training iteration: 426          last optimization: 425# --> Actions:\n",
      "mean: 0.03663895709304711 sdev: 0.00037570606481764594\n",
      "Training iteration: 427          last optimization: 425+ --> Actions:\n",
      "mean: 0.03660971012021468 sdev: 0.0003966593522456994\n",
      "Training iteration: 428          last optimization: 425# --> Actions:\n",
      "mean: 0.036581800681844204 sdev: 0.00042811771940550684\n",
      "Training iteration: 429          last optimization: 425+ --> Actions:\n",
      "mean: 0.036554915143868875 sdev: 0.0004656744525356816\n",
      "Training iteration: 430          last optimization: 430# --> Actions:\n",
      "mean: 0.0365601850035422 sdev: 0.0003373323011592879\n",
      "Training iteration: 431          last optimization: 430+ --> Actions:\n",
      "mean: 0.036536355872280275 sdev: 0.00037415642283283586\n",
      "Training iteration: 432          last optimization: 430# --> Actions:\n",
      "mean: 0.03651659280701417 sdev: 0.00040612705580447757\n",
      "Training iteration: 433          last optimization: 430+ --> Actions:\n",
      "mean: 0.036502733926739306 sdev: 0.00042910698054238005\n",
      "Training iteration: 434          last optimization: 430# --> Actions:\n",
      "mean: 0.03649517125908979 sdev: 0.0004396898156390816\n",
      "Training iteration: 435          last optimization: 435+ --> Actions:\n",
      "mean: 0.03674891861287678 sdev: 0.0005505269715225999\n",
      "Training iteration: 436          last optimization: 435# --> Actions:\n",
      "mean: 0.03675524417387884 sdev: 0.0005743676250761136\n",
      "Training iteration: 437          last optimization: 435+ --> Actions:\n",
      "mean: 0.03676826605877289 sdev: 0.0006155185936189535\n",
      "Training iteration: 438          last optimization: 435# --> Actions:\n",
      "mean: 0.036786946554266335 sdev: 0.0006719910418759652\n",
      "Training iteration: 439          last optimization: 435+ --> Actions:\n",
      "mean: 0.0368107119883203 sdev: 0.0007410672237156788\n",
      "Training iteration: 440          last optimization: 440# --> Actions:\n",
      "mean: 0.03669933334016044 sdev: 0.0006607553724521943\n",
      "Training iteration: 441          last optimization: 440+ --> Actions:\n",
      "mean: 0.03672806801273478 sdev: 0.0007333418516039886\n",
      "Training iteration: 442          last optimization: 440# --> Actions:\n",
      "mean: 0.036757946202054276 sdev: 0.0008116479375694857\n",
      "Training iteration: 443          last optimization: 440+ --> Actions:\n",
      "mean: 0.03678797338219528 sdev: 0.000891928107730437\n",
      "Training iteration: 444          last optimization: 440# --> Actions:\n",
      "mean: 0.03681767858955194 sdev: 0.0009703094488109096\n",
      "Training iteration: 445          last optimization: 445+ --> Actions:\n",
      "mean: 0.03643962311694465 sdev: 0.0004971416654483167\n",
      "Training iteration: 446          last optimization: 445# --> Actions:\n",
      "mean: 0.0364634866646327 sdev: 0.0004865700857551983\n",
      "Training iteration: 447          last optimization: 445+ --> Actions:\n",
      "mean: 0.0364838121062374 sdev: 0.00048598801269456027\n",
      "Training iteration: 448          last optimization: 445# --> Actions:\n",
      "mean: 0.03649935871478842 sdev: 0.0004905888736244201\n",
      "Training iteration: 449          last optimization: 445+ --> Actions:\n",
      "mean: 0.03650972733653336 sdev: 0.0004966872025944749\n",
      "Training iteration: 450          last optimization: 450# --> Actions:\n",
      "mean: 0.03627328517424563 sdev: 0.0007618682958862649\n",
      "Training iteration: 451          last optimization: 450+ --> Actions:\n",
      "mean: 0.03627407601717641 sdev: 0.0007569279812236224\n",
      "Training iteration: 452          last optimization: 450# --> Actions:\n",
      "mean: 0.03627182729167755 sdev: 0.0007591743697445387\n",
      "Training iteration: 453          last optimization: 450+ --> Actions:\n",
      "mean: 0.036266515991709936 sdev: 0.0007672783937879228\n",
      "Training iteration: 454          last optimization: 450# --> Actions:\n",
      "mean: 0.03625965095561449 sdev: 0.0007796180306720392\n",
      "Training iteration: 455          last optimization: 455+ --> Actions:\n",
      "mean: 0.0362998404830594 sdev: 0.0009680881116405673\n",
      "Training iteration: 456          last optimization: 455# --> Actions:\n",
      "mean: 0.03629054887704342 sdev: 0.000977996615486548\n",
      "Training iteration: 457          last optimization: 455+ --> Actions:\n",
      "mean: 0.036281111841401745 sdev: 0.000990243934883216\n",
      "Training iteration: 458          last optimization: 455# --> Actions:\n",
      "mean: 0.0362723979629541 sdev: 0.001003751751662475\n",
      "Training iteration: 459          last optimization: 455+ --> Actions:\n",
      "mean: 0.03626526439567612 sdev: 0.001017418870504649\n",
      "Training iteration: 460          last optimization: 460# --> Actions:\n",
      "mean: 0.036435157216866285 sdev: 0.0005102233108922783\n",
      "Training iteration: 461          last optimization: 460+ --> Actions:\n",
      "mean: 0.036432299946526074 sdev: 0.0005084375786553104\n",
      "Training iteration: 462          last optimization: 460# --> Actions:\n",
      "mean: 0.03643254726846482 sdev: 0.0005060407334409164\n",
      "Training iteration: 463          last optimization: 460+ --> Actions:\n",
      "mean: 0.036437363351945126 sdev: 0.000501965509039634\n",
      "Training iteration: 464          last optimization: 460# --> Actions:\n",
      "mean: 0.03644789200719571 sdev: 0.0004966398652208794\n",
      "Training iteration: 465          last optimization: 465+ --> Actions:\n",
      "mean: 0.03658806058821015 sdev: 0.0008758491117523909\n",
      "Training iteration: 466          last optimization: 465# --> Actions:\n",
      "mean: 0.036610451287871895 sdev: 0.0009136833502474522\n",
      "Training iteration: 467          last optimization: 465+ --> Actions:\n",
      "mean: 0.036637456437267825 sdev: 0.000964340983504934\n",
      "Training iteration: 468          last optimization: 465# --> Actions:\n",
      "mean: 0.03666858492487275 sdev: 0.0010261116456654544\n",
      "Training iteration: 469          last optimization: 465+ --> Actions:\n",
      "mean: 0.03670306149948106 sdev: 0.001096388095054179\n",
      "Training iteration: 470          last optimization: 470# --> Actions:\n",
      "mean: 0.03664966825697949 sdev: 0.0013712283856866857\n",
      "Training iteration: 471          last optimization: 470+ --> Actions:\n",
      "mean: 0.03668604510554391 sdev: 0.0014310927692410417\n",
      "Training iteration: 472          last optimization: 470# --> Actions:\n",
      "mean: 0.03672185823863038 sdev: 0.0014906504363151232\n",
      "Training iteration: 473          last optimization: 470+ --> Actions:\n",
      "mean: 0.0367554443947782 sdev: 0.0015464518795304737\n",
      "Training iteration: 474          last optimization: 470# --> Actions:\n",
      "mean: 0.036785555583146584 sdev: 0.0015949264741803562\n",
      "Training iteration: 475          last optimization: 475+ --> Actions:\n",
      "mean: 0.03654496248853509 sdev: 0.0009518558537947293\n",
      "Training iteration: 476          last optimization: 475# --> Actions:\n",
      "mean: 0.03656518839819538 sdev: 0.0009680449839029421\n",
      "Training iteration: 477          last optimization: 475+ --> Actions:\n",
      "mean: 0.0365780469403305 sdev: 0.0009739882825635532\n",
      "Training iteration: 478          last optimization: 475# --> Actions:\n",
      "mean: 0.03658322425426539 sdev: 0.0009685688074968042\n",
      "Training iteration: 479          last optimization: 475+ --> Actions:\n",
      "mean: 0.036581492355373106 sdev: 0.0009524267808423031\n",
      "Training iteration: 480          last optimization: 480# --> Actions:\n",
      "mean: 0.03622198492290428 sdev: 0.0007341753348397726\n",
      "Training iteration: 481          last optimization: 480+ --> Actions:\n",
      "mean: 0.03620745082580561 sdev: 0.0007839623905617974\n",
      "Training iteration: 482          last optimization: 480# --> Actions:\n",
      "mean: 0.036187634918278026 sdev: 0.000844616491781698\n",
      "Training iteration: 483          last optimization: 480+ --> Actions:\n",
      "mean: 0.036163726845689796 sdev: 0.000913480490871659\n",
      "Training iteration: 484          last optimization: 480# --> Actions:\n",
      "mean: 0.036136254787874134 sdev: 0.0009881502274620329\n",
      "Training iteration: 485          last optimization: 485+ --> Actions:\n",
      "mean: 0.036111210857167224 sdev: 0.0014097192718309276\n",
      "Training iteration: 486          last optimization: 485# --> Actions:\n",
      "mean: 0.03607979185826181 sdev: 0.0014733648995707781\n",
      "Training iteration: 487          last optimization: 485+ --> Actions:\n",
      "mean: 0.03604655040848196 sdev: 0.0015403176996655829\n",
      "Training iteration: 488          last optimization: 485# --> Actions:\n",
      "mean: 0.03601326235791123 sdev: 0.0016089788894061087\n",
      "Training iteration: 489          last optimization: 485+ --> Actions:\n",
      "mean: 0.03598114882487964 sdev: 0.0016770304209113205\n",
      "Training iteration: 490          last optimization: 490# --> Actions:\n",
      "mean: 0.036161578887696486 sdev: 0.0013974264900778832\n",
      "Training iteration: 491          last optimization: 490+ --> Actions:\n",
      "mean: 0.036132806946622346 sdev: 0.0014396399498484732\n",
      "Training iteration: 492          last optimization: 490# --> Actions:\n",
      "mean: 0.03610875153812098 sdev: 0.0014766222777682914\n",
      "Training iteration: 493          last optimization: 490+ --> Actions:\n",
      "mean: 0.03609044627377026 sdev: 0.001505493392926204\n",
      "Training iteration: 494          last optimization: 490# --> Actions:\n",
      "mean: 0.03607908486057736 sdev: 0.0015235227491372076\n",
      "Training iteration: 495          last optimization: 495+ --> Actions:\n",
      "mean: 0.03639592236385256 sdev: 0.0007711055285018843\n",
      "Training iteration: 496          last optimization: 495# --> Actions:\n",
      "mean: 0.036396120577016036 sdev: 0.0007794030619360599\n",
      "Training iteration: 497          last optimization: 495+ --> Actions:\n",
      "mean: 0.03640241840536454 sdev: 0.0007901454123532469\n",
      "Training iteration: 498          last optimization: 495# --> Actions:\n",
      "mean: 0.03641309862887452 sdev: 0.0008039369898943056\n",
      "Training iteration: 499          last optimization: 495+ --> Actions:\n",
      "mean: 0.03642670451469336 sdev: 0.0008205455556416219\n",
      "Training iteration: 500          last optimization: 500#\n",
      "***--> Total Elapsed Runtime: 00:00:39 for training the agent\n"
     ]
    }
   ],
   "source": [
    "# Thx2: https://discuss.pytorch.org/t/how-to-check-if-model-is-on-cuda/180/2?u=ferenc_acs\n",
    "start_time = time()\n",
    "\n",
    "agent.train()\n",
    "\n",
    "end_time = time()\n",
    "\n",
    "print_elapsed_time(start_time, end_time, \"for training the agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***--> Total Elapsed Runtime: 00:00:00 for observing the trained agent\n",
      "#\n",
      "Total score (averaged over agents) this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Some reminders about lambda functions\n",
    "# Thx2: https://realpython.com/python-lambda/\n",
    "# Thx2: https://thispointer.com/python-how-to-use-if-else-elif-in-lambda-functions/\n",
    "\n",
    "RANDOMRUN = False\n",
    "\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "#env_info = env.reset(train_mode=True)[brain_name] # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "avg100sum = np.zeros(num_agents)\n",
    "exectime = 0\n",
    "\n",
    "scores100 = deque(avg100sum, 100)\n",
    "time100 = list()\n",
    "epc = 0\n",
    "\n",
    "\n",
    "#import pdb; pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "start_time = time()\n",
    "\n",
    "while RANDOMRUN: #== True:\n",
    "    epc += 1\n",
    "    #print(f'\\r#{epc}', end = ' ')\n",
    "    print(f'\\r#{str(epc).rjust(6)}', end = ' ')\n",
    "    #actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = agent.a2c_net.select_action(states)\n",
    "    #actions = np.clip(actions.detach().cpu().numpy(), -1, 1)                  # all actions between -1 and 1\n",
    "        \n",
    "    t_step_b = time()\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    t_step_e = time()\n",
    "    time100.append(t_step_e - t_step_b)\n",
    "    \n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    rewards = env_info.rewards\n",
    "    nprewards = np.array(rewards)\n",
    "    scores += rewards                         # update the score (for each agent)\n",
    "    scores100.append(rewards)\n",
    "    if np.sum(nprewards) > 0:\n",
    "        #for x in scores100:\n",
    "        #    avg100sum += x\n",
    "        print(f'\\r#{epc} Avg 100 Rewards = {np.mean(scores100)}')  \n",
    "        avg100sum = np.zeros(num_agents)\n",
    "        maskagent = nprewards > 0\n",
    "        \n",
    "    if epc%100 == 0:\n",
    "        print(f'Exec time Avg 100: {np.mean(time100)}')\n",
    "        time100 = []\n",
    "        \n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "        \n",
    "end_time = time()\n",
    "\n",
    "print_elapsed_time(start_time, end_time, \"for observing the trained agent\")\n",
    "        \n",
    "print('#')\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-27 / 16-32-51  Notebook for Continuous Control ended.\n"
     ]
    }
   ],
   "source": [
    "print(get_time_string(sep=True), ' Notebook for Continuous Control ended.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
