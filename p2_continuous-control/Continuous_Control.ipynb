{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posix.uname_result(sysname='Linux', nodename='Anubis-Linux', release='5.4.0-48-generic', version='#52-Ubuntu SMP Thu Sep 10 10:58:49 UTC 2020', machine='x86_64')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.uname())\n",
    "\n",
    "# In the cloud environment?\n",
    "if 'root' in os.environ['HOME']:\n",
    "    UENVPATH = '/data/'\n",
    "    !pip -q install /home/workspace/python\n",
    "\n",
    "# In the standalone environment?\n",
    "if 'ferenc' in os.environ['HOME']:\n",
    "    UENVPATH = '/home/ferenc/Python/rl/udadrl/data/'\n",
    "\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "import pprint as pp\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "from time import time\n",
    "\n",
    "# Import the helper files\n",
    "from utilities import get_time_string, print_elapsed_time\n",
    "\n",
    "import pdb # Debug! Debug! Debug! Debug! Debug! Debug! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-27 / 08-33-37  Notebook for Continuous Control started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "print(get_time_string(sep=True), ' Notebook for Continuous Control started.')\n",
    "\n",
    "# ONE Agent, Standalone\n",
    "UENVCHOICE = 'Reacher_Linux/Reacher.x86_64'\n",
    "\n",
    "# TWENTY Agents, Standalone\n",
    "#UENVCHOICE = 'Reacher_Linux_20/Reacher.x86_64'\n",
    "\n",
    "# ONE Agent, Cloud, No-Visuals \n",
    "# UENVCHOICE = 'Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64'\n",
    "\n",
    "# TWENTY Agents, Cloud, No-Visuals \n",
    "#UENVCHOICE = 'Reacher_Linux_NoVis/Reacher.x86_64'\n",
    "\n",
    "env = UnityEnvironment( file_name=os.path.join( UENVPATH, UENVCHOICE ) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unityagents.environment.UnityEnvironment"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FA DEBUG! DEBUG! DEBUG! \n",
    "type(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ReacherBrain']\n",
      "<class 'unityagents.brain.BrainParameters'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ReacherBrain'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FA  DEBUG! DEBUG! DEBUG! \n",
    "print(env.brain_names)\n",
    "print( type(brain) )\n",
    "brain.brain_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space: 33 dimensions of continuous type\n",
      "Action Space: 4 dimensions of continuous type\n"
     ]
    }
   ],
   "source": [
    "# FA  DEBUG! DEBUG! DEBUG!\n",
    "print(f'Observation Space: {brain.vector_observation_space_size} dimensions of {brain.vector_observation_space_type} type') \n",
    "print(f'Action Space: {brain.vector_action_space_size} dimensions of {brain.vector_observation_space_type} type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Size of each action: 4\n",
      "There are 1 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726671e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1 active agent\n",
      "\n",
      "***--> Total Elapsed Runtime: 00:00:00 for choosing random actions\n",
      "#\n",
      "Total score (averaged over agents) this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Should a run with random actions be perfomed first?\n",
    "RANDOMRUN = False\n",
    "\n",
    "# Some reminders about lambda functions\n",
    "# Thx2: https://realpython.com/python-lambda/\n",
    "# Thx2: https://thispointer.com/python-how-to-use-if-else-elif-in-lambda-functions/\n",
    "# thx2: https://www.blog.pythonlibrary.org/2016/05/24/python-101-an-intro-to-benchmarking-your-code/\n",
    "import timeit\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "\n",
    "epc = 0\n",
    "print(f'We have {num_agents} active agent' + ( lambda x: 's' if x>1 else '' )(num_agents) )\n",
    "\n",
    "start_time = time()\n",
    "setup = \"from unityagents import UnityEnvironment\"\n",
    "\n",
    "while RANDOMRUN:\n",
    "    epc += 1\n",
    "    #print(f'\\r#{epc}', end = ' ')\n",
    "    print(f'\\r#{str(epc).rjust(6)}', end = ' ')\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    #pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    #print( timeit.timeit(\"env_info = env.step(actions)[brain_name]\", setup) )\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    rewards = env_info.rewards\n",
    "    nprewards = np.array(rewards)\n",
    "    scores += rewards                         # update the score (for each agent)\n",
    "    if np.sum(nprewards) > 0:\n",
    "        #print(f'\\r#{epc} Rewards = {rewards}')\n",
    "        maskagent = nprewards > 0\n",
    "        agentbefore = False\n",
    "        for (nagent, action) in enumerate(actions):\n",
    "            if maskagent[nagent]:\n",
    "                if agentbefore:\n",
    "                    print('\\r#' + '&'.rjust(6), end = ' ')\n",
    "                print(' -> Agent {:0>2d} got reward {:+.5f} for action: {}'.format(nagent+1, rewards[nagent], action))\n",
    "                agentbefore = True\n",
    "                #pp.pprint(list(action))\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "        \n",
    "end_time = time()\n",
    "\n",
    "print_elapsed_time(start_time, end_time, \"for choosing random actions\")\n",
    "\n",
    "print('#')\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re check running time (Random run)\n",
    "This time with the leanest code possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1 active agent\n",
      "\n",
      "***--> Total Elapsed Runtime: 00:00:00 for choosing fast random actions\n",
      "#\n",
      "Total score (averaged over agents) this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Should another run with random actions be perfomed?\n",
    "RANDOMRUN = False\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "#env_info = env.reset(train_mode=True)[brain_name] # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "\n",
    "epc = 0\n",
    "print(f'We have {num_agents} active agent' + ( lambda x: 's' if x>1 else '' )(num_agents) )\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "while RANDOMRUN:\n",
    "    epc += 1\n",
    "    print(f'\\r#{str(epc).rjust(6)}', end = ' ')\n",
    "    #pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "        \n",
    "end_time = time()\n",
    "\n",
    "print_elapsed_time(start_time, end_time, \"for choosing fast random actions\")\n",
    "\n",
    "print('#')\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.90150642e+00,\n",
       "        -1.00000000e+00,  1.25147498e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00, -2.99753308e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# thx2: https://github.com/udacity/deep-reinforcement-learning/blob/master/python/unityagents/brain.py\n",
    "env_info.vector_observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When finished, you can close the environment.\n",
    "#### Just not for now because unit testing below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FA: One BIG MISUNDERSTANDING & STACKS OF TENSORS (23-08-2020) --> #FA; BMSoT:\n",
    "It has cost me several days if not weeks to get behind the fact that the [A2C sample implementation of Miguel](https://github.com/mimoralea/gdrl/blob/master/notebooks/chapter_11/chapter-11.ipynb) is working with **stacks of tensors** instead of single tensors. Which was especially hard to find because the PyTorch code looks exactly the same for both.\n",
    "\n",
    "In the end, when I thought about it, it makes sense and is a nifty feature of PyTorch. It is just not obvious to people like me, without in deep insights in the inner workings of PyTorch. \n",
    "\n",
    "Furthermore the authors of the PyTorch documentation seem not to make it too visible, I had to dig it out of one of the function definitions I use, however inderectly over the layer defintion for a2cnet:\n",
    "\n",
    "https://pytorch.org/docs/0.4.0/_modules/torch/nn/functional.html#linear\n",
    "\n",
    "> def linear(input, weight, bias=None):\n",
    ">    \"\"\"\n",
    ">    Applies a linear transformation to the incoming data: :math:`y = xA^T + b`.\n",
    ">\n",
    ">    Shape:\n",
    ">        - Input: :math:`(N, *, in\\_features)` where `*` means any number of\n",
    ">          additional dimensions\n",
    ">        - Weight: :math:`(out\\_features, in\\_features)`\n",
    ">        - Bias: :math:`(out\\_features)`\n",
    ">        - Output: :math:`(N, *, out\\_features)`\n",
    ">    \"\"\"\n",
    ">    if input.dim() == 2 and bias is not None:\n",
    ">        # fused op is marginally faster\n",
    ">        return torch.addmm(bias, input, weight.t())\n",
    ">\n",
    ">    output = input.matmul(weight.t())\n",
    ">    if bias is not None:\n",
    ">        output += bias\n",
    ">    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracing the error in the 'mya2cnet' module code refactoring below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! \n",
    "#import pdb; pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(20200808) # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "#torch.manual_seed(456454618181) # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "\n",
    "# Format: IN_Num [Layer 1] (OUT_Num = IN_Num) [Layer 2] OUT_Num = ...\n",
    "HIDDEN_DIMS_DEFAULT = {\n",
    "    'shared' : (512, 512, 256, 256),\n",
    "    'actor' : (256, 128, 128, 64),\n",
    "    'critic' : (256, 128, 128, 64)\n",
    "}\n",
    "hidden_dims = HIDDEN_DIMS_DEFAULT\n",
    "\n",
    "hlayers = dict()\n",
    "\n",
    "hlayers['shared'] = nn.ModuleList()\n",
    "hlayers['actor'] = nn.ModuleList()\n",
    "hlayers['critic'] = nn.ModuleList()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "input_layer = nn.Linear( 33, hidden_dims['shared'][0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=33, out_features=512, bias=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layers shared\n",
    "for i in range( len(hidden_dims['shared']) -1 ):\n",
    "    hlayers['shared'].append( nn.Linear( hidden_dims['shared'][i], hidden_dims['shared'][i+1] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hlayers['shared']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actor layers\n",
    "for i in range( len(hidden_dims['actor']) ):\n",
    "    #import pdb; pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "    if i == 0:\n",
    "        hlayers['actor'].append( nn.Linear( hidden_dims['shared'][-1], hidden_dims['actor'][i] ) )\n",
    "    else:\n",
    "        # hlayers['actor'].append( nn.Linear( hidden_dims['actor'][i], hidden_dims['actor'][i+1] ERROR !!!\n",
    "        hlayers['actor'].append( nn.Linear( hidden_dims['actor'][i-1], hidden_dims['actor'][i] ) )\n",
    "    #print( i, hlayers['actor'] ) # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "        \n",
    "actor_out_layer = nn.Linear( hidden_dims['actor'][-1], 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (3): Linear(in_features=128, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hlayers['actor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=64, out_features=4, bias=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Critic layers\n",
    "for i in range( len(hidden_dims['critic']) ):\n",
    "    if i == 0:\n",
    "        hlayers['critic'].append( nn.Linear( hidden_dims['shared'][-1], hidden_dims['critic'][i] ) )\n",
    "    else:\n",
    "        hlayers['critic'].append( nn.Linear( hidden_dims['critic'][i-1], hidden_dims['critic'][i] ) )\n",
    "critic_out_layer = nn.Linear( hidden_dims['critic'][-1], 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (3): Linear(in_features=128, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hlayers['critic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=64, out_features=1, bias=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic_out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevents non Pytorch Tensor Object entering the processing stream\n",
    "def torch_format(state):\n",
    "    x = state\n",
    "    if not isinstance(x, torch.Tensor):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        if len(x.size()) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(state):\n",
    "    check_tensor = lambda x: isinstance(x, torch.Tensor)\n",
    "    x_act = True \n",
    "    x_crit = True\n",
    "\n",
    "    x = torch_format(state)\n",
    "    x = F.relu(  input_layer(x) )\n",
    "    for label in ['shared', 'actor', 'critic']:\n",
    "        for hlayer in  hlayers[label]:\n",
    "            if label == 'shared':\n",
    "                x = F.relu(  hlayer(x) )\n",
    "            if label == 'actor':\n",
    "                x_act = F.relu(  hlayer(x_act) )\n",
    "            if label == 'critic':\n",
    "                x_crit = F.relu(  hlayer(x_crit) )\n",
    "\n",
    "        # Thx2: https://discuss.pytorch.org/t/copy-deepcopy-vs-clone/55022\n",
    "        if ( type(x_act) == bool ):\n",
    "            x_act = x.clone()  # Create an Inplace copy...\n",
    "        if ( type(x_crit) == bool ):\n",
    "            x_crit = x.clone() # ...after processing shared layers\n",
    "\n",
    "    return  actor_out_layer(x_act),  critic_out_layer(x_crit) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if A STACK OF (BMSoT) states are propagated through the debug network\n",
    "And make a list of outputs of two A2C instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor: tensor(1.00000e-02 *\n",
      "       [[ 4.6713,  4.9987, -4.4540,  4.1302]])\n",
      "Critic: tensor(1.00000e-02 *\n",
      "       [[ 4.8234]])\n"
     ]
    }
   ],
   "source": [
    "#al = []\n",
    "#bl = []\n",
    "\n",
    "#for (dc, st) in enumerate(states):\n",
    "#    al.append(a)\n",
    "#    bl.append(b)\n",
    "\n",
    "#import pdb; pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!    \n",
    "    \n",
    "#FA; BMSoT: No need to iterate through states any more!\n",
    "a,b = forward(states)\n",
    "print(f'Actor: {a}')\n",
    "print(f'Critic: {b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if A STACK OF (BMSoT) states is propagated through the imported network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "\n",
    "#from mya2cnet import A2CNetwork\n",
    "import mya2cnet\n",
    "\n",
    "# Thx2: https://emacs.stackexchange.com/a/13483\n",
    "import imp\n",
    "imp.reload(mya2cnet)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tstnet1 = mya2cnet.A2CNetwork(33, 4).to(device) #FA; BMSoT: Looks exactly the same...\n",
    "tstnet2 = mya2cnet.A2CNetwork(33, 4).to(device) #FA; BMSoT: ...like without stacks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FA; BMSoT: OBSOLETE\n",
    "#for (dc, st) in enumerate(states):\n",
    "\n",
    "\n",
    "\n",
    "# pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "    \n",
    "#a1,b1 = tstnet1.forward(torch.tensor(states, dtype=torch.float, device=device))\n",
    "#a2,b2 = tstnet2.forward(torch.tensor(states).to(device))\n",
    "\n",
    "#print(f'Dist. Actor stacks 1-2: {torch.dist(a1, a2)}'.ljust(50) + ' # ' +\\\n",
    "#     f'Dist. Actor 1 stacks - Notebook stacks {torch.dist(a1, a)}'.rjust(50))\n",
    "#print(f'Dist. Critic stacks 1-2: {torch.dist(b1, b2)}'.ljust(50) + ' # ' +\\\n",
    "#     f'Dist. Critic 1 stacks - Notebook stacks {torch.dist(b1, b)}'.rjust(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next(tstnet1.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next(tstnet2.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FA; BMSoT: OBSOLETE\n",
    "#for (dc, st) in enumerate(states):\n",
    "#    print(f'({dc+1}) -> {tstnet1.fullpass(st)}')\n",
    "    \n",
    "#tstnet1.fullpass( torch.tensor(states, device = device, dtype = torch.float) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FA; BMSoT: OBSOLETE\n",
    "#for (dc, st) in enumerate(states):\n",
    "#    print(f'({dc+1})-> {tstnet1.select_action(st)}') #, end=' ')\n",
    "    \n",
    "#tstnet1.select_action(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the agent instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mya2cagent\n",
    "\n",
    "# Thx2: https://emacs.stackexchange.com/a/13483\n",
    "import imp\n",
    "imp.reload(mya2cagent)\n",
    "\n",
    "agent = mya2cagent.a2cagent(len(env_info.agents), env, brain, max_steps = 500, max_n_steps = 5*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --> Actions:\n",
      "mean: 0.018108515985055567 sdev: 0.08123751415667829\n",
      "Training iteration: 1            last optimization: 0+ --> Actions:\n",
      "mean: 0.018092322511666092 sdev: 0.08125268479982808\n",
      "Training iteration: 2            last optimization: 0# --> Actions:\n",
      "mean: 0.018069281636669984 sdev: 0.0812755916878922\n",
      "Training iteration: 3            last optimization: 0+ --> Actions:\n",
      "mean: 0.018050094006095613 sdev: 0.08127923476463696\n",
      "Training iteration: 4            last optimization: 0# --> Actions:\n",
      "mean: 0.018041608432382082 sdev: 0.08127071896994949\n",
      "Training iteration: 5            last optimization: 0+ --> Actions:\n",
      "mean: 0.01803749420180474 sdev: 0.08125634647571706\n",
      "Training iteration: 6            last optimization: 0# --> Actions:\n",
      "mean: 0.018035350876426742 sdev: 0.0812410906320223\n",
      "Training iteration: 7            last optimization: 0+ --> Actions:\n",
      "mean: 0.01802866131957436 sdev: 0.08122861702478829\n",
      "Training iteration: 8            last optimization: 0# --> Actions:\n",
      "mean: 0.018019713299659325 sdev: 0.08122212305926632\n",
      "Training iteration: 9            last optimization: 0+ --> Actions:\n",
      "mean: 0.01801043882525225 sdev: 0.08122114099033842\n",
      "Training iteration: 10            last optimization: 0# --> Actions:\n",
      "mean: 0.017999987979542064 sdev: 0.0812257636213165\n",
      "Training iteration: 11            last optimization: 0+ --> Actions:\n",
      "mean: 0.01798818997731482 sdev: 0.08123539749261123\n",
      "Training iteration: 12            last optimization: 0# --> Actions:\n",
      "mean: 0.017975087670356448 sdev: 0.081249737000756\n",
      "Training iteration: 13            last optimization: 0+ --> Actions:\n",
      "mean: 0.01796127733481251 sdev: 0.08126715780920585\n",
      "Training iteration: 14            last optimization: 0# --> Actions:\n",
      "mean: 0.017952749816644437 sdev: 0.08128311277186517\n",
      "Training iteration: 15            last optimization: 0+ --> Actions:\n",
      "mean: 0.017947798997748496 sdev: 0.0812922143924135\n",
      "Training iteration: 16            last optimization: 0# --> Actions:\n",
      "mean: 0.017945127286843384 sdev: 0.08129513668195183\n",
      "Training iteration: 17            last optimization: 0+ --> Actions:\n",
      "mean: 0.0179488406563137 sdev: 0.08129195755094705\n",
      "Training iteration: 18            last optimization: 0# --> Actions:\n",
      "mean: 0.017956990841041614 sdev: 0.08128273932654627\n",
      "Training iteration: 19            last optimization: 0+ --> Actions:\n",
      "mean: 0.017962759419133004 sdev: 0.08128210274131083\n",
      "Training iteration: 20            last optimization: 0# --> Actions:\n",
      "mean: 0.01796319948584081 sdev: 0.08128587326689694\n",
      "Training iteration: 21            last optimization: 0+ --> Actions:\n",
      "mean: 0.017966004910428754 sdev: 0.08128843244213073\n",
      "Training iteration: 22            last optimization: 0# --> Actions:\n",
      "mean: 0.017971659030307105 sdev: 0.0812888967287713\n",
      "Training iteration: 23            last optimization: 0+ --> Actions:\n",
      "mean: 0.01797934658118564 sdev: 0.08128979576349155\n",
      "Training iteration: 24            last optimization: 0# --> Actions:\n",
      "mean: 0.017989845283920575 sdev: 0.08128735681806984\n",
      "Training iteration: 25            last optimization: 0+ --> Actions:\n",
      "mean: 0.01800347082716773 sdev: 0.08128087069552473\n",
      "Training iteration: 26            last optimization: 0# --> Actions:\n",
      "mean: 0.018019628955925765 sdev: 0.0812706165393904\n",
      "Training iteration: 27            last optimization: 0+ --> Actions:\n",
      "mean: 0.01803778968240822 sdev: 0.08125705969646285\n",
      "Training iteration: 28            last optimization: 0# --> Actions:\n",
      "mean: 0.01805274220320901 sdev: 0.08124277319316477\n",
      "Training iteration: 29            last optimization: 0+ --> Actions:\n",
      "mean: 0.01806337024121859 sdev: 0.08122982198537959\n",
      "Training iteration: 30            last optimization: 0# --> Actions:\n",
      "mean: 0.01806968997796867 sdev: 0.08122059174628983\n",
      "Training iteration: 31            last optimization: 0+ --> Actions:\n",
      "mean: 0.018070185833594946 sdev: 0.08121626677369814\n",
      "Training iteration: 32            last optimization: 0# --> Actions:\n",
      "mean: 0.01806505247869035 sdev: 0.08121998232114516\n",
      "Training iteration: 33            last optimization: 0+ --> Actions:\n",
      "mean: 0.01805215079091267 sdev: 0.08123606022493064\n",
      "Training iteration: 34            last optimization: 0# --> Actions:\n",
      "mean: 0.018034620436074678 sdev: 0.08125335935290252\n",
      "Training iteration: 35            last optimization: 0+ --> Actions:\n",
      "mean: 0.01800824879672399 sdev: 0.08127633091205556\n",
      "Training iteration: 36            last optimization: 0# --> Actions:\n",
      "mean: 0.017984258682930618 sdev: 0.0812930622822092\n",
      "Training iteration: 37            last optimization: 0+ --> Actions:\n",
      "mean: 0.017968851076863704 sdev: 0.08129331666778197\n",
      "Training iteration: 38            last optimization: 0# --> Actions:\n",
      "mean: 0.01796332609458758 sdev: 0.08128140162052562\n",
      "Training iteration: 39            last optimization: 0+ --> Actions:\n",
      "mean: 0.01796005391627893 sdev: 0.08126544992456786\n",
      "Training iteration: 40            last optimization: 0# --> Actions:\n",
      "mean: 0.01795935389340888 sdev: 0.08124692131894083\n",
      "Training iteration: 41            last optimization: 0+ --> Actions:\n",
      "mean: 0.017960314766032087 sdev: 0.08123004499937113\n",
      "Training iteration: 42            last optimization: 0# --> Actions:\n",
      "mean: 0.01795900594057939 sdev: 0.0812182565880311\n",
      "Training iteration: 43            last optimization: 0+ --> Actions:\n",
      "mean: 0.01795583937885724 sdev: 0.08121315382818077\n",
      "Training iteration: 44            last optimization: 0# --> Actions:\n",
      "mean: 0.017951629117755444 sdev: 0.0812140256666474\n",
      "Training iteration: 45            last optimization: 0+ --> Actions:\n",
      "mean: 0.0179462265248845 sdev: 0.08122041397458253\n",
      "Training iteration: 46            last optimization: 0# --> Actions:\n",
      "mean: 0.017939801390021805 sdev: 0.08123064971159316\n",
      "Training iteration: 47            last optimization: 0+ --> Actions:\n",
      "mean: 0.017936397649569148 sdev: 0.08124222341283122\n",
      "Training iteration: 48            last optimization: 0# --> Actions:\n",
      "mean: 0.017936890723937095 sdev: 0.0812512130597285\n",
      "Training iteration: 49            last optimization: 0+ --> Actions:\n",
      "mean: 0.017939591976056518 sdev: 0.08125499052325351\n",
      "Training iteration: 50            last optimization: 0# --> Actions:\n",
      "mean: 0.017944841714420737 sdev: 0.0812564237547406\n",
      "Training iteration: 51            last optimization: 0+ --> Actions:\n",
      "mean: 0.017947021097041452 sdev: 0.08126453872469883\n",
      "Training iteration: 52            last optimization: 0# --> Actions:\n",
      "mean: 0.017948835569072598 sdev: 0.08127224942710266\n",
      "Training iteration: 53            last optimization: 0+ --> Actions:\n",
      "mean: 0.01795416645045212 sdev: 0.08127461729067158\n",
      "Training iteration: 54            last optimization: 0# --> Actions:\n",
      "mean: 0.01796165751471205 sdev: 0.08127610849341463\n",
      "Training iteration: 55            last optimization: 0+ --> Actions:\n",
      "mean: 0.01797107211319162 sdev: 0.08127713099327838\n",
      "Training iteration: 56            last optimization: 0# --> Actions:\n",
      "mean: 0.01798331867001709 sdev: 0.08127566709617046\n",
      "Training iteration: 57            last optimization: 0+ --> Actions:\n",
      "mean: 0.017998427956014196 sdev: 0.08127137171381296\n",
      "Training iteration: 58            last optimization: 0# --> Actions:\n",
      "mean: 0.018014752547253002 sdev: 0.08126757092457719\n",
      "Training iteration: 59            last optimization: 0+ --> Actions:\n",
      "mean: 0.018031987455863166 sdev: 0.08126074292995436\n",
      "Training iteration: 60            last optimization: 0# --> Actions:\n",
      "mean: 0.018050705217487993 sdev: 0.08125080001199061\n",
      "Training iteration: 61            last optimization: 0+ --> Actions:\n",
      "mean: 0.018069470663001214 sdev: 0.0812388150601997\n",
      "Training iteration: 62            last optimization: 0# --> Actions:\n",
      "mean: 0.018086356101292736 sdev: 0.08122660552190612\n",
      "Training iteration: 63            last optimization: 0+ --> Actions:\n",
      "mean: 0.01809941209078845 sdev: 0.08121584162393411\n",
      "Training iteration: 64            last optimization: 0# --> Actions:\n",
      "mean: 0.018106107970035035 sdev: 0.0812083421483339\n",
      "Training iteration: 65            last optimization: 0+ --> Actions:\n",
      "mean: 0.018106723092594715 sdev: 0.08120620587202822\n",
      "Training iteration: 66            last optimization: 0# --> Actions:\n",
      "mean: 0.018101231186799877 sdev: 0.0812176324356593\n",
      "Training iteration: 67            last optimization: 0+ --> Actions:\n",
      "mean: 0.018089306620320076 sdev: 0.08123145582996896\n",
      "Training iteration: 68            last optimization: 0# --> Actions:\n",
      "mean: 0.018077653975850105 sdev: 0.08124937137240064\n",
      "Training iteration: 69            last optimization: 0+ --> Actions:\n",
      "mean: 0.018061311973012154 sdev: 0.08126665159443218\n",
      "Training iteration: 70            last optimization: 0# --> Actions:\n",
      "mean: 0.018046772428352578 sdev: 0.08127495626400537\n",
      "Training iteration: 71            last optimization: 0+ --> Actions:\n",
      "mean: 0.018038863389124006 sdev: 0.08126933056405168\n",
      "Training iteration: 72            last optimization: 0# --> Actions:\n",
      "mean: 0.01803850308269018 sdev: 0.08125327703916653\n",
      "Training iteration: 73            last optimization: 0+ --> Actions:\n",
      "mean: 0.018037976183326837 sdev: 0.0812376792108132\n",
      "Training iteration: 74            last optimization: 0# --> Actions:\n",
      "mean: 0.018036579547667256 sdev: 0.08122496073062507\n",
      "Training iteration: 75            last optimization: 0+ --> Actions:\n",
      "mean: 0.018032924268325975 sdev: 0.08121780377130165\n",
      "Training iteration: 76            last optimization: 0# --> Actions:\n",
      "mean: 0.018024939180006912 sdev: 0.08121666572096942\n",
      "Training iteration: 77            last optimization: 0+ --> Actions:\n",
      "mean: 0.018015378379607455 sdev: 0.08122131554717618\n",
      "Training iteration: 78            last optimization: 0# --> Actions:\n",
      "mean: 0.018004583456183953 sdev: 0.0812309044972582\n",
      "Training iteration: 79            last optimization: 0+ --> Actions:\n",
      "mean: 0.017994713436295003 sdev: 0.08124356667505074\n",
      "Training iteration: 80            last optimization: 0# --> Actions:\n",
      "mean: 0.01798514174102498 sdev: 0.08125971133448114\n",
      "Training iteration: 81            last optimization: 0+ --> Actions:\n",
      "mean: 0.017979551132752826 sdev: 0.08127428168082586\n",
      "Training iteration: 82            last optimization: 0# --> Actions:\n",
      "mean: 0.017980088768183026 sdev: 0.08128074503499938\n",
      "Training iteration: 83            last optimization: 0+ --> Actions:\n",
      "mean: 0.01797994551347764 sdev: 0.08128671077149377\n",
      "Training iteration: 84            last optimization: 0# --> Actions:\n",
      "mean: 0.017980152452958396 sdev: 0.0812883608867054\n",
      "Training iteration: 85            last optimization: 0+ --> Actions:\n",
      "mean: 0.017986630520687587 sdev: 0.08127814611948342\n",
      "Training iteration: 86            last optimization: 0# --> Actions:\n",
      "mean: 0.017988648610157386 sdev: 0.08128069063604414\n",
      "Training iteration: 87            last optimization: 0+ --> Actions:\n",
      "mean: 0.01798944891810061 sdev: 0.08128661719733375\n",
      "Training iteration: 88            last optimization: 0# --> Actions:\n",
      "mean: 0.01799247933388905 sdev: 0.08129027038636438\n",
      "Training iteration: 89            last optimization: 0+ --> Actions:\n",
      "mean: 0.017998559937451815 sdev: 0.08129106997811222\n",
      "Training iteration: 90            last optimization: 0# --> Actions:\n",
      "mean: 0.018006647890838234 sdev: 0.08129235330442852\n",
      "Training iteration: 91            last optimization: 0+ --> Actions:\n",
      "mean: 0.018017075803015883 sdev: 0.08129148010322884\n",
      "Training iteration: 92            last optimization: 0# --> Actions:\n",
      "mean: 0.01802963135422464 sdev: 0.08128704788919103\n",
      "Training iteration: 93            last optimization: 0+ --> Actions:\n",
      "mean: 0.01804516781794152 sdev: 0.08127861053341648\n",
      "Training iteration: 94            last optimization: 0# --> Actions:\n",
      "mean: 0.018061397599277156 sdev: 0.0812675709580524\n",
      "Training iteration: 95            last optimization: 0+ --> Actions:\n",
      "mean: 0.018074160912055035 sdev: 0.08125558034223226\n",
      "Training iteration: 96            last optimization: 0# --> Actions:\n",
      "mean: 0.018084166276589653 sdev: 0.0812441439372622\n",
      "Training iteration: 97            last optimization: 0+ --> Actions:\n",
      "mean: 0.01809016469879122 sdev: 0.08123541631063055\n",
      "Training iteration: 98            last optimization: 0# --> Actions:\n",
      "mean: 0.01809017193178586 sdev: 0.08123036366991651\n",
      "Training iteration: 99            last optimization: 0+ --> Actions:\n",
      "mean: 0.018083790792266616 sdev: 0.08123598462977959\n",
      "Training iteration: 100          last optimization: 100# --> Actions:\n",
      "mean: 0.023352091994272413 sdev: 0.06609153591695555\n",
      "Training iteration: 101          last optimization: 100+ --> Actions:\n",
      "mean: 0.02334695112638915 sdev: 0.06608981946374339\n",
      "Training iteration: 102          last optimization: 100# --> Actions:\n",
      "mean: 0.02333978118795188 sdev: 0.06609075046780924\n",
      "Training iteration: 103          last optimization: 100+ --> Actions:\n",
      "mean: 0.02332995545203099 sdev: 0.06609088579967784\n",
      "Training iteration: 104          last optimization: 100# --> Actions:\n",
      "mean: 0.023318753928737265 sdev: 0.06609103344129644\n",
      "Training iteration: 105          last optimization: 100+ --> Actions:\n",
      "mean: 0.023307020706582082 sdev: 0.06609083001852797\n",
      "Training iteration: 106          last optimization: 100# --> Actions:\n",
      "mean: 0.023295541490143394 sdev: 0.06608966432296665\n",
      "Training iteration: 107          last optimization: 100+ --> Actions:\n",
      "mean: 0.023285409268846653 sdev: 0.0660860584695638\n",
      "Training iteration: 108          last optimization: 100# --> Actions:\n",
      "mean: 0.023276436800214212 sdev: 0.0660819955304894\n",
      "Training iteration: 109          last optimization: 100+ --> Actions:\n",
      "mean: 0.02326957144699593 sdev: 0.06607786085320229\n",
      "Training iteration: 110          last optimization: 100# --> Actions:\n",
      "mean: 0.023264162557262526 sdev: 0.06607415975223313\n",
      "Training iteration: 111          last optimization: 100+ --> Actions:\n",
      "mean: 0.0232593120127152 sdev: 0.06607137029874569\n",
      "Training iteration: 112          last optimization: 100# --> Actions:\n",
      "mean: 0.023254986144635368 sdev: 0.0660698238536895\n",
      "Training iteration: 113          last optimization: 100+ --> Actions:\n",
      "mean: 0.023252677569968787 sdev: 0.06606921225648332\n",
      "Training iteration: 114          last optimization: 100# --> Actions:\n",
      "mean: 0.023251639298805298 sdev: 0.06606952668580625\n",
      "Training iteration: 115          last optimization: 100+ --> Actions:\n",
      "mean: 0.023251623014282914 sdev: 0.06607108752596526\n",
      "Training iteration: 116          last optimization: 100# --> Actions:\n",
      "mean: 0.023253236824322277 sdev: 0.06607473108065673\n",
      "Training iteration: 117          last optimization: 100+ --> Actions:\n",
      "mean: 0.023253020344388593 sdev: 0.06607921453310901\n",
      "Training iteration: 118          last optimization: 100# --> Actions:\n",
      "mean: 0.02325333126581649 sdev: 0.0660843530631475\n",
      "Training iteration: 119          last optimization: 100+ --> Actions:\n",
      "mean: 0.023255223414222266 sdev: 0.06608993733022546\n",
      "Training iteration: 120          last optimization: 100# --> Actions:\n",
      "mean: 0.023258192637862267 sdev: 0.06609570629372176\n",
      "Training iteration: 121          last optimization: 100+ --> Actions:\n",
      "mean: 0.02326210841398504 sdev: 0.06610087674600415\n",
      "Training iteration: 122          last optimization: 100# --> Actions:\n",
      "mean: 0.02326752160082074 sdev: 0.0661047833943986\n",
      "Training iteration: 123          last optimization: 100+ --> Actions:\n",
      "mean: 0.02327412513733468 sdev: 0.06610730242699865\n",
      "Training iteration: 124          last optimization: 100# --> Actions:\n",
      "mean: 0.023281561284049263 sdev: 0.0661077765208968\n",
      "Training iteration: 125          last optimization: 100+ --> Actions:\n",
      "mean: 0.023289597093111937 sdev: 0.06610592885417726\n",
      "Training iteration: 126          last optimization: 100# --> Actions:\n",
      "mean: 0.023297884967173638 sdev: 0.0661018626856384\n",
      "Training iteration: 127          last optimization: 100+ --> Actions:\n",
      "mean: 0.02330591443194719 sdev: 0.06609593250423271\n",
      "Training iteration: 128          last optimization: 100# --> Actions:\n",
      "mean: 0.02331304950882281 sdev: 0.06608863028906922\n",
      "Training iteration: 129          last optimization: 100+ --> Actions:\n",
      "mean: 0.02331870017693946 sdev: 0.06608159006353104\n",
      "Training iteration: 130          last optimization: 100# --> Actions:\n",
      "mean: 0.023321892417957096 sdev: 0.06607599855691944\n",
      "Training iteration: 131          last optimization: 100+ --> Actions:\n",
      "mean: 0.02332436860285006 sdev: 0.0660728282647551\n",
      "Training iteration: 132          last optimization: 100# --> Actions:\n",
      "mean: 0.02332499301816597 sdev: 0.06607219326442218\n",
      "Training iteration: 133          last optimization: 100+ --> Actions:\n",
      "mean: 0.023323954390165234 sdev: 0.06607253904769421\n",
      "Training iteration: 134          last optimization: 100# --> Actions:\n",
      "mean: 0.02332136679018401 sdev: 0.0660735666441159\n",
      "Training iteration: 135          last optimization: 100+ --> Actions:\n",
      "mean: 0.023315673708618624 sdev: 0.06607296007571195\n",
      "Training iteration: 136          last optimization: 100# --> Actions:\n",
      "mean: 0.02330921208941459 sdev: 0.06607223854718719\n",
      "Training iteration: 137          last optimization: 100+ --> Actions:\n",
      "mean: 0.023302795344933618 sdev: 0.06607124389389366\n",
      "Training iteration: 138          last optimization: 100# --> Actions:\n",
      "mean: 0.023297072699120257 sdev: 0.06606969903383461\n",
      "Training iteration: 139          last optimization: 100+ --> Actions:\n",
      "mean: 0.023292752599854246 sdev: 0.06606706605483084\n",
      "Training iteration: 140          last optimization: 100# --> Actions:\n",
      "mean: 0.02328994949374088 sdev: 0.06606448517907951\n",
      "Training iteration: 141          last optimization: 100+ --> Actions:\n",
      "mean: 0.023288780732123024 sdev: 0.06606233221913567\n",
      "Training iteration: 142          last optimization: 100# --> Actions:\n",
      "mean: 0.023289198554608502 sdev: 0.06606095059751067\n",
      "Training iteration: 143          last optimization: 100+ --> Actions:\n",
      "mean: 0.023290077309398992 sdev: 0.06606033824186597\n",
      "Training iteration: 144          last optimization: 100# --> Actions:\n",
      "mean: 0.023291766221763946 sdev: 0.06606108955619078\n",
      "Training iteration: 145          last optimization: 100+ --> Actions:\n",
      "mean: 0.023294790497454174 sdev: 0.06606298624897626\n",
      "Training iteration: 146          last optimization: 100# --> Actions:\n",
      "mean: 0.023299318988375332 sdev: 0.0660650643589575\n",
      "Training iteration: 147          last optimization: 100+ --> Actions:\n",
      "mean: 0.023302433126171036 sdev: 0.06606783497244352\n",
      "Training iteration: 148          last optimization: 100# --> Actions:\n",
      "mean: 0.023305483705763522 sdev: 0.06607274674601993\n",
      "Training iteration: 149          last optimization: 100+ --> Actions:\n",
      "mean: 0.023308994392929064 sdev: 0.06608000217916214\n",
      "Training iteration: 150          last optimization: 100# --> Actions:\n",
      "mean: 0.023313172628122242 sdev: 0.06608814631577767\n",
      "Training iteration: 151          last optimization: 100+ --> Actions:\n",
      "mean: 0.02331798017581681 sdev: 0.06609694823826943\n",
      "Training iteration: 152          last optimization: 100# --> Actions:\n",
      "mean: 0.023323107904267736 sdev: 0.06610540648094067\n",
      "Training iteration: 153          last optimization: 100+ --> Actions:\n",
      "mean: 0.023328918869077973 sdev: 0.06611262576125551\n",
      "Training iteration: 154          last optimization: 100# --> Actions:\n",
      "mean: 0.023335357516862172 sdev: 0.06611839914071803\n",
      "Training iteration: 155          last optimization: 100+ --> Actions:\n",
      "mean: 0.023342673979526486 sdev: 0.0661231208030126\n",
      "Training iteration: 156          last optimization: 100# --> Actions:\n",
      "mean: 0.023350465344928864 sdev: 0.06612614948316302\n",
      "Training iteration: 157          last optimization: 100+ --> Actions:\n",
      "mean: 0.023358534754433426 sdev: 0.06612700260804853\n",
      "Training iteration: 158          last optimization: 100# --> Actions:\n",
      "mean: 0.023366737454534624 sdev: 0.06612542481880612\n",
      "Training iteration: 159          last optimization: 100+ --> Actions:\n",
      "mean: 0.023374266265211645 sdev: 0.06612170768412569\n",
      "Training iteration: 160          last optimization: 100# --> Actions:\n",
      "mean: 0.0233790128110306 sdev: 0.06611549220549462\n",
      "Training iteration: 161          last optimization: 100+ --> Actions:\n",
      "mean: 0.02338230415268539 sdev: 0.06610888959599624\n",
      "Training iteration: 162          last optimization: 100# --> Actions:\n",
      "mean: 0.02338389453645601 sdev: 0.06610291216364622\n",
      "Training iteration: 163          last optimization: 100+ --> Actions:\n",
      "mean: 0.023383626533060343 sdev: 0.06609829912733764\n",
      "Training iteration: 164          last optimization: 100# --> Actions:\n",
      "mean: 0.023381860230600945 sdev: 0.06609680734196949\n",
      "Training iteration: 165          last optimization: 100+ --> Actions:\n",
      "mean: 0.023378662909847574 sdev: 0.06609779993558935\n",
      "Training iteration: 166          last optimization: 100# --> Actions:\n",
      "mean: 0.023372466518560904 sdev: 0.06609957141488682\n",
      "Training iteration: 167          last optimization: 100+ --> Actions:\n",
      "mean: 0.02336388992347704 sdev: 0.06609987738234904\n",
      "Training iteration: 168          last optimization: 100# --> Actions:\n",
      "mean: 0.023353725229095717 sdev: 0.06609964612476936\n",
      "Training iteration: 169          last optimization: 100+ --> Actions:\n",
      "mean: 0.023343546727980596 sdev: 0.06609891349244594\n",
      "Training iteration: 170          last optimization: 100# --> Actions:\n",
      "mean: 0.023334078016941887 sdev: 0.0660974624857948\n",
      "Training iteration: 171          last optimization: 100+ --> Actions:\n",
      "mean: 0.02332509556843339 sdev: 0.06609540813502096\n",
      "Training iteration: 172          last optimization: 100# --> Actions:\n",
      "mean: 0.023317261607109212 sdev: 0.06609302870075934\n",
      "Training iteration: 173          last optimization: 100+ --> Actions:\n",
      "mean: 0.02331062490508229 sdev: 0.06609068303701565\n",
      "Training iteration: 174          last optimization: 100# --> Actions:\n",
      "mean: 0.023305442665131404 sdev: 0.06608862742782859\n",
      "Training iteration: 175          last optimization: 100+ --> Actions:\n",
      "mean: 0.023301847575818782 sdev: 0.06608710601030668\n",
      "Training iteration: 176          last optimization: 100# --> Actions:\n",
      "mean: 0.023299396769305702 sdev: 0.06608647129490716\n",
      "Training iteration: 177          last optimization: 100+ --> Actions:\n",
      "mean: 0.02329785088467659 sdev: 0.06608706881581562\n",
      "Training iteration: 178          last optimization: 100# --> Actions:\n",
      "mean: 0.023296826067072375 sdev: 0.06608892583717492\n",
      "Training iteration: 179          last optimization: 100+ --> Actions:\n",
      "mean: 0.02329399680940652 sdev: 0.06609262630525845\n",
      "Training iteration: 180          last optimization: 100# --> Actions:\n",
      "mean: 0.02329192574091084 sdev: 0.06609770847371209\n",
      "Training iteration: 181          last optimization: 100+ --> Actions:\n",
      "mean: 0.02329015315229837 sdev: 0.06610298185650793\n",
      "Training iteration: 182          last optimization: 100# --> Actions:\n",
      "mean: 0.023289238546032643 sdev: 0.0661087728207825\n",
      "Training iteration: 183          last optimization: 100+ --> Actions:\n",
      "mean: 0.023289830939046248 sdev: 0.06611368043420074\n",
      "Training iteration: 184          last optimization: 100# --> Actions:\n",
      "mean: 0.023291211759730163 sdev: 0.06611837479308229\n",
      "Training iteration: 185          last optimization: 100+ --> Actions:\n",
      "mean: 0.023293311008521105 sdev: 0.06612190562164277\n",
      "Training iteration: 186          last optimization: 100# --> Actions:\n",
      "mean: 0.0232960509504967 sdev: 0.06612382669721385\n",
      "Training iteration: 187          last optimization: 100+ --> Actions:\n",
      "mean: 0.023299826858124647 sdev: 0.06612447384338445\n",
      "Training iteration: 188          last optimization: 100# --> Actions:\n",
      "mean: 0.02330418333530308 sdev: 0.06612342306209269\n",
      "Training iteration: 189          last optimization: 100+ --> Actions:\n",
      "mean: 0.023308756037674277 sdev: 0.06612046554513881\n",
      "Training iteration: 190          last optimization: 100# --> Actions:\n",
      "mean: 0.02331287920844414 sdev: 0.066114644531376\n",
      "Training iteration: 191          last optimization: 100+ --> Actions:\n",
      "mean: 0.023316298246618225 sdev: 0.06610744786379204\n",
      "Training iteration: 192          last optimization: 100# --> Actions:\n",
      "mean: 0.023318617099080237 sdev: 0.0660998334583036\n",
      "Training iteration: 193          last optimization: 100+ --> Actions:\n",
      "mean: 0.023319524681485744 sdev: 0.06609280321330689\n",
      "Training iteration: 194          last optimization: 100# --> Actions:\n",
      "mean: 0.023319206221905378 sdev: 0.06608677189144155\n",
      "Training iteration: 195          last optimization: 100+ --> Actions:\n",
      "mean: 0.023318337242488496 sdev: 0.06608351702251548\n",
      "Training iteration: 196          last optimization: 100# --> Actions:\n",
      "mean: 0.02331470220969311 sdev: 0.0660823800403818\n",
      "Training iteration: 197          last optimization: 100+ --> Actions:\n",
      "mean: 0.02330983912990365 sdev: 0.06608235614319895\n",
      "Training iteration: 198          last optimization: 100# --> Actions:\n",
      "mean: 0.02330396552083491 sdev: 0.0660834741570253\n",
      "Training iteration: 199          last optimization: 100+ --> Actions:\n",
      "mean: 0.023296877805263037 sdev: 0.06608315314665092\n",
      "Training iteration: 200          last optimization: 200# --> Actions:\n",
      "mean: 0.02865548376500534 sdev: 0.05335856318092816\n",
      "Training iteration: 201          last optimization: 200+ --> Actions:\n",
      "mean: 0.028655868770953965 sdev: 0.05335773061565758\n",
      "Training iteration: 202          last optimization: 200# --> Actions:\n",
      "mean: 0.02865519966272482 sdev: 0.05335579224764328\n",
      "Training iteration: 203          last optimization: 200+ --> Actions:\n",
      "mean: 0.028653678784407985 sdev: 0.05335280252224564\n",
      "Training iteration: 204          last optimization: 200# --> Actions:\n",
      "mean: 0.02865152239263309 sdev: 0.05334874577533104\n",
      "Training iteration: 205          last optimization: 200+ --> Actions:\n",
      "mean: 0.02864852508340406 sdev: 0.05334386733470859\n",
      "Training iteration: 206          last optimization: 200# --> Actions:\n",
      "mean: 0.02864446910715627 sdev: 0.053338535548734904\n",
      "Training iteration: 207          last optimization: 200+ --> Actions:\n",
      "mean: 0.028642024287460717 sdev: 0.053332694909799916\n",
      "Training iteration: 208          last optimization: 200# --> Actions:\n",
      "mean: 0.028639856564179104 sdev: 0.053327101614534474\n",
      "Training iteration: 209          last optimization: 200+ --> Actions:\n",
      "mean: 0.028637727974426725 sdev: 0.05332223852835951\n",
      "Training iteration: 210          last optimization: 200# --> Actions:\n",
      "mean: 0.028634988637853104 sdev: 0.05331903907685322\n",
      "Training iteration: 211          last optimization: 200+ --> Actions:\n",
      "mean: 0.028632192521574975 sdev: 0.053317373716407365\n",
      "Training iteration: 212          last optimization: 200# --> Actions:\n",
      "mean: 0.02862966932941064 sdev: 0.05331722257792197\n",
      "Training iteration: 213          last optimization: 200+ --> Actions:\n",
      "mean: 0.028629285966803593 sdev: 0.053319622355789735\n",
      "Training iteration: 214          last optimization: 200# --> Actions:\n",
      "mean: 0.02862987726461866 sdev: 0.053324076421742715\n",
      "Training iteration: 215          last optimization: 200+ --> Actions:\n",
      "mean: 0.028630895821073588 sdev: 0.05332893006260736\n",
      "Training iteration: 216          last optimization: 200# --> Actions:\n",
      "mean: 0.028633288238927433 sdev: 0.053334243906335524\n",
      "Training iteration: 217          last optimization: 200+ --> Actions:\n",
      "mean: 0.0286381099374172 sdev: 0.05333914204698163\n",
      "Training iteration: 218          last optimization: 200# --> Actions:\n",
      "mean: 0.02864335801531596 sdev: 0.05334443999669839\n",
      "Training iteration: 219          last optimization: 200+ --> Actions:\n",
      "mean: 0.0286499672446478 sdev: 0.05334953222928455\n",
      "Training iteration: 220          last optimization: 200# --> Actions:\n",
      "mean: 0.028657634698818477 sdev: 0.05335466955664812\n",
      "Training iteration: 221          last optimization: 200+ --> Actions:\n",
      "mean: 0.02866486751717565 sdev: 0.05335954035592188\n",
      "Training iteration: 222          last optimization: 200# --> Actions:\n",
      "mean: 0.028672155098696195 sdev: 0.05336430997869928\n",
      "Training iteration: 223          last optimization: 200+ --> Actions:\n",
      "mean: 0.02867914432580302 sdev: 0.05336950766775936\n",
      "Training iteration: 224          last optimization: 200# --> Actions:\n",
      "mean: 0.028685065136971243 sdev: 0.05337471169663032\n",
      "Training iteration: 225          last optimization: 200+ --> Actions:\n",
      "mean: 0.02868958171140877 sdev: 0.05337906856978194\n",
      "Training iteration: 226          last optimization: 200# --> Actions:\n",
      "mean: 0.02869257749920255 sdev: 0.05338236664253667\n",
      "Training iteration: 227          last optimization: 200+ --> Actions:\n",
      "mean: 0.028697548606465846 sdev: 0.053385061863219126\n",
      "Training iteration: 228          last optimization: 200# --> Actions:\n",
      "mean: 0.02870454704956442 sdev: 0.053386813434807945\n",
      "Training iteration: 229          last optimization: 200+ --> Actions:\n",
      "mean: 0.02871061737445556 sdev: 0.0533873293776822\n",
      "Training iteration: 230          last optimization: 200# --> Actions:\n",
      "mean: 0.02871460733468973 sdev: 0.053386495522829584\n",
      "Training iteration: 231          last optimization: 200+ --> Actions:\n",
      "mean: 0.028716757311149824 sdev: 0.05338482237315745\n",
      "Training iteration: 232          last optimization: 200# --> Actions:\n",
      "mean: 0.028717299883325956 sdev: 0.05338132942310394\n",
      "Training iteration: 233          last optimization: 200+ --> Actions:\n",
      "mean: 0.02871657917166561 sdev: 0.05337618514749001\n",
      "Training iteration: 234          last optimization: 200# --> Actions:\n",
      "mean: 0.028714460440092914 sdev: 0.05336937161188881\n",
      "Training iteration: 235          last optimization: 200+ --> Actions:\n",
      "mean: 0.02871055419821639 sdev: 0.05336137277343113\n",
      "Training iteration: 236          last optimization: 200# --> Actions:\n",
      "mean: 0.028704988568489718 sdev: 0.05335265043433783\n",
      "Training iteration: 237          last optimization: 200+ --> Actions:\n",
      "mean: 0.02869800447724749 sdev: 0.05334370101533487\n",
      "Training iteration: 238          last optimization: 200# --> Actions:\n",
      "mean: 0.028690375400013547 sdev: 0.0533349058428116\n",
      "Training iteration: 239          last optimization: 200+ --> Actions:\n",
      "mean: 0.028682313337823697 sdev: 0.05332670826482221\n",
      "Training iteration: 240          last optimization: 200# --> Actions:\n",
      "mean: 0.028677798586218467 sdev: 0.05331906450662587\n",
      "Training iteration: 241          last optimization: 200+ --> Actions:\n",
      "mean: 0.028673811294531986 sdev: 0.05331293106951231\n",
      "Training iteration: 242          last optimization: 200# --> Actions:\n",
      "mean: 0.028669220478617467 sdev: 0.053309144093916634\n",
      "Training iteration: 243          last optimization: 200+ --> Actions:\n",
      "mean: 0.028664413569699322 sdev: 0.05330751010156842\n",
      "Training iteration: 244          last optimization: 200# --> Actions:\n",
      "mean: 0.028659649882657165 sdev: 0.05330750647340723\n",
      "Training iteration: 245          last optimization: 200+ --> Actions:\n",
      "mean: 0.028655037624051825 sdev: 0.05330929864720015\n",
      "Training iteration: 246          last optimization: 200# --> Actions:\n",
      "mean: 0.028650772253570912 sdev: 0.0533131964041618\n",
      "Training iteration: 247          last optimization: 200+ --> Actions:\n",
      "mean: 0.028647584728995007 sdev: 0.05331795214198873\n",
      "Training iteration: 248          last optimization: 200# --> Actions:\n",
      "mean: 0.028645840515774963 sdev: 0.05332320825931459\n",
      "Training iteration: 249          last optimization: 200+ --> Actions:\n",
      "mean: 0.02864581866918857 sdev: 0.05332861544215423\n",
      "Training iteration: 250          last optimization: 200# --> Actions:\n",
      "mean: 0.028647629777246345 sdev: 0.05333387181489729\n",
      "Training iteration: 251          last optimization: 200+ --> Actions:\n",
      "mean: 0.02865114487851022 sdev: 0.05333874554677739\n",
      "Training iteration: 252          last optimization: 200# --> Actions:\n",
      "mean: 0.02865596939871281 sdev: 0.05334307551383977\n",
      "Training iteration: 253          last optimization: 200+ --> Actions:\n",
      "mean: 0.0286614924409077 sdev: 0.05334675606886134\n",
      "Training iteration: 254          last optimization: 200# --> Actions:\n",
      "mean: 0.028667006125261386 sdev: 0.05334972786081406\n",
      "Training iteration: 255          last optimization: 200+ --> Actions:\n",
      "mean: 0.028671851110488415 sdev: 0.05335198218693551\n",
      "Training iteration: 256          last optimization: 200# --> Actions:\n",
      "mean: 0.028675564028528288 sdev: 0.053354480105054294\n",
      "Training iteration: 257          last optimization: 200+ --> Actions:\n",
      "mean: 0.02867661155984973 sdev: 0.0533574762347166\n",
      "Training iteration: 258          last optimization: 200# --> Actions:\n",
      "mean: 0.02867816190603291 sdev: 0.05336028911865862\n",
      "Training iteration: 259          last optimization: 200+ --> Actions:\n",
      "mean: 0.02867813894458013 sdev: 0.053361617293508266\n",
      "Training iteration: 260          last optimization: 200# --> Actions:\n",
      "mean: 0.0286768837841737 sdev: 0.0533614502206131\n",
      "Training iteration: 261          last optimization: 200+ --> Actions:\n",
      "mean: 0.028675348513375543 sdev: 0.05336053920446987\n",
      "Training iteration: 262          last optimization: 200# --> Actions:\n",
      "mean: 0.028672800107727804 sdev: 0.053358608462646284\n",
      "Training iteration: 263          last optimization: 200+ --> Actions:\n",
      "mean: 0.028669841707509254 sdev: 0.053356242566280694\n",
      "Training iteration: 264          last optimization: 200# --> Actions:\n",
      "mean: 0.028666116303631764 sdev: 0.05335267479562095\n",
      "Training iteration: 265          last optimization: 200+ --> Actions:\n",
      "mean: 0.02866168524504397 sdev: 0.05334784714128065\n",
      "Training iteration: 266          last optimization: 200# --> Actions:\n",
      "mean: 0.028656511339962387 sdev: 0.053341925684695486\n",
      "Training iteration: 267          last optimization: 200+ --> Actions:\n",
      "mean: 0.028650858467640532 sdev: 0.053335122913795455\n",
      "Training iteration: 268          last optimization: 200# --> Actions:\n",
      "mean: 0.028646206290341106 sdev: 0.053327199095870345\n",
      "Training iteration: 269          last optimization: 200+ --> Actions:\n",
      "mean: 0.028641831348359993 sdev: 0.05331916216290773\n",
      "Training iteration: 270          last optimization: 200# --> Actions:\n",
      "mean: 0.028637664269555156 sdev: 0.05331159586674847\n",
      "Training iteration: 271          last optimization: 200+ --> Actions:\n",
      "mean: 0.028633653152683763 sdev: 0.05330501581181294\n",
      "Training iteration: 272          last optimization: 200# --> Actions:\n",
      "mean: 0.028629686122794394 sdev: 0.05329992358624155\n",
      "Training iteration: 273          last optimization: 200+ --> Actions:\n",
      "mean: 0.028624847800193216 sdev: 0.05329740701611892\n",
      "Training iteration: 274          last optimization: 200# --> Actions:\n",
      "mean: 0.02862004425643965 sdev: 0.05329703300038642\n",
      "Training iteration: 275          last optimization: 200+ --> Actions:\n",
      "mean: 0.028615325321013733 sdev: 0.053298990496788864\n",
      "Training iteration: 276          last optimization: 200# --> Actions:\n",
      "mean: 0.028612447094238318 sdev: 0.05330310001143479\n",
      "Training iteration: 277          last optimization: 200+ --> Actions:\n",
      "mean: 0.028611721078569047 sdev: 0.05330914983096073\n",
      "Training iteration: 278          last optimization: 200# --> Actions:\n",
      "mean: 0.028612284317008675 sdev: 0.053316298857287635\n",
      "Training iteration: 279          last optimization: 200+ --> Actions:\n",
      "mean: 0.02861400789540186 sdev: 0.05332378744461505\n",
      "Training iteration: 280          last optimization: 200# --> Actions:\n",
      "mean: 0.028617723217357116 sdev: 0.05333170280875447\n",
      "Training iteration: 281          last optimization: 200+ --> Actions:\n",
      "mean: 0.028622641136237012 sdev: 0.05333957146780615\n",
      "Training iteration: 282          last optimization: 200# --> Actions:\n",
      "mean: 0.028627886836170582 sdev: 0.053347518737956255\n",
      "Training iteration: 283          last optimization: 200+ --> Actions:\n",
      "mean: 0.028633554739993846 sdev: 0.053354876641954166\n",
      "Training iteration: 284          last optimization: 200# --> Actions:\n",
      "mean: 0.028639096198413205 sdev: 0.05336157852769178\n",
      "Training iteration: 285          last optimization: 200+ --> Actions:\n",
      "mean: 0.02864380451200491 sdev: 0.05336813874911591\n",
      "Training iteration: 286          last optimization: 200# --> Actions:\n",
      "mean: 0.028647511287360497 sdev: 0.0533736539870104\n",
      "Training iteration: 287          last optimization: 200+ --> Actions:\n",
      "mean: 0.028651006975487003 sdev: 0.05337766441701801\n",
      "Training iteration: 288          last optimization: 200# --> Actions:\n",
      "mean: 0.028654031687258892 sdev: 0.05338117144665588\n",
      "Training iteration: 289          last optimization: 200+ --> Actions:\n",
      "mean: 0.028656383754159836 sdev: 0.05338400835360762\n",
      "Training iteration: 290          last optimization: 200# --> Actions:\n",
      "mean: 0.028658367885138848 sdev: 0.05338599697645455\n",
      "Training iteration: 291          last optimization: 200+ --> Actions:\n",
      "mean: 0.028661854617228415 sdev: 0.05338664217082299\n",
      "Training iteration: 292          last optimization: 200# --> Actions:\n",
      "mean: 0.02866539261896334 sdev: 0.053386516415043696\n",
      "Training iteration: 293          last optimization: 200+ --> Actions:\n",
      "mean: 0.028668639313745654 sdev: 0.053385019970383314\n",
      "Training iteration: 294          last optimization: 200# --> Actions:\n",
      "mean: 0.0286712653630114 sdev: 0.05338193414144756\n",
      "Training iteration: 295          last optimization: 200+ --> Actions:\n",
      "mean: 0.028673626751674054 sdev: 0.05337718202287664\n",
      "Training iteration: 296          last optimization: 200# --> Actions:\n",
      "mean: 0.0286756195029704 sdev: 0.05337087475297102\n",
      "Training iteration: 297          last optimization: 200+ --> Actions:\n",
      "mean: 0.028677184675024364 sdev: 0.053363313520998594\n",
      "Training iteration: 298          last optimization: 200# --> Actions:\n",
      "mean: 0.028677882994288716 sdev: 0.05335495783975136\n",
      "Training iteration: 299          last optimization: 200+ --> Actions:\n",
      "mean: 0.02867782059313851 sdev: 0.053346354482233495\n",
      "Training iteration: 300          last optimization: 300# --> Actions:\n",
      "mean: 0.03628142716372291 sdev: 0.04153260267062667\n",
      "Training iteration: 301          last optimization: 300+ --> Actions:\n",
      "mean: 0.03629441985920483 sdev: 0.041531383546448176\n",
      "Training iteration: 302          last optimization: 300# --> Actions:\n",
      "mean: 0.03629960666978908 sdev: 0.04153230584393875\n",
      "Training iteration: 303          last optimization: 300+ --> Actions:\n",
      "mean: 0.03629602910058622 sdev: 0.041535917123675374\n",
      "Training iteration: 304          last optimization: 300# --> Actions:\n",
      "mean: 0.03628988927546275 sdev: 0.04154110343467819\n",
      "Training iteration: 305          last optimization: 300+ --> Actions:\n",
      "mean: 0.03628180116365501 sdev: 0.041547635597027004\n",
      "Training iteration: 306          last optimization: 300# --> Actions:\n",
      "mean: 0.036272842963901084 sdev: 0.04155489766926921\n",
      "Training iteration: 307          last optimization: 300+ --> Actions:\n",
      "mean: 0.03626310838112905 sdev: 0.04156275552320813\n",
      "Training iteration: 308          last optimization: 300# --> Actions:\n",
      "mean: 0.03625234558595586 sdev: 0.041570565360249834\n",
      "Training iteration: 309          last optimization: 300+ --> Actions:\n",
      "mean: 0.03624436354471038 sdev: 0.04157850042837346\n",
      "Training iteration: 310          last optimization: 300# --> Actions:\n",
      "mean: 0.036234636276381106 sdev: 0.041587546913994\n",
      "Training iteration: 311          last optimization: 300+ --> Actions:\n",
      "mean: 0.036224846693999925 sdev: 0.041596493634069406\n",
      "Training iteration: 312          last optimization: 300# --> Actions:\n",
      "mean: 0.03621482400158057 sdev: 0.04160317179843625\n",
      "Training iteration: 313          last optimization: 300+ --> Actions:\n",
      "mean: 0.03621080979082006 sdev: 0.041606871617947974\n",
      "Training iteration: 314          last optimization: 300# --> Actions:\n",
      "mean: 0.036213300673669964 sdev: 0.04160973400141672\n",
      "Training iteration: 315          last optimization: 300+ --> Actions:\n",
      "mean: 0.03622005741494921 sdev: 0.04161232150799119\n",
      "Training iteration: 316          last optimization: 300# --> Actions:\n",
      "mean: 0.036228315920927165 sdev: 0.04161477732729022\n",
      "Training iteration: 317          last optimization: 300+ --> Actions:\n",
      "mean: 0.03623262062715643 sdev: 0.041617601222012544\n",
      "Training iteration: 318          last optimization: 300# --> Actions:\n",
      "mean: 0.03623256542704218 sdev: 0.04161966387965954\n",
      "Training iteration: 319          last optimization: 300+ --> Actions:\n",
      "mean: 0.036230846950839064 sdev: 0.04162206339006258\n",
      "Training iteration: 320          last optimization: 300# --> Actions:\n",
      "mean: 0.0362284788690713 sdev: 0.04162299797285093\n",
      "Training iteration: 321          last optimization: 300+ --> Actions:\n",
      "mean: 0.03622597912788255 sdev: 0.041622355493124055\n",
      "Training iteration: 322          last optimization: 300# --> Actions:\n",
      "mean: 0.03622423371389804 sdev: 0.04162032216205133\n",
      "Training iteration: 323          last optimization: 300+ --> Actions:\n",
      "mean: 0.0362198923976814 sdev: 0.04161687389174505\n",
      "Training iteration: 324          last optimization: 300# --> Actions:\n",
      "mean: 0.036216623192483824 sdev: 0.04161120104454427\n",
      "Training iteration: 325          last optimization: 300+ --> Actions:\n",
      "mean: 0.036216343176633636 sdev: 0.0416003801590272\n",
      "Training iteration: 326          last optimization: 300# --> Actions:\n",
      "mean: 0.0362185507179874 sdev: 0.04158792512605963\n",
      "Training iteration: 327          last optimization: 300+ --> Actions:\n",
      "mean: 0.03622291561665988 sdev: 0.04157478911911333\n",
      "Training iteration: 328          last optimization: 300# --> Actions:\n",
      "mean: 0.0362281172050613 sdev: 0.04156300605903389\n",
      "Training iteration: 329          last optimization: 300+ --> Actions:\n",
      "mean: 0.03623409637345453 sdev: 0.041552062037322014\n",
      "Training iteration: 330          last optimization: 300# --> Actions:\n",
      "mean: 0.03623792613118948 sdev: 0.04154315736763962\n",
      "Training iteration: 331          last optimization: 300+ --> Actions:\n",
      "mean: 0.0362390774651856 sdev: 0.04153613530989024\n",
      "Training iteration: 332          last optimization: 300# --> Actions:\n",
      "mean: 0.036239068967491316 sdev: 0.041530812795596825\n",
      "Training iteration: 333          last optimization: 300+ --> Actions:\n",
      "mean: 0.0362382201341152 sdev: 0.0415272628542426\n",
      "Training iteration: 334          last optimization: 300# --> Actions:\n",
      "mean: 0.036235056519648826 sdev: 0.04152525496751969\n",
      "Training iteration: 335          last optimization: 300+ --> Actions:\n",
      "mean: 0.03622634530716007 sdev: 0.04152356621329909\n",
      "Training iteration: 336          last optimization: 300# --> Actions:\n",
      "mean: 0.03621477331197904 sdev: 0.04152287860749947\n",
      "Training iteration: 337          last optimization: 300+ --> Actions:\n",
      "mean: 0.036202425673690905 sdev: 0.041523405603119214\n",
      "Training iteration: 338          last optimization: 300# --> Actions:\n",
      "mean: 0.03619083162889735 sdev: 0.04152478126823488\n",
      "Training iteration: 339          last optimization: 300+ --> Actions:\n",
      "mean: 0.03617762445218926 sdev: 0.04152793869450776\n",
      "Training iteration: 340          last optimization: 300# --> Actions:\n",
      "mean: 0.0361654595300361 sdev: 0.04153177416628671\n",
      "Training iteration: 341          last optimization: 300+ --> Actions:\n",
      "mean: 0.03615761888883166 sdev: 0.04153568439239845\n",
      "Training iteration: 342          last optimization: 300# --> Actions:\n",
      "mean: 0.03615243721696054 sdev: 0.041539467148739864\n",
      "Training iteration: 343          last optimization: 300+ --> Actions:\n",
      "mean: 0.03615154470704512 sdev: 0.04154258253067758\n",
      "Training iteration: 344          last optimization: 300# --> Actions:\n",
      "mean: 0.03615701455111233 sdev: 0.041545241432360526\n",
      "Training iteration: 345          last optimization: 300+ --> Actions:\n",
      "mean: 0.03616669725096512 sdev: 0.04154748478895098\n",
      "Training iteration: 346          last optimization: 300# --> Actions:\n",
      "mean: 0.036178540469470485 sdev: 0.04154974807456929\n",
      "Training iteration: 347          last optimization: 300+ --> Actions:\n",
      "mean: 0.036185514921903104 sdev: 0.041554313961702234\n",
      "Training iteration: 348          last optimization: 300# --> Actions:\n",
      "mean: 0.03619141660254303 sdev: 0.04155864427538021\n",
      "Training iteration: 349          last optimization: 300+ --> Actions:\n",
      "mean: 0.03619476339502194 sdev: 0.04156202821034855\n",
      "Training iteration: 350          last optimization: 300# --> Actions:\n",
      "mean: 0.03619598727618816 sdev: 0.041566046213018217\n",
      "Training iteration: 351          last optimization: 300+ --> Actions:\n",
      "mean: 0.0361909516357614 sdev: 0.041570327575330746\n",
      "Training iteration: 352          last optimization: 300# --> Actions:\n",
      "mean: 0.036187259660524225 sdev: 0.041574256380122056\n",
      "Training iteration: 353          last optimization: 300+ --> Actions:\n",
      "mean: 0.03618225998291775 sdev: 0.041575543719298017\n",
      "Training iteration: 354          last optimization: 300# --> Actions:\n",
      "mean: 0.03617726819312105 sdev: 0.0415738195291305\n",
      "Training iteration: 355          last optimization: 300+ --> Actions:\n",
      "mean: 0.0361748467066952 sdev: 0.04156898091320358\n",
      "Training iteration: 356          last optimization: 300# --> Actions:\n",
      "mean: 0.03617558800416021 sdev: 0.04156145470619291\n",
      "Training iteration: 357          last optimization: 300+ --> Actions:\n",
      "mean: 0.036179664835095916 sdev: 0.041551954039918584\n",
      "Training iteration: 358          last optimization: 300# --> Actions:\n",
      "mean: 0.03618654437041014 sdev: 0.04154116108914163\n",
      "Training iteration: 359          last optimization: 300+ --> Actions:\n",
      "mean: 0.03619564591792991 sdev: 0.0415299484132051\n",
      "Training iteration: 360          last optimization: 300# --> Actions:\n",
      "mean: 0.03620456030947894 sdev: 0.04151860222301357\n",
      "Training iteration: 361          last optimization: 300+ --> Actions:\n",
      "mean: 0.03621680632863994 sdev: 0.04150865592962626\n",
      "Training iteration: 362          last optimization: 300# --> Actions:\n",
      "mean: 0.036228516317928464 sdev: 0.04150163917272351\n",
      "Training iteration: 363          last optimization: 300+ --> Actions:\n",
      "mean: 0.03623911656973685 sdev: 0.04149657964012166\n",
      "Training iteration: 364          last optimization: 300# --> Actions:\n",
      "mean: 0.03624774064707967 sdev: 0.0414933646305174\n",
      "Training iteration: 365          last optimization: 300+ --> Actions:\n",
      "mean: 0.036250481422150066 sdev: 0.04149245577068097\n",
      "Training iteration: 366          last optimization: 300# --> Actions:\n",
      "mean: 0.036246660902984326 sdev: 0.04149464007668949\n",
      "Training iteration: 367          last optimization: 300+ --> Actions:\n",
      "mean: 0.03624153167835949 sdev: 0.0414982089295931\n",
      "Training iteration: 368          last optimization: 300# --> Actions:\n",
      "mean: 0.036235611234098415 sdev: 0.041503131715438464\n",
      "Training iteration: 369          last optimization: 300+ --> Actions:\n",
      "mean: 0.03623127828272293 sdev: 0.041509159899761915\n",
      "Training iteration: 370          last optimization: 300# --> Actions:\n",
      "mean: 0.036229159088506845 sdev: 0.04151614173178876\n",
      "Training iteration: 371          last optimization: 300+ --> Actions:\n",
      "mean: 0.03622798573458062 sdev: 0.0415240603159579\n",
      "Training iteration: 372          last optimization: 300# --> Actions:\n",
      "mean: 0.03622808567760005 sdev: 0.041532938105683766\n",
      "Training iteration: 373          last optimization: 300+ --> Actions:\n",
      "mean: 0.03622749460137195 sdev: 0.04154295626119291\n",
      "Training iteration: 374          last optimization: 300# --> Actions:\n",
      "mean: 0.03622886508062958 sdev: 0.04155390929378247\n",
      "Training iteration: 375          last optimization: 300+ --> Actions:\n",
      "mean: 0.03623614048165441 sdev: 0.04156485311473737\n",
      "Training iteration: 376          last optimization: 300# --> Actions:\n",
      "mean: 0.03624461155577464 sdev: 0.04157546439302247\n",
      "Training iteration: 377          last optimization: 300+ --> Actions:\n",
      "mean: 0.03625275148436366 sdev: 0.041586087171152024\n",
      "Training iteration: 378          last optimization: 300# --> Actions:\n",
      "mean: 0.036258316654539144 sdev: 0.04159743694479037\n",
      "Training iteration: 379          last optimization: 300+ --> Actions:\n",
      "mean: 0.03626124185553497 sdev: 0.04160763174413929\n",
      "Training iteration: 380          last optimization: 300# --> Actions:\n",
      "mean: 0.03626034876700781 sdev: 0.041617051001330396\n",
      "Training iteration: 381          last optimization: 300+ --> Actions:\n",
      "mean: 0.03625489156241895 sdev: 0.04162582896846414\n",
      "Training iteration: 382          last optimization: 300# --> Actions:\n",
      "mean: 0.036249559715643094 sdev: 0.04163209343125514\n",
      "Training iteration: 383          last optimization: 300+ --> Actions:\n",
      "mean: 0.03624471476371233 sdev: 0.04163517383813047\n",
      "Training iteration: 384          last optimization: 300# --> Actions:\n",
      "mean: 0.03624139306399624 sdev: 0.041634908717714095\n",
      "Training iteration: 385          last optimization: 300+ --> Actions:\n",
      "mean: 0.036240295565222215 sdev: 0.04163120193050076\n",
      "Training iteration: 386          last optimization: 300# --> Actions:\n",
      "mean: 0.03624165696888015 sdev: 0.04162410369556296\n",
      "Training iteration: 387          last optimization: 300+ --> Actions:\n",
      "mean: 0.03624572176722887 sdev: 0.04161443490260805\n",
      "Training iteration: 388          last optimization: 300# --> Actions:\n",
      "mean: 0.03625330074807283 sdev: 0.04160372284613899\n",
      "Training iteration: 389          last optimization: 300+ --> Actions:\n",
      "mean: 0.036262993578555607 sdev: 0.041592402662573545\n",
      "Training iteration: 390          last optimization: 300# --> Actions:\n",
      "mean: 0.03627376363108447 sdev: 0.04158118859900749\n",
      "Training iteration: 391          last optimization: 300+ --> Actions:\n",
      "mean: 0.03628467733471715 sdev: 0.0415706987747726\n",
      "Training iteration: 392          last optimization: 300# --> Actions:\n",
      "mean: 0.03629435571147215 sdev: 0.041561639242855844\n",
      "Training iteration: 393          last optimization: 300+ --> Actions:\n",
      "mean: 0.036300658507780935 sdev: 0.041555132484628776\n",
      "Training iteration: 394          last optimization: 300# --> Actions:\n",
      "mean: 0.03629887915120732 sdev: 0.04155240952122299\n",
      "Training iteration: 395          last optimization: 300+ --> Actions:\n",
      "mean: 0.03629410529182757 sdev: 0.04155142016926518\n",
      "Training iteration: 396          last optimization: 300# --> Actions:\n",
      "mean: 0.03628403187934114 sdev: 0.04155180733191807\n",
      "Training iteration: 397          last optimization: 300+ --> Actions:\n",
      "mean: 0.036270328762512724 sdev: 0.04155315196689824\n",
      "Training iteration: 398          last optimization: 300# --> Actions:\n",
      "mean: 0.03625512460306814 sdev: 0.04155573240997147\n",
      "Training iteration: 399          last optimization: 300+ --> Actions:\n",
      "mean: 0.03623942804183806 sdev: 0.041559384709846096\n",
      "Training iteration: 400          last optimization: 400# --> Actions:\n",
      "mean: 0.04179412778563686 sdev: 0.03179362525082438\n",
      "Training iteration: 401          last optimization: 400+ --> Actions:\n",
      "mean: 0.041781630139242895 sdev: 0.03180029288083792\n",
      "Training iteration: 402          last optimization: 400# --> Actions:\n",
      "mean: 0.041771534676629786 sdev: 0.03180873996234727\n",
      "Training iteration: 403          last optimization: 400+ --> Actions:\n",
      "mean: 0.041764459441953936 sdev: 0.031819117689341724\n",
      "Training iteration: 404          last optimization: 400# --> Actions:\n",
      "mean: 0.04176007856753011 sdev: 0.031829188721493304\n",
      "Training iteration: 405          last optimization: 400+ --> Actions:\n",
      "mean: 0.0417579892212501 sdev: 0.03183878733265411\n",
      "Training iteration: 406          last optimization: 400# --> Actions:\n",
      "mean: 0.04175743846811969 sdev: 0.031848956144204396\n",
      "Training iteration: 407          last optimization: 400+ --> Actions:\n",
      "mean: 0.0417572553656325 sdev: 0.0318591744887602\n",
      "Training iteration: 408          last optimization: 400# --> Actions:\n",
      "mean: 0.041756760500634205 sdev: 0.031867966252603616\n",
      "Training iteration: 409          last optimization: 400+ --> Actions:\n",
      "mean: 0.04175501404272596 sdev: 0.0318745208669057\n",
      "Training iteration: 410          last optimization: 400# --> Actions:\n",
      "mean: 0.04175117207119762 sdev: 0.031878140209852954\n",
      "Training iteration: 411          last optimization: 400+ --> Actions:\n",
      "mean: 0.04174485165177386 sdev: 0.03187831079506324\n",
      "Training iteration: 412          last optimization: 400# --> Actions:\n",
      "mean: 0.0417352800873263 sdev: 0.03187362006771495\n",
      "Training iteration: 413          last optimization: 400+ --> Actions:\n",
      "mean: 0.041724555460266245 sdev: 0.03186646369073168\n",
      "Training iteration: 414          last optimization: 400# --> Actions:\n",
      "mean: 0.04171478581744306 sdev: 0.031858143121979425\n",
      "Training iteration: 415          last optimization: 400+ --> Actions:\n",
      "mean: 0.04170598787265761 sdev: 0.03184794052839257\n",
      "Training iteration: 416          last optimization: 400# --> Actions:\n",
      "mean: 0.0416992157823654 sdev: 0.03183642896441135\n",
      "Training iteration: 417          last optimization: 400+ --> Actions:\n",
      "mean: 0.041694710338546485 sdev: 0.03182670198965425\n",
      "Training iteration: 418          last optimization: 400# --> Actions:\n",
      "mean: 0.041692777620826744 sdev: 0.03181750939538237\n",
      "Training iteration: 419          last optimization: 400+ --> Actions:\n",
      "mean: 0.041692703561475496 sdev: 0.03180696984084988\n",
      "Training iteration: 420          last optimization: 400# --> Actions:\n",
      "mean: 0.041694839859693224 sdev: 0.03179743312423737\n",
      "Training iteration: 421          last optimization: 400+ --> Actions:\n",
      "mean: 0.04169832215199986 sdev: 0.03178922591470489\n",
      "Training iteration: 422          last optimization: 400# --> Actions:\n",
      "mean: 0.041702760023337594 sdev: 0.03178268373399325\n",
      "Training iteration: 423          last optimization: 400+ --> Actions:\n",
      "mean: 0.04170779495825523 sdev: 0.03177800648159647\n",
      "Training iteration: 424          last optimization: 400# --> Actions:\n",
      "mean: 0.04171083796345747 sdev: 0.03177480608151364\n",
      "Training iteration: 425          last optimization: 400+ --> Actions:\n",
      "mean: 0.04170942505826095 sdev: 0.031773885344645744\n",
      "Training iteration: 426          last optimization: 400# --> Actions:\n",
      "mean: 0.04170506167528798 sdev: 0.031774251466304186\n",
      "Training iteration: 427          last optimization: 400+ --> Actions:\n",
      "mean: 0.04169913889635168 sdev: 0.031775626646794695\n",
      "Training iteration: 428          last optimization: 400# --> Actions:\n",
      "mean: 0.041692095426636704 sdev: 0.03177801701742857\n",
      "Training iteration: 429          last optimization: 400+ --> Actions:\n",
      "mean: 0.04168356765856644 sdev: 0.03178234698372735\n",
      "Training iteration: 430          last optimization: 400# --> Actions:\n",
      "mean: 0.04167629339572336 sdev: 0.031787219247415066\n",
      "Training iteration: 431          last optimization: 400+ --> Actions:\n",
      "mean: 0.04167239718089075 sdev: 0.03179148749755045\n",
      "Training iteration: 432          last optimization: 400# --> Actions:\n",
      "mean: 0.04167193225638741 sdev: 0.03179607352385373\n",
      "Training iteration: 433          last optimization: 400+ --> Actions:\n",
      "mean: 0.0416752070479264 sdev: 0.03180106849845975\n",
      "Training iteration: 434          last optimization: 400# --> Actions:\n",
      "mean: 0.04168115718374644 sdev: 0.03180635979576068\n",
      "Training iteration: 435          last optimization: 400+ --> Actions:\n",
      "mean: 0.041688067345294205 sdev: 0.03181254663048607\n",
      "Training iteration: 436          last optimization: 400# --> Actions:\n",
      "mean: 0.041696546959354305 sdev: 0.03181915064767597\n",
      "Training iteration: 437          last optimization: 400+ --> Actions:\n",
      "mean: 0.04170542006224202 sdev: 0.03182540717878381\n",
      "Training iteration: 438          last optimization: 400# --> Actions:\n",
      "mean: 0.04171315730158466 sdev: 0.031830867720968284\n",
      "Training iteration: 439          last optimization: 400+ --> Actions:\n",
      "mean: 0.04171723651498922 sdev: 0.0318363076441937\n",
      "Training iteration: 440          last optimization: 400# --> Actions:\n",
      "mean: 0.04171971695084212 sdev: 0.03183852561242912\n",
      "Training iteration: 441          last optimization: 400+ --> Actions:\n",
      "mean: 0.04171829779379471 sdev: 0.031837878393923366\n",
      "Training iteration: 442          last optimization: 400# --> Actions:\n",
      "mean: 0.04171505316712311 sdev: 0.03183616516350053\n",
      "Training iteration: 443          last optimization: 400+ --> Actions:\n",
      "mean: 0.041709757883162044 sdev: 0.03183290549237486\n",
      "Training iteration: 444          last optimization: 400# --> Actions:\n",
      "mean: 0.04170516611878266 sdev: 0.03182765680663206\n",
      "Training iteration: 445          last optimization: 400+ --> Actions:\n",
      "mean: 0.0417021954486264 sdev: 0.031820404940984044\n",
      "Training iteration: 446          last optimization: 400# --> Actions:\n",
      "mean: 0.041702005541282394 sdev: 0.03181165402476836\n",
      "Training iteration: 447          last optimization: 400+ --> Actions:\n",
      "mean: 0.04170527815639265 sdev: 0.03180206885461437\n",
      "Training iteration: 448          last optimization: 400# --> Actions:\n",
      "mean: 0.041712085683211976 sdev: 0.03179227776952173\n",
      "Training iteration: 449          last optimization: 400+ --> Actions:\n",
      "mean: 0.04172260708853071 sdev: 0.031783210713534904\n",
      "Training iteration: 450          last optimization: 400# --> Actions:\n",
      "mean: 0.04173532513709379 sdev: 0.031775389794153765\n",
      "Training iteration: 451          last optimization: 400+ --> Actions:\n",
      "mean: 0.04174946112986449 sdev: 0.031769450062949435\n",
      "Training iteration: 452          last optimization: 400# --> Actions:\n",
      "mean: 0.04176371600209616 sdev: 0.03176483622874624\n",
      "Training iteration: 453          last optimization: 400+ --> Actions:\n",
      "mean: 0.04177675401902308 sdev: 0.03176126738631591\n",
      "Training iteration: 454          last optimization: 400# --> Actions:\n",
      "mean: 0.041787417351721715 sdev: 0.03175847982349884\n",
      "Training iteration: 455          last optimization: 400+ --> Actions:\n",
      "mean: 0.04179553359490431 sdev: 0.03175681404242591\n",
      "Training iteration: 456          last optimization: 400# --> Actions:\n",
      "mean: 0.04180014126804167 sdev: 0.031756233522972785\n",
      "Training iteration: 457          last optimization: 400+ --> Actions:\n",
      "mean: 0.04180298972328128 sdev: 0.03175700992492788\n",
      "Training iteration: 458          last optimization: 400# --> Actions:\n",
      "mean: 0.04180508335505375 sdev: 0.031759107246953924\n",
      "Training iteration: 459          last optimization: 400+ --> Actions:\n",
      "mean: 0.041804464848947835 sdev: 0.031763400627447036\n",
      "Training iteration: 460          last optimization: 400# --> Actions:\n",
      "mean: 0.0418013598174804 sdev: 0.03177021679775359\n",
      "Training iteration: 461          last optimization: 400+ --> Actions:\n",
      "mean: 0.041799459654936325 sdev: 0.03177703428669826\n",
      "Training iteration: 462          last optimization: 400# --> Actions:\n",
      "mean: 0.04179847674127668 sdev: 0.03178381518979555\n",
      "Training iteration: 463          last optimization: 400+ --> Actions:\n",
      "mean: 0.04179907776718941 sdev: 0.03179139558958811\n",
      "Training iteration: 464          last optimization: 400# --> Actions:\n",
      "mean: 0.04180213157167951 sdev: 0.031798905704986204\n",
      "Training iteration: 465          last optimization: 400+ --> Actions:\n",
      "mean: 0.0418072775436252 sdev: 0.03180584819961929\n",
      "Training iteration: 466          last optimization: 400# --> Actions:\n",
      "mean: 0.04181261446262007 sdev: 0.03181415352084008\n",
      "Training iteration: 467          last optimization: 400+ --> Actions:\n",
      "mean: 0.041815834613882004 sdev: 0.03182446469563615\n",
      "Training iteration: 468          last optimization: 400# --> Actions:\n",
      "mean: 0.04181909444178894 sdev: 0.03183342439882224\n",
      "Training iteration: 469          last optimization: 400+ --> Actions:\n",
      "mean: 0.041822054659583136 sdev: 0.03184001957784161\n",
      "Training iteration: 470          last optimization: 400# --> Actions:\n",
      "mean: 0.041823487047203185 sdev: 0.03184518736240783\n",
      "Training iteration: 471          last optimization: 400+ --> Actions:\n",
      "mean: 0.041822777267992196 sdev: 0.0318474320074187\n",
      "Training iteration: 472          last optimization: 400# --> Actions:\n",
      "mean: 0.04181946852405246 sdev: 0.0318456856920041\n",
      "Training iteration: 473          last optimization: 400+ --> Actions:\n",
      "mean: 0.04181416532576234 sdev: 0.03184236787140475\n",
      "Training iteration: 474          last optimization: 400# --> Actions:\n",
      "mean: 0.04180937505395154 sdev: 0.031838140137840025\n",
      "Training iteration: 475          last optimization: 400+ --> Actions:\n",
      "mean: 0.04180533136232961 sdev: 0.03183264796291836\n",
      "Training iteration: 476          last optimization: 400# --> Actions:\n",
      "mean: 0.04180283290943668 sdev: 0.03182646312007812\n",
      "Training iteration: 477          last optimization: 400+ --> Actions:\n",
      "mean: 0.04180222750582341 sdev: 0.031820150764558804\n",
      "Training iteration: 478          last optimization: 400# --> Actions:\n",
      "mean: 0.041803590211196465 sdev: 0.03181410499565364\n",
      "Training iteration: 479          last optimization: 400+ --> Actions:\n",
      "mean: 0.04180668501414783 sdev: 0.03180859701177915\n",
      "Training iteration: 480          last optimization: 400# --> Actions:\n",
      "mean: 0.04181068322024588 sdev: 0.031803187948867384\n",
      "Training iteration: 481          last optimization: 400+ --> Actions:\n",
      "mean: 0.041814737918280206 sdev: 0.03179796147271916\n",
      "Training iteration: 482          last optimization: 400# --> Actions:\n",
      "mean: 0.04181844533529554 sdev: 0.03179363117715269\n",
      "Training iteration: 483          last optimization: 400+ --> Actions:\n",
      "mean: 0.04182138217786992 sdev: 0.03179051852005584\n",
      "Training iteration: 484          last optimization: 400# --> Actions:\n",
      "mean: 0.041821358447910184 sdev: 0.031788362366762565\n",
      "Training iteration: 485          last optimization: 400+ --> Actions:\n",
      "mean: 0.04181778595644028 sdev: 0.03178795784160075\n",
      "Training iteration: 486          last optimization: 400# --> Actions:\n",
      "mean: 0.041810250372549096 sdev: 0.03178942361864365\n",
      "Training iteration: 487          last optimization: 400+ --> Actions:\n",
      "mean: 0.041800279689631105 sdev: 0.031791557325941765\n",
      "Training iteration: 488          last optimization: 400# --> Actions:\n",
      "mean: 0.04178840880944407 sdev: 0.03179422953443765\n",
      "Training iteration: 489          last optimization: 400+ --> Actions:\n",
      "mean: 0.04177542408240455 sdev: 0.03179735209454114\n",
      "Training iteration: 490          last optimization: 400# --> Actions:\n",
      "mean: 0.041762290924361074 sdev: 0.031800886501486166\n",
      "Training iteration: 491          last optimization: 400+ --> Actions:\n",
      "mean: 0.041750029840566256 sdev: 0.03180484887159356\n",
      "Training iteration: 492          last optimization: 400# --> Actions:\n",
      "mean: 0.04173855037487449 sdev: 0.03181011709124251\n",
      "Training iteration: 493          last optimization: 400+ --> Actions:\n",
      "mean: 0.04173005752808743 sdev: 0.03181535384747431\n",
      "Training iteration: 494          last optimization: 400# --> Actions:\n",
      "mean: 0.04172484504186624 sdev: 0.03182048252235467\n",
      "Training iteration: 495          last optimization: 400+ --> Actions:\n",
      "mean: 0.04172208242805215 sdev: 0.03182591822222613\n",
      "Training iteration: 496          last optimization: 400# --> Actions:\n",
      "mean: 0.04172200964716423 sdev: 0.0318318298331594\n",
      "Training iteration: 497          last optimization: 400+ --> Actions:\n",
      "mean: 0.041722459254149656 sdev: 0.03183850855606488\n",
      "Training iteration: 498          last optimization: 400# --> Actions:\n",
      "mean: 0.04172057217153039 sdev: 0.031845912159569785\n",
      "Training iteration: 499          last optimization: 400+ --> Actions:\n",
      "mean: 0.04171913953402457 sdev: 0.031850769112020984\n",
      "Training iteration: 500          last optimization: 500#\n",
      "***--> Total Elapsed Runtime: 00:00:46 for training the agent\n"
     ]
    }
   ],
   "source": [
    "# Thx2: https://discuss.pytorch.org/t/how-to-check-if-model-is-on-cuda/180/2?u=ferenc_acs\n",
    "start_time = time()\n",
    "\n",
    "agent.train()\n",
    "\n",
    "end_time = time()\n",
    "\n",
    "print_elapsed_time(start_time, end_time, \"for training the agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***--> Total Elapsed Runtime: 00:00:00 for observing the trained agent\n",
      "#\n",
      "Total score (averaged over agents) this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Some reminders about lambda functions\n",
    "# Thx2: https://realpython.com/python-lambda/\n",
    "# Thx2: https://thispointer.com/python-how-to-use-if-else-elif-in-lambda-functions/\n",
    "\n",
    "RANDOMRUN = False\n",
    "\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "#env_info = env.reset(train_mode=True)[brain_name] # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "avg100sum = np.zeros(num_agents)\n",
    "exectime = 0\n",
    "\n",
    "scores100 = deque(avg100sum, 100)\n",
    "time100 = list()\n",
    "epc = 0\n",
    "\n",
    "\n",
    "#import pdb; pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "start_time = time()\n",
    "\n",
    "while RANDOMRUN: #== True:\n",
    "    epc += 1\n",
    "    #print(f'\\r#{epc}', end = ' ')\n",
    "    print(f'\\r#{str(epc).rjust(6)}', end = ' ')\n",
    "    #actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = agent.a2c_net.select_action(states)\n",
    "    #actions = np.clip(actions.detach().cpu().numpy(), -1, 1)                  # all actions between -1 and 1\n",
    "        \n",
    "    t_step_b = time()\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    t_step_e = time()\n",
    "    time100.append(t_step_e - t_step_b)\n",
    "    \n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    rewards = env_info.rewards\n",
    "    nprewards = np.array(rewards)\n",
    "    scores += rewards                         # update the score (for each agent)\n",
    "    scores100.append(rewards)\n",
    "    if np.sum(nprewards) > 0:\n",
    "        #for x in scores100:\n",
    "        #    avg100sum += x\n",
    "        print(f'\\r#{epc} Avg 100 Rewards = {np.mean(scores100)}')  \n",
    "        avg100sum = np.zeros(num_agents)\n",
    "        maskagent = nprewards > 0\n",
    "        \n",
    "    if epc%100 == 0:\n",
    "        print(f'Exec time Avg 100: {np.mean(time100)}')\n",
    "        time100 = []\n",
    "        \n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "        \n",
    "end_time = time()\n",
    "\n",
    "print_elapsed_time(start_time, end_time, \"for observing the trained agent\")\n",
    "        \n",
    "print('#')\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-27 / 08-34-31  Notebook for Continuous Control ended.\n"
     ]
    }
   ],
   "source": [
    "print(get_time_string(sep=True), ' Notebook for Continuous Control ended.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
