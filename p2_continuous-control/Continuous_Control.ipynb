{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posix.uname_result(sysname='Linux', nodename='Anubis-Linux', release='5.4.0-48-generic', version='#52-Ubuntu SMP Thu Sep 10 10:58:49 UTC 2020', machine='x86_64')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.uname())\n",
    "\n",
    "# In the cloud environment?\n",
    "if 'root' in os.environ['HOME']:\n",
    "    UENVPATH = '/data/'\n",
    "    !pip -q install /home/workspace/python\n",
    "\n",
    "# In the standalone environment?\n",
    "if 'ferenc' in os.environ['HOME']:\n",
    "    UENVPATH = '/home/ferenc/Python/rl/udadrl/data/'\n",
    "\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "import pprint as pp\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "from time import time\n",
    "\n",
    "# Import the helper files\n",
    "from utilities import get_time_string, print_elapsed_time\n",
    "\n",
    "import pdb # Debug! Debug! Debug! Debug! Debug! Debug! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-26 / 20-31-16  Notebook for Continuous Control started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "print(get_time_string(sep=True), ' Notebook for Continuous Control started.')\n",
    "\n",
    "# ONE Agent, Standalone\n",
    "#UENVCHOICE = 'Reacher_Linux/Reacher.x86_64'\n",
    "\n",
    "# TWENTY Agents, Standalone\n",
    "#UENVCHOICE = 'Reacher_Linux_20/Reacher.x86_64'\n",
    "\n",
    "# ONE Agent, Cloud, No-Visuals \n",
    "#UENVCHOICE = 'Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64'\n",
    "\n",
    "# TWENTY Agents, Cloud, No-Visuals \n",
    "UENVCHOICE = 'Reacher_Linux_NoVis/Reacher.x86_64'\n",
    "\n",
    "env = UnityEnvironment( file_name=os.path.join( UENVPATH, UENVCHOICE ) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unityagents.environment.UnityEnvironment"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FA DEBUG! DEBUG! DEBUG! \n",
    "type(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ReacherBrain']\n",
      "<class 'unityagents.brain.BrainParameters'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ReacherBrain'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FA  DEBUG! DEBUG! DEBUG! \n",
    "print(env.brain_names)\n",
    "print( type(brain) )\n",
    "brain.brain_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space: 33 dimensions of continuous type\n",
      "Action Space: 4 dimensions of continuous type\n"
     ]
    }
   ],
   "source": [
    "# FA  DEBUG! DEBUG! DEBUG!\n",
    "print(f'Observation Space: {brain.vector_observation_space_size} dimensions of {brain.vector_observation_space_type} type') \n",
    "print(f'Action Space: {brain.vector_action_space_size} dimensions of {brain.vector_observation_space_type} type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 20 active agents\n",
      "\n",
      "***--> Total Elapsed Runtime: 00:00:00 for choosing random actions\n",
      "#\n",
      "Total score (averaged over agents) this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Should a run with random actions be perfomed first?\n",
    "RANDOMRUN = False\n",
    "\n",
    "# Some reminders about lambda functions\n",
    "# Thx2: https://realpython.com/python-lambda/\n",
    "# Thx2: https://thispointer.com/python-how-to-use-if-else-elif-in-lambda-functions/\n",
    "# thx2: https://www.blog.pythonlibrary.org/2016/05/24/python-101-an-intro-to-benchmarking-your-code/\n",
    "import timeit\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "\n",
    "epc = 0\n",
    "print(f'We have {num_agents} active agent' + ( lambda x: 's' if x>1 else '' )(num_agents) )\n",
    "\n",
    "start_time = time()\n",
    "setup = \"from unityagents import UnityEnvironment\"\n",
    "\n",
    "while RANDOMRUN:\n",
    "    epc += 1\n",
    "    #print(f'\\r#{epc}', end = ' ')\n",
    "    print(f'\\r#{str(epc).rjust(6)}', end = ' ')\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    #pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    #print( timeit.timeit(\"env_info = env.step(actions)[brain_name]\", setup) )\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    rewards = env_info.rewards\n",
    "    nprewards = np.array(rewards)\n",
    "    scores += rewards                         # update the score (for each agent)\n",
    "    if np.sum(nprewards) > 0:\n",
    "        #print(f'\\r#{epc} Rewards = {rewards}')\n",
    "        maskagent = nprewards > 0\n",
    "        agentbefore = False\n",
    "        for (nagent, action) in enumerate(actions):\n",
    "            if maskagent[nagent]:\n",
    "                if agentbefore:\n",
    "                    print('\\r#' + '&'.rjust(6), end = ' ')\n",
    "                print(' -> Agent {:0>2d} got reward {:+.5f} for action: {}'.format(nagent+1, rewards[nagent], action))\n",
    "                agentbefore = True\n",
    "                #pp.pprint(list(action))\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "        \n",
    "end_time = time()\n",
    "\n",
    "print_elapsed_time(start_time, end_time, \"for choosing random actions\")\n",
    "\n",
    "print('#')\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re check running time (Random run)\n",
    "This time with the leanest code possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 20 active agents\n",
      "\n",
      "***--> Total Elapsed Runtime: 00:00:00 for choosing fast random actions\n",
      "#\n",
      "Total score (averaged over agents) this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Should another run with random actions be perfomed?\n",
    "RANDOMRUN = False\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "#env_info = env.reset(train_mode=True)[brain_name] # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "\n",
    "epc = 0\n",
    "print(f'We have {num_agents} active agent' + ( lambda x: 's' if x>1 else '' )(num_agents) )\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "while RANDOMRUN:\n",
    "    epc += 1\n",
    "    print(f'\\r#{str(epc).rjust(6)}', end = ' ')\n",
    "    #pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "        \n",
    "end_time = time()\n",
    "\n",
    "print_elapsed_time(start_time, end_time, \"for choosing fast random actions\")\n",
    "\n",
    "print('#')\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.12805176e+00,\n",
       "        -1.00000000e+00, -3.63192368e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  3.92812490e-02],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  5.03456116e+00,\n",
       "        -1.00000000e+00,  6.21716690e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  9.63666677e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  5.24847412e+00,\n",
       "        -1.00000000e+00,  6.03767776e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00, -1.35212541e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -7.87846184e+00,\n",
       "        -1.00000000e+00, -1.38918507e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00, -5.42254448e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -2.79192984e-01,\n",
       "        -1.00000000e+00,  7.99512672e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  7.49394178e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  4.70228195e+00,\n",
       "        -1.00000000e+00, -6.47213650e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  2.25743055e-02],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -3.75577545e+00,\n",
       "        -1.00000000e+00, -7.06358004e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  5.07442713e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.38918495e+00,\n",
       "        -1.00000000e+00,  7.87846184e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00, -4.48411107e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.73616028e+00,\n",
       "        -1.00000000e+00, -7.51754141e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00, -5.25649071e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -5.55726719e+00,\n",
       "        -1.00000000e+00, -5.75471878e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  6.52894735e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -6.99695778e+00,\n",
       "        -1.00000000e+00,  3.87847900e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  8.39847088e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.60454559e+00,\n",
       "        -1.00000000e+00, -7.56414795e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  8.63162279e-02],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.30836487e+00,\n",
       "        -1.00000000e+00,  3.25389290e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  5.08338690e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.96955776e+00,\n",
       "        -1.00000000e+00,  6.97246552e-01,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  6.07460499e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.51754093e+00,\n",
       "        -1.00000000e+00,  2.73616028e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  5.45782328e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -7.25046158e+00,\n",
       "        -1.00000000e+00, -3.38094544e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  2.36645341e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -2.79193878e-01,\n",
       "        -1.00000000e+00,  7.99512482e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  5.87887526e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.33897400e+00,\n",
       "        -1.00000000e+00, -7.65043640e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  6.67207956e-01],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -5.75471878e+00,\n",
       "        -1.00000000e+00,  5.55726624e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00, -5.25265932e-02],\n",
       "       [ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -4.37113883e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.00000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  5.94515800e+00,\n",
       "        -1.00000000e+00, -5.35304642e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00, -8.03074121e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# thx2: https://github.com/udacity/deep-reinforcement-learning/blob/master/python/unityagents/brain.py\n",
    "env_info.vector_observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When finished, you can close the environment.\n",
    "#### Just not for now because unit testing below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FA: One BIG MISUNDERSTANDING & STACKS OF TENSORS (23-08-2020) --> #FA; BMSoT:\n",
    "It has cost me several days if not weeks to get behind the fact that the [A2C sample implementation of Miguel](https://github.com/mimoralea/gdrl/blob/master/notebooks/chapter_11/chapter-11.ipynb) is working with **stacks of tensors** instead of single tensors. Which was especially hard to find because the PyTorch code looks exactly the same for both.\n",
    "\n",
    "In the end, when I thought about it, it makes sense and is a nifty feature of PyTorch. It is just not obvious to people like me, without in deep insights in the inner workings of PyTorch. \n",
    "\n",
    "Furthermore the authors of the PyTorch documentation seem not to make it too visible, I had to dig it out of one of the function definitions I use, however inderectly over the layer defintion for a2cnet:\n",
    "\n",
    "https://pytorch.org/docs/0.4.0/_modules/torch/nn/functional.html#linear\n",
    "\n",
    "> def linear(input, weight, bias=None):\n",
    ">    \"\"\"\n",
    ">    Applies a linear transformation to the incoming data: :math:`y = xA^T + b`.\n",
    ">\n",
    ">    Shape:\n",
    ">        - Input: :math:`(N, *, in\\_features)` where `*` means any number of\n",
    ">          additional dimensions\n",
    ">        - Weight: :math:`(out\\_features, in\\_features)`\n",
    ">        - Bias: :math:`(out\\_features)`\n",
    ">        - Output: :math:`(N, *, out\\_features)`\n",
    ">    \"\"\"\n",
    ">    if input.dim() == 2 and bias is not None:\n",
    ">        # fused op is marginally faster\n",
    ">        return torch.addmm(bias, input, weight.t())\n",
    ">\n",
    ">    output = input.matmul(weight.t())\n",
    ">    if bias is not None:\n",
    ">        output += bias\n",
    ">    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracing the error in the 'mya2cnet' module code refactoring below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! TEST! \n",
    "#import pdb; pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(20200808) # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "#torch.manual_seed(456454618181) # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "\n",
    "# Format: IN_Num [Layer 1] (OUT_Num = IN_Num) [Layer 2] OUT_Num = ...\n",
    "HIDDEN_DIMS_DEFAULT = {\n",
    "    'shared' : (512, 512, 256, 256),\n",
    "    'actor' : (256, 128, 128, 64),\n",
    "    'critic' : (256, 128, 128, 64)\n",
    "}\n",
    "hidden_dims = HIDDEN_DIMS_DEFAULT\n",
    "\n",
    "hlayers = dict()\n",
    "\n",
    "hlayers['shared'] = nn.ModuleList()\n",
    "hlayers['actor'] = nn.ModuleList()\n",
    "hlayers['critic'] = nn.ModuleList()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "input_layer = nn.Linear( 33, hidden_dims['shared'][0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=33, out_features=512, bias=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layers shared\n",
    "for i in range( len(hidden_dims['shared']) -1 ):\n",
    "    hlayers['shared'].append( nn.Linear( hidden_dims['shared'][i], hidden_dims['shared'][i+1] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hlayers['shared']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actor layers\n",
    "for i in range( len(hidden_dims['actor']) ):\n",
    "    #import pdb; pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "    if i == 0:\n",
    "        hlayers['actor'].append( nn.Linear( hidden_dims['shared'][-1], hidden_dims['actor'][i] ) )\n",
    "    else:\n",
    "        # hlayers['actor'].append( nn.Linear( hidden_dims['actor'][i], hidden_dims['actor'][i+1] ERROR !!!\n",
    "        hlayers['actor'].append( nn.Linear( hidden_dims['actor'][i-1], hidden_dims['actor'][i] ) )\n",
    "    #print( i, hlayers['actor'] ) # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "        \n",
    "actor_out_layer = nn.Linear( hidden_dims['actor'][-1], 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (3): Linear(in_features=128, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hlayers['actor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=64, out_features=4, bias=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Critic layers\n",
    "for i in range( len(hidden_dims['critic']) ):\n",
    "    if i == 0:\n",
    "        hlayers['critic'].append( nn.Linear( hidden_dims['shared'][-1], hidden_dims['critic'][i] ) )\n",
    "    else:\n",
    "        hlayers['critic'].append( nn.Linear( hidden_dims['critic'][i-1], hidden_dims['critic'][i] ) )\n",
    "critic_out_layer = nn.Linear( hidden_dims['critic'][-1], 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (3): Linear(in_features=128, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hlayers['critic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=64, out_features=1, bias=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic_out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevents non Pytorch Tensor Object entering the processing stream\n",
    "def torch_format(state):\n",
    "    x = state\n",
    "    if not isinstance(x, torch.Tensor):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        if len(x.size()) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(state):\n",
    "    check_tensor = lambda x: isinstance(x, torch.Tensor)\n",
    "    x_act = True \n",
    "    x_crit = True\n",
    "\n",
    "    x = torch_format(state)\n",
    "    x = F.relu(  input_layer(x) )\n",
    "    for label in ['shared', 'actor', 'critic']:\n",
    "        for hlayer in  hlayers[label]:\n",
    "            if label == 'shared':\n",
    "                x = F.relu(  hlayer(x) )\n",
    "            if label == 'actor':\n",
    "                x_act = F.relu(  hlayer(x_act) )\n",
    "            if label == 'critic':\n",
    "                x_crit = F.relu(  hlayer(x_crit) )\n",
    "\n",
    "        # Thx2: https://discuss.pytorch.org/t/copy-deepcopy-vs-clone/55022\n",
    "        if ( type(x_act) == bool ):\n",
    "            x_act = x.clone()  # Create an Inplace copy...\n",
    "        if ( type(x_crit) == bool ):\n",
    "            x_crit = x.clone() # ...after processing shared layers\n",
    "\n",
    "    return  actor_out_layer(x_act),  critic_out_layer(x_crit) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if A STACK OF (BMSoT) states are propagated through the debug network\n",
    "And make a list of outputs of two A2C instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor: tensor(1.00000e-02 *\n",
      "       [[ 4.6543,  4.9756, -4.4953,  4.2128],\n",
      "        [ 4.7037,  4.9775, -4.4215,  4.1041],\n",
      "        [ 4.7006,  4.9798, -4.4235,  4.1018],\n",
      "        [ 4.6981,  4.9901, -4.3603,  4.1175],\n",
      "        [ 4.7117,  4.9911, -4.4272,  4.1191],\n",
      "        [ 4.6864,  4.9768, -4.4898,  4.2664],\n",
      "        [ 4.7017,  5.0059, -4.4374,  4.2481],\n",
      "        [ 4.7107,  4.9870, -4.4269,  4.1114],\n",
      "        [ 4.6985,  4.9721, -4.4752,  4.2727],\n",
      "        [ 4.6935,  5.0025, -4.4124,  4.2141],\n",
      "        [ 4.7007,  4.9718, -4.3907,  4.1061],\n",
      "        [ 4.6997,  4.9750, -4.4772,  4.2800],\n",
      "        [ 4.6790,  4.9917, -4.4376,  4.1197],\n",
      "        [ 4.6685,  4.9951, -4.4505,  4.1421],\n",
      "        [ 4.6763,  4.9944, -4.4406,  4.1248],\n",
      "        [ 4.6967,  4.9936, -4.3724,  4.1618],\n",
      "        [ 4.7116,  4.9925, -4.4258,  4.1176],\n",
      "        [ 4.7030,  4.9784, -4.4800,  4.2864],\n",
      "        [ 4.7116,  4.9804, -4.4134,  4.1002],\n",
      "        [ 4.6749,  4.9665, -4.4912,  4.2393]])\n",
      "Critic: tensor(1.00000e-02 *\n",
      "       [[ 4.7572],\n",
      "        [ 4.8767],\n",
      "        [ 4.8752],\n",
      "        [ 4.8696],\n",
      "        [ 4.8610],\n",
      "        [ 4.7746],\n",
      "        [ 4.8414],\n",
      "        [ 4.8706],\n",
      "        [ 4.8107],\n",
      "        [ 4.8393],\n",
      "        [ 4.8479],\n",
      "        [ 4.8147],\n",
      "        [ 4.8553],\n",
      "        [ 4.8110],\n",
      "        [ 4.8488],\n",
      "        [ 4.8638],\n",
      "        [ 4.8612],\n",
      "        [ 4.8194],\n",
      "        [ 4.8508],\n",
      "        [ 4.7676]])\n"
     ]
    }
   ],
   "source": [
    "#al = []\n",
    "#bl = []\n",
    "\n",
    "#for (dc, st) in enumerate(states):\n",
    "#    al.append(a)\n",
    "#    bl.append(b)\n",
    "\n",
    "#import pdb; pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!    \n",
    "    \n",
    "#FA; BMSoT: No need to iterate through states any more!\n",
    "a,b = forward(states)\n",
    "print(f'Actor: {a}')\n",
    "print(f'Critic: {b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if A STACK OF (BMSoT) states is propagated through the imported network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "\n",
    "#from mya2cnet import A2CNetwork\n",
    "import mya2cnet\n",
    "\n",
    "# Thx2: https://emacs.stackexchange.com/a/13483\n",
    "import imp\n",
    "imp.reload(mya2cnet)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tstnet1 = mya2cnet.A2CNetwork(33, 4).to(device) #FA; BMSoT: Looks exactly the same...\n",
    "tstnet2 = mya2cnet.A2CNetwork(33, 4).to(device) #FA; BMSoT: ...like without stacks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FA; BMSoT: OBSOLETE\n",
    "#for (dc, st) in enumerate(states):\n",
    "\n",
    "\n",
    "\n",
    "# pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! Debug! Debug!\n",
    "    \n",
    "#a1,b1 = tstnet1.forward(torch.tensor(states, dtype=torch.float, device=device))\n",
    "#a2,b2 = tstnet2.forward(torch.tensor(states).to(device))\n",
    "\n",
    "#print(f'Dist. Actor stacks 1-2: {torch.dist(a1, a2)}'.ljust(50) + ' # ' +\\\n",
    "#     f'Dist. Actor 1 stacks - Notebook stacks {torch.dist(a1, a)}'.rjust(50))\n",
    "#print(f'Dist. Critic stacks 1-2: {torch.dist(b1, b2)}'.ljust(50) + ' # ' +\\\n",
    "#     f'Dist. Critic 1 stacks - Notebook stacks {torch.dist(b1, b)}'.rjust(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next(tstnet1.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next(tstnet2.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FA; BMSoT: OBSOLETE\n",
    "#for (dc, st) in enumerate(states):\n",
    "#    print(f'({dc+1}) -> {tstnet1.fullpass(st)}')\n",
    "    \n",
    "#tstnet1.fullpass( torch.tensor(states, device = device, dtype = torch.float) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FA; BMSoT: OBSOLETE\n",
    "#for (dc, st) in enumerate(states):\n",
    "#    print(f'({dc+1})-> {tstnet1.select_action(st)}') #, end=' ')\n",
    "    \n",
    "#tstnet1.select_action(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the agent instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mya2cagent\n",
    "\n",
    "# Thx2: https://emacs.stackexchange.com/a/13483\n",
    "import imp\n",
    "imp.reload(mya2cagent)\n",
    "\n",
    "agent = mya2cagent.a2cagent(len(env_info.agents), env, brain, max_steps = 500, max_n_steps = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --> Actions:\n",
      "mean: 0.02347423920590171 sdev: 0.03959107614115\n",
      "Training iteration: 1            last optimization: 0+ --> Actions:\n",
      "mean: 0.023474444986695295 sdev: 0.0395914738501506\n",
      "Training iteration: 2            last optimization: 0# --> Actions:\n",
      "mean: 0.02347462940906156 sdev: 0.03959187398273974\n",
      "Training iteration: 3            last optimization: 0+ --> Actions:\n",
      "mean: 0.02347493917094157 sdev: 0.039592388519802714\n",
      "Training iteration: 4            last optimization: 0# --> Actions:\n",
      "mean: 0.023475292441308464 sdev: 0.03959289948486099\n",
      "Training iteration: 5            last optimization: 5+ --> Actions:\n",
      "mean: 0.022337646659870074 sdev: 0.03758612637024458\n",
      "Training iteration: 6            last optimization: 5# --> Actions:\n",
      "mean: 0.02233784510313203 sdev: 0.037586468722021066\n",
      "Training iteration: 7            last optimization: 5+ --> Actions:\n",
      "mean: 0.02233793541795304 sdev: 0.03758669726480504\n",
      "Training iteration: 8            last optimization: 5# --> Actions:\n",
      "mean: 0.022338033671780784 sdev: 0.03758679827582857\n",
      "Training iteration: 9            last optimization: 5+ --> Actions:\n",
      "mean: 0.02233815011317853 sdev: 0.03758667135264132\n",
      "Training iteration: 10           last optimization: 10# --> Actions:\n",
      "mean: 0.021200668545271247 sdev: 0.035579517394709756\n",
      "Training iteration: 11           last optimization: 10+ --> Actions:\n",
      "mean: 0.021200568834521656 sdev: 0.03557916357005585\n",
      "Training iteration: 12           last optimization: 10# --> Actions:\n",
      "mean: 0.02120035378573208 sdev: 0.0355788990053094\n",
      "Training iteration: 13           last optimization: 10+ --> Actions:\n",
      "mean: 0.021200090209538704 sdev: 0.03557856805371083\n",
      "Training iteration: 14           last optimization: 10# --> Actions:\n",
      "mean: 0.021199774578085723 sdev: 0.0355782557486734\n",
      "Training iteration: 15           last optimization: 15+ --> Actions:\n",
      "mean: 0.02006247450869806 sdev: 0.0335737857979233\n",
      "Training iteration: 16           last optimization: 15# --> Actions:\n",
      "mean: 0.020061887824914207 sdev: 0.033573787472114376\n",
      "Training iteration: 17           last optimization: 15+ --> Actions:\n",
      "mean: 0.020061290560699434 sdev: 0.033573991919429495\n",
      "Training iteration: 18           last optimization: 15# --> Actions:\n",
      "mean: 0.020060710883892406 sdev: 0.033574329855894536\n",
      "Training iteration: 19           last optimization: 15+ --> Actions:\n",
      "mean: 0.0200600583179903 sdev: 0.03357478454387763\n",
      "Training iteration: 20           last optimization: 20# --> Actions:\n",
      "mean: 0.018923227212103263 sdev: 0.03157330237524143\n",
      "Training iteration: 21           last optimization: 20+ --> Actions:\n",
      "mean: 0.018922617109773422 sdev: 0.03157411382659997\n",
      "Training iteration: 22           last optimization: 20# --> Actions:\n",
      "mean: 0.0189221126484153 sdev: 0.03157490820797207\n",
      "Training iteration: 23           last optimization: 20+ --> Actions:\n",
      "mean: 0.018921736813617834 sdev: 0.03157553843520885\n",
      "Training iteration: 24           last optimization: 20# --> Actions:\n",
      "mean: 0.01892145893786313 sdev: 0.03157599571161624\n",
      "Training iteration: 25           last optimization: 25+ --> Actions:\n",
      "mean: 0.01778614075597522 sdev: 0.029575691420369705\n",
      "Training iteration: 26           last optimization: 25# --> Actions:\n",
      "mean: 0.017785921840699343 sdev: 0.029575839363386813\n",
      "Training iteration: 27           last optimization: 25+ --> Actions:\n",
      "mean: 0.0177858842949031 sdev: 0.02957574976826343\n",
      "Training iteration: 28           last optimization: 25# --> Actions:\n",
      "mean: 0.017785904797286284 sdev: 0.029575419005227775\n",
      "Training iteration: 29           last optimization: 25+ --> Actions:\n",
      "mean: 0.017786014168588528 sdev: 0.029574934842004543\n",
      "Training iteration: 30           last optimization: 30# --> Actions:\n",
      "mean: 0.01665196674600474 sdev: 0.027576384444206535\n",
      "Training iteration: 31           last optimization: 30+ --> Actions:\n",
      "mean: 0.016652290641041977 sdev: 0.027575793904875374\n",
      "Training iteration: 32           last optimization: 30# --> Actions:\n",
      "mean: 0.016652712424751012 sdev: 0.027575188968971723\n",
      "Training iteration: 33           last optimization: 30+ --> Actions:\n",
      "mean: 0.016653085963542435 sdev: 0.027574761738558898\n",
      "Training iteration: 34           last optimization: 30# --> Actions:\n",
      "mean: 0.016653351028017092 sdev: 0.027574503319154293\n",
      "Training iteration: 35           last optimization: 35+ --> Actions:\n",
      "mean: 0.015520992457927285 sdev: 0.025579473775030323\n",
      "Training iteration: 36           last optimization: 35# --> Actions:\n",
      "mean: 0.015521214736288624 sdev: 0.025579595033588094\n",
      "Training iteration: 37           last optimization: 35+ --> Actions:\n",
      "mean: 0.015521463381026552 sdev: 0.02557969739678271\n",
      "Training iteration: 38           last optimization: 35# --> Actions:\n",
      "mean: 0.015521746334294045 sdev: 0.02557978154444171\n",
      "Training iteration: 39           last optimization: 35+ --> Actions:\n",
      "mean: 0.015521978256751306 sdev: 0.02557992039854161\n",
      "Training iteration: 40           last optimization: 40# --> Actions:\n",
      "mean: 0.014391566146134311 sdev: 0.023588558014848413\n",
      "Training iteration: 41           last optimization: 40+ --> Actions:\n",
      "mean: 0.014391673456494992 sdev: 0.023588742843174415\n",
      "Training iteration: 42           last optimization: 40# --> Actions:\n",
      "mean: 0.01439161785701484 sdev: 0.023588895992621307\n",
      "Training iteration: 43           last optimization: 40+ --> Actions:\n",
      "mean: 0.01439137040594084 sdev: 0.023589146146095065\n",
      "Training iteration: 44           last optimization: 40# --> Actions:\n",
      "mean: 0.014391071608433757 sdev: 0.023589505396535475\n",
      "Training iteration: 45           last optimization: 45+ --> Actions:\n",
      "mean: 0.013262569535491136 sdev: 0.02160252391789963\n",
      "Training iteration: 46           last optimization: 45# --> Actions:\n",
      "mean: 0.013262157210918599 sdev: 0.021603271209550974\n",
      "Training iteration: 47           last optimization: 45+ --> Actions:\n",
      "mean: 0.013261767105507047 sdev: 0.02160417280262376\n",
      "Training iteration: 48           last optimization: 45# --> Actions:\n",
      "mean: 0.013261369159492439 sdev: 0.021605152236292027\n",
      "Training iteration: 49           last optimization: 45+ --> Actions:\n",
      "mean: 0.013260953643635349 sdev: 0.021606168286561967\n",
      "Training iteration: 50           last optimization: 50# --> Actions:\n",
      "mean: 0.012135707086020528 sdev: 0.01962452856032418\n",
      "Training iteration: 51           last optimization: 50+ --> Actions:\n",
      "mean: 0.01213528795796766 sdev: 0.019625681446803687\n",
      "Training iteration: 52           last optimization: 50# --> Actions:\n",
      "mean: 0.012134939251079332 sdev: 0.0196267412483669\n",
      "Training iteration: 53           last optimization: 50+ --> Actions:\n",
      "mean: 0.012134663467774535 sdev: 0.019627565376784336\n",
      "Training iteration: 54           last optimization: 50# --> Actions:\n",
      "mean: 0.012134426017934491 sdev: 0.019628070692440464\n",
      "Training iteration: 55           last optimization: 55+ --> Actions:\n",
      "mean: 0.011013757678770558 sdev: 0.01765087026445492\n",
      "Training iteration: 56           last optimization: 55# --> Actions:\n",
      "mean: 0.011013602934361186 sdev: 0.017651009411972746\n",
      "Training iteration: 57           last optimization: 55+ --> Actions:\n",
      "mean: 0.011013490962229843 sdev: 0.017650953426118846\n",
      "Training iteration: 58           last optimization: 55# --> Actions:\n",
      "mean: 0.011013411990977618 sdev: 0.01765074440180431\n",
      "Training iteration: 59           last optimization: 55+ --> Actions:\n",
      "mean: 0.011013396025522901 sdev: 0.017650380949452805\n",
      "Training iteration: 60           last optimization: 60# --> Actions:\n",
      "mean: 0.009898547209865664 sdev: 0.015680150596745237\n",
      "Training iteration: 61           last optimization: 60+ --> Actions:\n",
      "mean: 0.009898508303775536 sdev: 0.015680015986900817\n",
      "Training iteration: 62           last optimization: 60# --> Actions:\n",
      "mean: 0.00989852321904108 sdev: 0.015679961931251055\n",
      "Training iteration: 63           last optimization: 60+ --> Actions:\n",
      "mean: 0.009898677277838403 sdev: 0.01567987217053001\n",
      "Training iteration: 64           last optimization: 60# --> Actions:\n",
      "mean: 0.009898931105081239 sdev: 0.015679861345696523\n",
      "Training iteration: 65           last optimization: 65+ --> Actions:\n",
      "mean: 0.008792616687226768 sdev: 0.01371878066610393\n",
      "Training iteration: 66           last optimization: 65# --> Actions:\n",
      "mean: 0.00879299702128356 sdev: 0.013718892558630092\n",
      "Training iteration: 67           last optimization: 65+ --> Actions:\n",
      "mean: 0.008793370194401993 sdev: 0.01371912726700214\n",
      "Training iteration: 68           last optimization: 65# --> Actions:\n",
      "mean: 0.008793708419822872 sdev: 0.013719416782390283\n",
      "Training iteration: 69           last optimization: 65+ --> Actions:\n",
      "mean: 0.008793948039251579 sdev: 0.01371970044790416\n",
      "Training iteration: 70           last optimization: 70# --> Actions:\n",
      "mean: 0.007699178885681059 sdev: 0.011770034265894132\n",
      "Training iteration: 71           last optimization: 70+ --> Actions:\n",
      "mean: 0.007699086728167577 sdev: 0.011770651806655572\n",
      "Training iteration: 72           last optimization: 70# --> Actions:\n",
      "mean: 0.007698953639895502 sdev: 0.01177134607647276\n",
      "Training iteration: 73           last optimization: 70+ --> Actions:\n",
      "mean: 0.007698676626553859 sdev: 0.01177218712747379\n",
      "Training iteration: 74           last optimization: 70# --> Actions:\n",
      "mean: 0.00769836329638454 sdev: 0.011773034761518588\n",
      "Training iteration: 75           last optimization: 75+ --> Actions:\n",
      "mean: 0.006619742704286306 sdev: 0.009838079755953511\n",
      "Training iteration: 76           last optimization: 75# --> Actions:\n",
      "mean: 0.006619207151183108 sdev: 0.009839008391447124\n",
      "Training iteration: 77           last optimization: 75+ --> Actions:\n",
      "mean: 0.00661868178137791 sdev: 0.009839966547512319\n",
      "Training iteration: 78           last optimization: 75# --> Actions:\n",
      "mean: 0.0066181866011396015 sdev: 0.009840881092485612\n",
      "Training iteration: 79           last optimization: 75+ --> Actions:\n",
      "mean: 0.00661770935576024 sdev: 0.00984169202470748\n",
      "Training iteration: 80           last optimization: 80# --> Actions:\n",
      "mean: 0.005563204602863191 sdev: 0.007924099340684861\n",
      "Training iteration: 81           last optimization: 80+ --> Actions:\n",
      "mean: 0.005562905942411259 sdev: 0.007924446202651831\n",
      "Training iteration: 82           last optimization: 80# --> Actions:\n",
      "mean: 0.005562647662841477 sdev: 0.007924647644227643\n",
      "Training iteration: 83           last optimization: 80+ --> Actions:\n",
      "mean: 0.0055624702398682 sdev: 0.007924589574666213\n",
      "Training iteration: 84           last optimization: 80# --> Actions:\n",
      "mean: 0.005562306751914507 sdev: 0.007924238759178697\n",
      "Training iteration: 85           last optimization: 85+ --> Actions:\n",
      "mean: 0.004543503917653498 sdev: 0.00602990600463109\n",
      "Training iteration: 86           last optimization: 85# --> Actions:\n",
      "mean: 0.004543313564811868 sdev: 0.006029336024412643\n",
      "Training iteration: 87           last optimization: 85+ --> Actions:\n",
      "mean: 0.00454314202954703 sdev: 0.0060286214408933276\n",
      "Training iteration: 88           last optimization: 85# --> Actions:\n",
      "mean: 0.004543009202290436 sdev: 0.006027839483137058\n",
      "Training iteration: 89           last optimization: 85+ --> Actions:\n",
      "mean: 0.004542973970595169 sdev: 0.0060270155081988\n",
      "Training iteration: 90           last optimization: 90# --> Actions:\n",
      "mean: 0.0035791018539170862 sdev: 0.0041672212998010326\n",
      "Training iteration: 91           last optimization: 90+ --> Actions:\n",
      "mean: 0.0035791833435458347 sdev: 0.004166724729742024\n",
      "Training iteration: 92           last optimization: 90# --> Actions:\n",
      "mean: 0.0035793569237878436 sdev: 0.004166232777471678\n",
      "Training iteration: 93           last optimization: 90+ --> Actions:\n",
      "mean: 0.0035796039171338847 sdev: 0.004165705390136082\n",
      "Training iteration: 94           last optimization: 90# --> Actions:\n",
      "mean: 0.0035798539225257524 sdev: 0.004165212542072294\n",
      "Training iteration: 95           last optimization: 95+ --> Actions:\n",
      "mean: 0.0027026510478317745 sdev: 0.0023689518541130886\n",
      "Training iteration: 96           last optimization: 95# --> Actions:\n",
      "mean: 0.002702813735130044 sdev: 0.0023687761570262886\n",
      "Training iteration: 97           last optimization: 95+ --> Actions:\n",
      "mean: 0.0027029253829961167 sdev: 0.0023687018938880365\n",
      "Training iteration: 98           last optimization: 95# --> Actions:\n",
      "mean: 0.002702877424302825 sdev: 0.002368747524618655\n",
      "Training iteration: 99           last optimization: 95+ --> Actions:\n",
      "mean: 0.0027026619932415423 sdev: 0.002368909485643199\n",
      "Training iteration: 100          last optimization: 100# --> Actions:\n",
      "mean: 0.0019647618270521644 sdev: 0.0009277474057646302\n",
      "Training iteration: 101          last optimization: 100+ --> Actions:\n",
      "mean: 0.001964205929340334 sdev: 0.0009286127625069555\n",
      "Training iteration: 102          last optimization: 100# --> Actions:\n",
      "mean: 0.001963567873876933 sdev: 0.00092961778765018\n",
      "Training iteration: 103          last optimization: 100+ --> Actions:\n",
      "mean: 0.001962945056079121 sdev: 0.0009306621512510808\n",
      "Training iteration: 104          last optimization: 100# --> Actions:\n",
      "mean: 0.0019622930514782773 sdev: 0.0009315329795140194\n",
      "Training iteration: 105          last optimization: 105+ --> Actions:\n",
      "mean: 0.0014807974143683249 sdev: 0.0015934050773207802\n",
      "Training iteration: 106          last optimization: 105# --> Actions:\n",
      "mean: 0.0014801112004828789 sdev: 0.0015927928969092318\n",
      "Training iteration: 107          last optimization: 105+ --> Actions:\n",
      "mean: 0.0014794675270591996 sdev: 0.0015918483567190665\n",
      "Training iteration: 108          last optimization: 105# --> Actions:\n",
      "mean: 0.0014788610567890133 sdev: 0.0015907598798686562\n",
      "Training iteration: 109          last optimization: 105+ --> Actions:\n",
      "mean: 0.0014782789683586814 sdev: 0.0015895937751510053\n",
      "Training iteration: 110          last optimization: 110# --> Actions:\n",
      "mean: 0.0011487422277714951 sdev: 0.002860109459560831\n",
      "Training iteration: 111          last optimization: 110+ --> Actions:\n",
      "mean: 0.0011483314983593452 sdev: 0.002859385802185194\n",
      "Training iteration: 112          last optimization: 110# --> Actions:\n",
      "mean: 0.0011479918827710849 sdev: 0.0028588736372694395\n",
      "Training iteration: 113          last optimization: 110+ --> Actions:\n",
      "mean: 0.0011477648251897602 sdev: 0.002858630605585775\n",
      "Training iteration: 114          last optimization: 110# --> Actions:\n",
      "mean: 0.0011476039844202078 sdev: 0.002858524321286475\n",
      "Training iteration: 115          last optimization: 115+ --> Actions:\n",
      "mean: 0.0009097356438277379 sdev: 0.00384941039515591\n",
      "Training iteration: 116          last optimization: 115# --> Actions:\n",
      "mean: 0.0009097360687138099 sdev: 0.0038496578612341134\n",
      "Training iteration: 117          last optimization: 115+ --> Actions:\n",
      "mean: 0.0009098561196332053 sdev: 0.003850032373734378\n",
      "Training iteration: 118          last optimization: 115# --> Actions:\n",
      "mean: 0.0009100615069041116 sdev: 0.0038503982143747355\n",
      "Training iteration: 119          last optimization: 115+ --> Actions:\n",
      "mean: 0.0009102707215568942 sdev: 0.003850687268792441\n",
      "Training iteration: 120          last optimization: 120# --> Actions:\n",
      "mean: 0.0007406584646992593 sdev: 0.004526235555751913\n",
      "Training iteration: 121          last optimization: 120+ --> Actions:\n",
      "mean: 0.0007408595070254107 sdev: 0.004526428604677777\n",
      "Training iteration: 122          last optimization: 120# --> Actions:\n",
      "mean: 0.0007410686468096257 sdev: 0.004526525608101739\n",
      "Training iteration: 123          last optimization: 120+ --> Actions:\n",
      "mean: 0.0007412974258366076 sdev: 0.004526567588146067\n",
      "Training iteration: 124          last optimization: 120# --> Actions:\n",
      "mean: 0.0007414862199192789 sdev: 0.004526555953514017\n",
      "Training iteration: 125          last optimization: 125+ --> Actions:\n",
      "mean: 0.0006268332403815124 sdev: 0.004913440538085343\n",
      "Training iteration: 126          last optimization: 125# --> Actions:\n",
      "mean: 0.000626922759388892 sdev: 0.004913205215953703\n",
      "Training iteration: 127          last optimization: 125+ --> Actions:\n",
      "mean: 0.0006268905420069387 sdev: 0.004912882308997361\n",
      "Training iteration: 128          last optimization: 125# --> Actions:\n",
      "mean: 0.000626815747913837 sdev: 0.004912514495059662\n",
      "Training iteration: 129          last optimization: 125+ --> Actions:\n",
      "mean: 0.0006266270705831667 sdev: 0.004912024216376617\n",
      "Training iteration: 130          last optimization: 130# --> Actions:\n",
      "mean: 0.0005591505078480954 sdev: 0.005047087474713524\n",
      "Training iteration: 131          last optimization: 130+ --> Actions:\n",
      "mean: 0.0005586735858476805 sdev: 0.005046326044795175\n",
      "Training iteration: 132          last optimization: 130# --> Actions:\n",
      "mean: 0.0005580240703257945 sdev: 0.005045434244881227\n",
      "Training iteration: 133          last optimization: 130+ --> Actions:\n",
      "mean: 0.0005572252700946856 sdev: 0.005044433183285434\n",
      "Training iteration: 134          last optimization: 130# --> Actions:\n",
      "mean: 0.0005563340049534654 sdev: 0.005043376594749178\n",
      "Training iteration: 135          last optimization: 135+ --> Actions:\n",
      "mean: 0.0005320470786214649 sdev: 0.004963781825473851\n",
      "Training iteration: 136          last optimization: 135# --> Actions:\n",
      "mean: 0.0005312521262245017 sdev: 0.004962867286692678\n",
      "Training iteration: 137          last optimization: 135+ --> Actions:\n",
      "mean: 0.0005305406567929764 sdev: 0.004962151964234374\n",
      "Training iteration: 138          last optimization: 135# --> Actions:\n",
      "mean: 0.0005298628889309967 sdev: 0.004961611387396382\n",
      "Training iteration: 139          last optimization: 135+ --> Actions:\n",
      "mean: 0.0005293524883081307 sdev: 0.004961228316521952\n",
      "Training iteration: 140          last optimization: 140# --> Actions:\n",
      "mean: 0.0005482675011875087 sdev: 0.004702841102048156\n",
      "Training iteration: 141          last optimization: 140+ --> Actions:\n",
      "mean: 0.0005480793048385721 sdev: 0.004703023969067164\n",
      "Training iteration: 142          last optimization: 140# --> Actions:\n",
      "mean: 0.0005481147816917213 sdev: 0.004703510956753467\n",
      "Training iteration: 143          last optimization: 140+ --> Actions:\n",
      "mean: 0.0005483176043335741 sdev: 0.004704212060675616\n",
      "Training iteration: 144          last optimization: 140# --> Actions:\n",
      "mean: 0.000548654603278384 sdev: 0.004705021920112398\n",
      "Training iteration: 145          last optimization: 145+ --> Actions:\n",
      "mean: 0.000613258018913578 sdev: 0.0042979215413959\n",
      "Training iteration: 146          last optimization: 145# --> Actions:\n",
      "mean: 0.0006138069767601079 sdev: 0.004298814744066232\n",
      "Training iteration: 147          last optimization: 145+ --> Actions:\n",
      "mean: 0.0006144287424269577 sdev: 0.004299809265776979\n",
      "Training iteration: 148          last optimization: 145# --> Actions:\n",
      "mean: 0.0006150798351192424 sdev: 0.0043008220634472225\n",
      "Training iteration: 149          last optimization: 145+ --> Actions:\n",
      "mean: 0.0006158423237274355 sdev: 0.004301934147716183\n",
      "Training iteration: 150          last optimization: 150# --> Actions:\n",
      "mean: 0.000730506472996426 sdev: 0.0037688066211299526\n",
      "Training iteration: 151          last optimization: 150+ --> Actions:\n",
      "mean: 0.0007314215543498529 sdev: 0.0037698553264434356\n",
      "Training iteration: 152          last optimization: 150# --> Actions:\n",
      "mean: 0.0007322693000985325 sdev: 0.0037707377404502915\n",
      "Training iteration: 153          last optimization: 150+ --> Actions:\n",
      "mean: 0.0007330155776510016 sdev: 0.0037713996091536684\n",
      "Training iteration: 154          last optimization: 150# --> Actions:\n",
      "mean: 0.0007336395268517234 sdev: 0.003771749351467763\n",
      "Training iteration: 155          last optimization: 155+ --> Actions:\n",
      "mean: 0.0009035633755736456 sdev: 0.003125469939817932\n",
      "Training iteration: 156          last optimization: 155# --> Actions:\n",
      "mean: 0.0009040191669126618 sdev: 0.0031255688056161966\n",
      "Training iteration: 157          last optimization: 155+ --> Actions:\n",
      "mean: 0.0009043766693377734 sdev: 0.0031256546939589774\n",
      "Training iteration: 158          last optimization: 155# --> Actions:\n",
      "mean: 0.0009047161609110921 sdev: 0.0031256898413199665\n",
      "Training iteration: 159          last optimization: 155+ --> Actions:\n",
      "mean: 0.0009050770969384984 sdev: 0.0031256781570752103\n",
      "Training iteration: 160          last optimization: 160# --> Actions:\n",
      "mean: 0.0011359195717439415 sdev: 0.0023717225215190495\n",
      "Training iteration: 161          last optimization: 160+ --> Actions:\n",
      "mean: 0.0011361724972365397 sdev: 0.002371517985516769\n",
      "Training iteration: 162          last optimization: 160# --> Actions:\n",
      "mean: 0.0011363416573472666 sdev: 0.002371270601642171\n",
      "Training iteration: 163          last optimization: 160+ --> Actions:\n",
      "mean: 0.001136601766331228 sdev: 0.0023711401919951822\n",
      "Training iteration: 164          last optimization: 160# --> Actions:\n",
      "mean: 0.001136876145478727 sdev: 0.002371228277289186\n",
      "Training iteration: 165          last optimization: 165+ --> Actions:\n",
      "mean: 0.0014299604173493613 sdev: 0.0015078800127847013\n",
      "Training iteration: 166          last optimization: 165# --> Actions:\n",
      "mean: 0.00143040618095958 sdev: 0.001508358749431396\n",
      "Training iteration: 167          last optimization: 165+ --> Actions:\n",
      "mean: 0.0014309954718606077 sdev: 0.0015090116467810326\n",
      "Training iteration: 168          last optimization: 165# --> Actions:\n",
      "mean: 0.001431702686304769 sdev: 0.001509889518543539\n",
      "Training iteration: 169          last optimization: 165+ --> Actions:\n",
      "mean: 0.0014325353809271628 sdev: 0.0015109347492734946\n",
      "Training iteration: 170          last optimization: 170# --> Actions:\n",
      "mean: 0.0017810928675151445 sdev: 0.0005445554829372872\n",
      "Training iteration: 171          last optimization: 170+ --> Actions:\n",
      "mean: 0.001781939724368874 sdev: 0.0005458866782408286\n",
      "Training iteration: 172          last optimization: 170# --> Actions:\n",
      "mean: 0.0017827043696954279 sdev: 0.0005473132851524781\n",
      "Training iteration: 173          last optimization: 170+ --> Actions:\n",
      "mean: 0.0017835092742533524 sdev: 0.0005488052110981479\n",
      "Training iteration: 174          last optimization: 170# --> Actions:\n",
      "mean: 0.0017842787626837242 sdev: 0.0005503050004362389\n",
      "Training iteration: 175          last optimization: 175+ --> Actions:\n",
      "mean: 0.0021596704605045406 sdev: 0.0006369807112627628\n",
      "Training iteration: 176          last optimization: 175# --> Actions:\n",
      "mean: 0.0021602584272045716 sdev: 0.000635527400672762\n",
      "Training iteration: 177          last optimization: 175+ --> Actions:\n",
      "mean: 0.002160765376876237 sdev: 0.0006341912847957388\n",
      "Training iteration: 178          last optimization: 175# --> Actions:\n",
      "mean: 0.0021612510268021546 sdev: 0.0006330486303551998\n",
      "Training iteration: 179          last optimization: 175+ --> Actions:\n",
      "mean: 0.0021615778169664585 sdev: 0.0006321401759633401\n",
      "Training iteration: 180          last optimization: 180# --> Actions:\n",
      "mean: 0.002400085750574682 sdev: 0.0014214935385320224\n",
      "Training iteration: 181          last optimization: 180+ --> Actions:\n",
      "mean: 0.002400225985949708 sdev: 0.0014209890567830027\n",
      "Training iteration: 182          last optimization: 180# --> Actions:\n",
      "mean: 0.0024002367009442562 sdev: 0.0014207286569441718\n",
      "Training iteration: 183          last optimization: 180+ --> Actions:\n",
      "mean: 0.0024000425539707658 sdev: 0.0014206444415776139\n",
      "Training iteration: 184          last optimization: 180# --> Actions:\n",
      "mean: 0.002399756591216404 sdev: 0.0014207077237400499\n",
      "Training iteration: 185          last optimization: 185+ --> Actions:\n",
      "mean: 0.0025297337066287643 sdev: 0.0019136551254617196\n",
      "Training iteration: 186          last optimization: 185# --> Actions:\n",
      "mean: 0.0025290797689272596 sdev: 0.0019140646250981827\n",
      "Training iteration: 187          last optimization: 185+ --> Actions:\n",
      "mean: 0.002528228133475444 sdev: 0.0019146200261269991\n",
      "Training iteration: 188          last optimization: 185# --> Actions:\n",
      "mean: 0.0025272938071507433 sdev: 0.0019153643293712075\n",
      "Training iteration: 189          last optimization: 185+ --> Actions:\n",
      "mean: 0.0025262477108962864 sdev: 0.0019162585292420025\n",
      "Training iteration: 190          last optimization: 190# --> Actions:\n",
      "mean: 0.0025708008568907825 sdev: 0.002153000192825241\n",
      "Training iteration: 191          last optimization: 190+ --> Actions:\n",
      "mean: 0.0025694403148631357 sdev: 0.002154288620582806\n",
      "Training iteration: 192          last optimization: 190# --> Actions:\n",
      "mean: 0.002568059877077085 sdev: 0.002155626440125119\n",
      "Training iteration: 193          last optimization: 190+ --> Actions:\n",
      "mean: 0.0025666265787279443 sdev: 0.002156974751248755\n",
      "Training iteration: 194          last optimization: 190# --> Actions:\n",
      "mean: 0.002565202158632437 sdev: 0.002158260829143469\n",
      "Training iteration: 195          last optimization: 195+ --> Actions:\n",
      "mean: 0.0025431636576422664 sdev: 0.002180290115503198\n",
      "Training iteration: 196          last optimization: 195# --> Actions:\n",
      "mean: 0.002541887748537777 sdev: 0.0021814276062203986\n",
      "Training iteration: 197          last optimization: 195+ --> Actions:\n",
      "mean: 0.0025407522402698937 sdev: 0.0021823420093749287\n",
      "Training iteration: 198          last optimization: 195# --> Actions:\n",
      "mean: 0.0025397460265009927 sdev: 0.0021830908228569162\n",
      "Training iteration: 199          last optimization: 195+ --> Actions:\n",
      "mean: 0.0025388109826613553 sdev: 0.0021835494472764697\n",
      "Training iteration: 200          last optimization: 200# --> Actions:\n",
      "mean: 0.0024658848432535007 sdev: 0.0020275012355575987\n",
      "Training iteration: 201          last optimization: 200+ --> Actions:\n",
      "mean: 0.0024652762963188373 sdev: 0.0020276173103381365\n",
      "Training iteration: 202          last optimization: 200# --> Actions:\n",
      "mean: 0.002464859909109973 sdev: 0.002027483090105462\n",
      "Training iteration: 203          last optimization: 200+ --> Actions:\n",
      "mean: 0.002464631548144144 sdev: 0.002027150758980219\n",
      "Training iteration: 204          last optimization: 200# --> Actions:\n",
      "mean: 0.00246447948701222 sdev: 0.0020267759110920262\n",
      "Training iteration: 205          last optimization: 205+ --> Actions:\n",
      "mean: 0.0023547750156334194 sdev: 0.0017236193633261955\n",
      "Training iteration: 206          last optimization: 205# --> Actions:\n",
      "mean: 0.0023546833024765805 sdev: 0.001723377306688149\n",
      "Training iteration: 207          last optimization: 205+ --> Actions:\n",
      "mean: 0.0023546116376314576 sdev: 0.0017231085365928395\n",
      "Training iteration: 208          last optimization: 205# --> Actions:\n",
      "mean: 0.0023545519460780374 sdev: 0.0017229671007496466\n",
      "Training iteration: 209          last optimization: 205+ --> Actions:\n",
      "mean: 0.0023545531538529266 sdev: 0.001722912474975055\n",
      "Training iteration: 210          last optimization: 210# --> Actions:\n",
      "mean: 0.002222536326423832 sdev: 0.0012927494016902123\n",
      "Training iteration: 211          last optimization: 210+ --> Actions:\n",
      "mean: 0.002222490295854451 sdev: 0.001293189100173884\n",
      "Training iteration: 212          last optimization: 210# --> Actions:\n",
      "mean: 0.002222302690220667 sdev: 0.0012937840992722836\n",
      "Training iteration: 213          last optimization: 210+ --> Actions:\n",
      "mean: 0.002222083623812355 sdev: 0.0012943984516873887\n",
      "Training iteration: 214          last optimization: 210# --> Actions:\n",
      "mean: 0.0022218231434606543 sdev: 0.0012950864707357644\n",
      "Training iteration: 215          last optimization: 215+ --> Actions:\n",
      "mean: 0.002082686520841782 sdev: 0.0007414864166364525\n",
      "Training iteration: 216          last optimization: 215# --> Actions:\n",
      "mean: 0.002082280499582549 sdev: 0.0007424190857547239\n",
      "Training iteration: 217          last optimization: 215+ --> Actions:\n",
      "mean: 0.002081809621425656 sdev: 0.000743422438133824\n",
      "Training iteration: 218          last optimization: 215# --> Actions:\n",
      "mean: 0.0020813737454390357 sdev: 0.0007444123843374623\n",
      "Training iteration: 219          last optimization: 215+ --> Actions:\n",
      "mean: 0.0020808626883039383 sdev: 0.0007454140130357514\n",
      "Training iteration: 220          last optimization: 220# --> Actions:\n",
      "mean: 0.001950027481266263 sdev: 0.0001398434804025052\n",
      "Training iteration: 221          last optimization: 220+ --> Actions:\n",
      "mean: 0.0019493386760617184 sdev: 0.00013943656944882132\n",
      "Training iteration: 222          last optimization: 220# --> Actions:\n",
      "mean: 0.0019487079829332396 sdev: 0.00013915856392461486\n",
      "Training iteration: 223          last optimization: 220+ --> Actions:\n",
      "mean: 0.001948121366995997 sdev: 0.00013905064393567422\n",
      "Training iteration: 224          last optimization: 220# --> Actions:\n",
      "mean: 0.0019476898864263653 sdev: 0.00013904710141977525\n",
      "Training iteration: 225          last optimization: 225+ --> Actions:\n",
      "mean: 0.0018492693034073842 sdev: 0.0007777265655141586\n",
      "Training iteration: 226          last optimization: 225# --> Actions:\n",
      "mean: 0.0018491342153679658 sdev: 0.0007778331596192629\n",
      "Training iteration: 227          last optimization: 225+ --> Actions:\n",
      "mean: 0.0018491788552997038 sdev: 0.0007782156397120668\n",
      "Training iteration: 228          last optimization: 225# --> Actions:\n",
      "mean: 0.0018494018971865294 sdev: 0.0007787629203199211\n",
      "Training iteration: 229          last optimization: 225+ --> Actions:\n",
      "mean: 0.001849869978542346 sdev: 0.000779520529111095\n",
      "Training iteration: 230          last optimization: 230# --> Actions:\n",
      "mean: 0.0017520012200709905 sdev: 0.0012272122266931357\n",
      "Training iteration: 231          last optimization: 230+ --> Actions:\n",
      "mean: 0.0017526479886064456 sdev: 0.0012283671073771358\n",
      "Training iteration: 232          last optimization: 230# --> Actions:\n",
      "mean: 0.0017533722949644934 sdev: 0.0012296374097349454\n",
      "Training iteration: 233          last optimization: 230+ --> Actions:\n",
      "mean: 0.0017542253462039057 sdev: 0.001231051307459959\n",
      "Training iteration: 234          last optimization: 230# --> Actions:\n",
      "mean: 0.0017551353391569529 sdev: 0.001232516128191123\n",
      "Training iteration: 235          last optimization: 235+ --> Actions:\n",
      "mean: 0.00167254989294564 sdev: 0.001377606039932076\n",
      "Training iteration: 236          last optimization: 235# --> Actions:\n",
      "mean: 0.0016734812912182339 sdev: 0.0013790251199464862\n",
      "Training iteration: 237          last optimization: 235+ --> Actions:\n",
      "mean: 0.0016744272951339585 sdev: 0.0013803634133430615\n",
      "Training iteration: 238          last optimization: 235# --> Actions:\n",
      "mean: 0.0016753249699939666 sdev: 0.001381650425785322\n",
      "Training iteration: 239          last optimization: 235+ --> Actions:\n",
      "mean: 0.001676147776223265 sdev: 0.001382802674418992\n",
      "Training iteration: 240          last optimization: 240# --> Actions:\n",
      "mean: 0.001620424388700434 sdev: 0.0013072057053580865\n",
      "Training iteration: 241          last optimization: 240+ --> Actions:\n",
      "mean: 0.0016209963901394086 sdev: 0.001308021334940692\n",
      "Training iteration: 242          last optimization: 240# --> Actions:\n",
      "mean: 0.001621420525007107 sdev: 0.0013087485784233266\n",
      "Training iteration: 243          last optimization: 240+ --> Actions:\n",
      "mean: 0.0016216394938056808 sdev: 0.001309400644626989\n",
      "Training iteration: 244          last optimization: 240# --> Actions:\n",
      "mean: 0.0016217390472850527 sdev: 0.001309951337467493\n",
      "Training iteration: 245          last optimization: 245+ --> Actions:\n",
      "mean: 0.0016074988507096162 sdev: 0.0011040896473903813\n",
      "Training iteration: 246          last optimization: 245# --> Actions:\n",
      "mean: 0.00160750590241922 sdev: 0.0011043849179550303\n",
      "Training iteration: 247          last optimization: 245+ --> Actions:\n",
      "mean: 0.0016074512480848148 sdev: 0.0011045673995272872\n",
      "Training iteration: 248          last optimization: 245# --> Actions:\n",
      "mean: 0.0016073657205433283 sdev: 0.0011046162725296723\n",
      "Training iteration: 249          last optimization: 245+ --> Actions:\n",
      "mean: 0.0016073110338379229 sdev: 0.0011046065239151287\n",
      "Training iteration: 250          last optimization: 250# --> Actions:\n",
      "mean: 0.0016583741575492178 sdev: 0.0008447962210889699\n",
      "Training iteration: 251          last optimization: 250+ --> Actions:\n",
      "mean: 0.0016582896772097135 sdev: 0.0008445278016650793\n",
      "Training iteration: 252          last optimization: 250# --> Actions:\n",
      "mean: 0.0016582956229105664 sdev: 0.0008443984174372649\n",
      "Training iteration: 253          last optimization: 250+ --> Actions:\n",
      "mean: 0.0016584108969566684 sdev: 0.0008444950105164621\n",
      "Training iteration: 254          last optimization: 250# --> Actions:\n",
      "mean: 0.0016586604399543622 sdev: 0.0008448291463509146\n",
      "Training iteration: 255          last optimization: 255+ --> Actions:\n",
      "mean: 0.0017958732337560227 sdev: 0.0005373775983108511\n",
      "Training iteration: 256          last optimization: 255# --> Actions:\n",
      "mean: 0.0017963981303118794 sdev: 0.0005381049634794401\n",
      "Training iteration: 257          last optimization: 255+ --> Actions:\n",
      "mean: 0.0017970484863868877 sdev: 0.0005390369448405141\n",
      "Training iteration: 258          last optimization: 255# --> Actions:\n",
      "mean: 0.001797735160243618 sdev: 0.0005401152255085979\n",
      "Training iteration: 259          last optimization: 255+ --> Actions:\n",
      "mean: 0.0017985604505345635 sdev: 0.0005414401086481085\n",
      "Training iteration: 260          last optimization: 260# --> Actions:\n",
      "mean: 0.001998204513705886 sdev: 0.00029212253588546444\n",
      "Training iteration: 261          last optimization: 260+ --> Actions:\n",
      "mean: 0.0019991951684365985 sdev: 0.0002910661543330345\n",
      "Training iteration: 262          last optimization: 260# --> Actions:\n",
      "mean: 0.0020001608075869435 sdev: 0.00029008238274756047\n",
      "Training iteration: 263          last optimization: 260+ --> Actions:\n",
      "mean: 0.0020010940127572607 sdev: 0.0002891160521147926\n",
      "Training iteration: 264          last optimization: 260# --> Actions:\n",
      "mean: 0.0020019957259306094 sdev: 0.00028827178158692283\n",
      "Training iteration: 265          last optimization: 265+ --> Actions:\n",
      "mean: 0.0021580580570241476 sdev: 0.0006322055945951307\n",
      "Training iteration: 266          last optimization: 265# --> Actions:\n",
      "mean: 0.002158777751749659 sdev: 0.00063152633410241\n",
      "Training iteration: 267          last optimization: 265+ --> Actions:\n",
      "mean: 0.002159352900285665 sdev: 0.0006311359984164544\n",
      "Training iteration: 268          last optimization: 265# --> Actions:\n",
      "mean: 0.0021597830177712382 sdev: 0.0006309833901987302\n",
      "Training iteration: 269          last optimization: 265+ --> Actions:\n",
      "mean: 0.0021599212759359685 sdev: 0.0006310001083291614\n",
      "Training iteration: 270          last optimization: 270# --> Actions:\n",
      "mean: 0.0022143015599604666 sdev: 0.0008769246301081165\n",
      "Training iteration: 271          last optimization: 270+ --> Actions:\n",
      "mean: 0.0022140686013681597 sdev: 0.0008772948934123672\n",
      "Training iteration: 272          last optimization: 270# --> Actions:\n",
      "mean: 0.0022136619485457407 sdev: 0.0008777760356766433\n",
      "Training iteration: 273          last optimization: 270+ --> Actions:\n",
      "mean: 0.0022131706099147047 sdev: 0.0008783352070474657\n",
      "Training iteration: 274          last optimization: 270# --> Actions:\n",
      "mean: 0.0022125775750892534 sdev: 0.0008789826810340891\n",
      "Training iteration: 275          last optimization: 275+ --> Actions:\n",
      "mean: 0.0021888015972832985 sdev: 0.0008374530628548543\n",
      "Training iteration: 276          last optimization: 275# --> Actions:\n",
      "mean: 0.0021879435211871975 sdev: 0.0008382583097645015\n",
      "Training iteration: 277          last optimization: 275+ --> Actions:\n",
      "mean: 0.0021869843200005854 sdev: 0.0008391754127932677\n",
      "Training iteration: 278          last optimization: 275# --> Actions:\n",
      "mean: 0.002186000507056134 sdev: 0.0008400733444618554\n",
      "Training iteration: 279          last optimization: 275+ --> Actions:\n",
      "mean: 0.002185006387062932 sdev: 0.0008409484271468826\n",
      "Training iteration: 280          last optimization: 280# --> Actions:\n",
      "mean: 0.002104240390639418 sdev: 0.0005685399147594015\n",
      "Training iteration: 281          last optimization: 280+ --> Actions:\n",
      "mean: 0.0021034458966085095 sdev: 0.0005693976350793317\n",
      "Training iteration: 282          last optimization: 280# --> Actions:\n",
      "mean: 0.0021027542442155316 sdev: 0.0005700648229052781\n",
      "Training iteration: 283          last optimization: 280+ --> Actions:\n",
      "mean: 0.002102211909102602 sdev: 0.0005705503845851237\n",
      "Training iteration: 284          last optimization: 280# --> Actions:\n",
      "mean: 0.002101776343662009 sdev: 0.0005708832197265314\n",
      "Training iteration: 285          last optimization: 285+ --> Actions:\n",
      "mean: 0.0019802844923837684 sdev: 0.00029531374492061045\n",
      "Training iteration: 286          last optimization: 285# --> Actions:\n",
      "mean: 0.0019800169470181837 sdev: 0.00029583794853720583\n",
      "Training iteration: 287          last optimization: 285+ --> Actions:\n",
      "mean: 0.001979892729989582 sdev: 0.00029627249518073093\n",
      "Training iteration: 288          last optimization: 285# --> Actions:\n",
      "mean: 0.0019798365674761507 sdev: 0.00029672198397753493\n",
      "Training iteration: 289          last optimization: 285+ --> Actions:\n",
      "mean: 0.0019797353847697875 sdev: 0.00029723040624147525\n",
      "Training iteration: 290          last optimization: 290# --> Actions:\n",
      "mean: 0.001877566700637684 sdev: 0.00035378867296756693\n",
      "Training iteration: 291          last optimization: 290+ --> Actions:\n",
      "mean: 0.0018774289892089513 sdev: 0.0003539883152249806\n",
      "Training iteration: 292          last optimization: 290# --> Actions:\n",
      "mean: 0.0018773594784609077 sdev: 0.0003540058613987543\n",
      "Training iteration: 293          last optimization: 290+ --> Actions:\n",
      "mean: 0.0018772436603712943 sdev: 0.0003537885729321227\n",
      "Training iteration: 294          last optimization: 290# --> Actions:\n",
      "mean: 0.0018770438324865711 sdev: 0.0003533415173145655\n",
      "Training iteration: 295          last optimization: 295+ --> Actions:\n",
      "mean: 0.0018370683952752566 sdev: 0.00048593421448026047\n",
      "Training iteration: 296          last optimization: 295# --> Actions:\n",
      "mean: 0.0018368051767939872 sdev: 0.00048484108381727253\n",
      "Training iteration: 297          last optimization: 295+ --> Actions:\n",
      "mean: 0.0018364509116848657 sdev: 0.0004835445066508628\n",
      "Training iteration: 298          last optimization: 295# --> Actions:\n",
      "mean: 0.001836028119722942 sdev: 0.0004820527136309365\n",
      "Training iteration: 299          last optimization: 295+ --> Actions:\n",
      "mean: 0.0018355180762081222 sdev: 0.0004804815902502697\n",
      "Training iteration: 300          last optimization: 300# --> Actions:\n",
      "mean: 0.0018412110861984864 sdev: 0.0005732074403800942\n",
      "Training iteration: 301          last optimization: 300+ --> Actions:\n",
      "mean: 0.001840575560828342 sdev: 0.0005718269909741852\n",
      "Training iteration: 302          last optimization: 300# --> Actions:\n",
      "mean: 0.001839892995769762 sdev: 0.0005705315203508489\n",
      "Training iteration: 303          last optimization: 300+ --> Actions:\n",
      "mean: 0.0018390902282424619 sdev: 0.0005691484728335352\n",
      "Training iteration: 304          last optimization: 300# --> Actions:\n",
      "mean: 0.0018382220911038964 sdev: 0.0005676848444896609\n",
      "Training iteration: 305          last optimization: 305+ --> Actions:\n",
      "mean: 0.0018696045535237966 sdev: 0.000497338998355024\n",
      "Training iteration: 306          last optimization: 305# --> Actions:\n",
      "mean: 0.001868840841834157 sdev: 0.0004964045216975788\n",
      "Training iteration: 307          last optimization: 305+ --> Actions:\n",
      "mean: 0.001868203831993484 sdev: 0.0004956314552918299\n",
      "Training iteration: 308          last optimization: 305# --> Actions:\n",
      "mean: 0.0018676825683338033 sdev: 0.0004949932057179966\n",
      "Training iteration: 309          last optimization: 305+ --> Actions:\n",
      "mean: 0.0018673481770643968 sdev: 0.0004945425413332302\n",
      "Training iteration: 310          last optimization: 310# --> Actions:\n",
      "mean: 0.0019117080704107886 sdev: 0.00019729049781808922\n",
      "Training iteration: 311          last optimization: 310+ --> Actions:\n",
      "mean: 0.001911867029500978 sdev: 0.00019752195982822255\n",
      "Training iteration: 312          last optimization: 310# --> Actions:\n",
      "mean: 0.0019122802572167717 sdev: 0.00019804672975987038\n",
      "Training iteration: 313          last optimization: 310+ --> Actions:\n",
      "mean: 0.001912893352163874 sdev: 0.00019875404060802507\n",
      "Training iteration: 314          last optimization: 310# --> Actions:\n",
      "mean: 0.0019136178458835443 sdev: 0.00019970816614781837\n",
      "Training iteration: 315          last optimization: 315+ --> Actions:\n",
      "mean: 0.0019651543359637804 sdev: 0.00035832757585995756\n",
      "Training iteration: 316          last optimization: 315# --> Actions:\n",
      "mean: 0.0019660023270162254 sdev: 0.0003573286357696163\n",
      "Training iteration: 317          last optimization: 315+ --> Actions:\n",
      "mean: 0.0019668917694632905 sdev: 0.000356281988912892\n",
      "Training iteration: 318          last optimization: 315# --> Actions:\n",
      "mean: 0.0019678491184118496 sdev: 0.00035517551527322215\n",
      "Training iteration: 319          last optimization: 315+ --> Actions:\n",
      "mean: 0.001968893428432661 sdev: 0.000354010282441883\n",
      "Training iteration: 320          last optimization: 320# --> Actions:\n",
      "mean: 0.002011414341213749 sdev: 0.0005540688427560605\n",
      "Training iteration: 321          last optimization: 320+ --> Actions:\n",
      "mean: 0.002012573945040001 sdev: 0.0005525581349579581\n",
      "Training iteration: 322          last optimization: 320# --> Actions:\n",
      "mean: 0.0020136732835757164 sdev: 0.0005511467299778749\n",
      "Training iteration: 323          last optimization: 320+ --> Actions:\n",
      "mean: 0.0020147915191838827 sdev: 0.000549755159031535\n",
      "Training iteration: 324          last optimization: 320# --> Actions:\n",
      "mean: 0.0020159019305651766 sdev: 0.0005483452595367404\n",
      "Training iteration: 325          last optimization: 325+ --> Actions:\n",
      "mean: 0.002039604482543134 sdev: 0.0005018914847368203\n",
      "Training iteration: 326          last optimization: 325# --> Actions:\n",
      "mean: 0.002040365022597858 sdev: 0.0005008035096326784\n",
      "Training iteration: 327          last optimization: 325+ --> Actions:\n",
      "mean: 0.002040989522438808 sdev: 0.0004999045539452589\n",
      "Training iteration: 328          last optimization: 325# --> Actions:\n",
      "mean: 0.0020414238700391923 sdev: 0.0004991462001294768\n",
      "Training iteration: 329          last optimization: 325+ --> Actions:\n",
      "mean: 0.002041549814911635 sdev: 0.0004984725028198228\n",
      "Training iteration: 330          last optimization: 330# --> Actions:\n",
      "mean: 0.002035443086329175 sdev: 0.00034911322984957266\n",
      "Training iteration: 331          last optimization: 330+ --> Actions:\n",
      "mean: 0.002035227565662565 sdev: 0.0003488262240479776\n",
      "Training iteration: 332          last optimization: 330# --> Actions:\n",
      "mean: 0.002035001653023151 sdev: 0.0003486133194863989\n",
      "Training iteration: 333          last optimization: 330+ --> Actions:\n",
      "mean: 0.0020347507657849503 sdev: 0.00034848101845232895\n",
      "Training iteration: 334          last optimization: 330# --> Actions:\n",
      "mean: 0.00203452723063242 sdev: 0.00034828326828537207\n",
      "Training iteration: 335          last optimization: 335+ --> Actions:\n",
      "mean: 0.001983685876579507 sdev: 0.0002524169939074504\n",
      "Training iteration: 336          last optimization: 335# --> Actions:\n",
      "mean: 0.0019835634370702323 sdev: 0.00025225506353266925\n",
      "Training iteration: 337          last optimization: 335+ --> Actions:\n",
      "mean: 0.0019834622287362774 sdev: 0.0002520128895161506\n",
      "Training iteration: 338          last optimization: 335# --> Actions:\n",
      "mean: 0.001983435743802985 sdev: 0.0002517339630747063\n",
      "Training iteration: 339          last optimization: 335+ --> Actions:\n",
      "mean: 0.00198353018039779 sdev: 0.0002513591957391186\n",
      "Training iteration: 340          last optimization: 340# --> Actions:\n",
      "mean: 0.0019103921022899744 sdev: 0.00027179395602074325\n",
      "Training iteration: 341          last optimization: 340+ --> Actions:\n",
      "mean: 0.001910659697456869 sdev: 0.00027317084558595595\n",
      "Training iteration: 342          last optimization: 340# --> Actions:\n",
      "mean: 0.00191107053520458 sdev: 0.0002746820239605256\n",
      "Training iteration: 343          last optimization: 340+ --> Actions:\n",
      "mean: 0.001911589881631028 sdev: 0.00027635082659987586\n",
      "Training iteration: 344          last optimization: 340# --> Actions:\n",
      "mean: 0.0019121825492025867 sdev: 0.0002780205106637081\n",
      "Training iteration: 345          last optimization: 345+ --> Actions:\n",
      "mean: 0.001875572952557935 sdev: 0.00041165278284301945\n",
      "Training iteration: 346          last optimization: 345# --> Actions:\n",
      "mean: 0.001876302565928925 sdev: 0.0004134898180150097\n",
      "Training iteration: 347          last optimization: 345+ --> Actions:\n",
      "mean: 0.0018769046124539955 sdev: 0.00041527586204253067\n",
      "Training iteration: 348          last optimization: 345# --> Actions:\n",
      "mean: 0.0018774585948169865 sdev: 0.0004169198973301629\n",
      "Training iteration: 349          last optimization: 345+ --> Actions:\n",
      "mean: 0.001877989971677613 sdev: 0.0004184048236118345\n",
      "Training iteration: 350          last optimization: 350# --> Actions:\n",
      "mean: 0.0018869999763228916 sdev: 0.00035364499719456777\n",
      "Training iteration: 351          last optimization: 350+ --> Actions:\n",
      "mean: 0.001887405234685369 sdev: 0.00035447766302736214\n",
      "Training iteration: 352          last optimization: 350# --> Actions:\n",
      "mean: 0.0018877949373644273 sdev: 0.0003550204599013746\n",
      "Training iteration: 353          last optimization: 350+ --> Actions:\n",
      "mean: 0.0018880861042131808 sdev: 0.0003552777721870242\n",
      "Training iteration: 354          last optimization: 350# --> Actions:\n",
      "mean: 0.001888179166925786 sdev: 0.0003552398584278201\n",
      "Training iteration: 355          last optimization: 355+ --> Actions:\n",
      "mean: 0.0019416266051702116 sdev: 8.506120691176239e-05\n",
      "Training iteration: 356          last optimization: 355# --> Actions:\n",
      "mean: 0.001941442948486338 sdev: 8.448700450226987e-05\n",
      "Training iteration: 357          last optimization: 355+ --> Actions:\n",
      "mean: 0.001941116411275728 sdev: 8.381267541761493e-05\n",
      "Training iteration: 358          last optimization: 355# --> Actions:\n",
      "mean: 0.001940734533914285 sdev: 8.303650792944442e-05\n",
      "Training iteration: 359          last optimization: 355+ --> Actions:\n",
      "mean: 0.0019401825995444956 sdev: 8.220753576934178e-05\n",
      "Training iteration: 360          last optimization: 360# --> Actions:\n",
      "mean: 0.0020714021524005934 sdev: 0.0003760774330751287\n",
      "Training iteration: 361          last optimization: 360+ --> Actions:\n",
      "mean: 0.002070551999444525 sdev: 0.0003769082296552495\n",
      "Training iteration: 362          last optimization: 360# --> Actions:\n",
      "mean: 0.00206965955087976 sdev: 0.00037783439446408527\n",
      "Training iteration: 363          last optimization: 360+ --> Actions:\n",
      "mean: 0.0020686639163833703 sdev: 0.0003789880297047458\n",
      "Training iteration: 364          last optimization: 360# --> Actions:\n",
      "mean: 0.0020676276899203897 sdev: 0.0003802126981544151\n",
      "Training iteration: 365          last optimization: 365+ --> Actions:\n",
      "mean: 0.002120965055456497 sdev: 0.000527488218452991\n",
      "Training iteration: 366          last optimization: 365# --> Actions:\n",
      "mean: 0.002119907080907458 sdev: 0.0005288306986193822\n",
      "Training iteration: 367          last optimization: 365+ --> Actions:\n",
      "mean: 0.00211896279784187 sdev: 0.0005300634809925203\n",
      "Training iteration: 368          last optimization: 365# --> Actions:\n",
      "mean: 0.0021182052758034688 sdev: 0.0005310829764527057\n",
      "Training iteration: 369          last optimization: 365+ --> Actions:\n",
      "mean: 0.0021176100277830283 sdev: 0.0005318852085185192\n",
      "Training iteration: 370          last optimization: 370# --> Actions:\n",
      "mean: 0.0020999467831870292 sdev: 0.00045923772401616287\n",
      "Training iteration: 371          last optimization: 370+ --> Actions:\n",
      "mean: 0.0020996420838189254 sdev: 0.00045961402672743435\n",
      "Training iteration: 372          last optimization: 370# --> Actions:\n",
      "mean: 0.0020994920883292316 sdev: 0.00045977204358614484\n",
      "Training iteration: 373          last optimization: 370+ --> Actions:\n",
      "mean: 0.0020994098019233246 sdev: 0.0004598718497241692\n",
      "Training iteration: 374          last optimization: 370# --> Actions:\n",
      "mean: 0.0020994236351588934 sdev: 0.00045997203404987756\n",
      "Training iteration: 375          last optimization: 375+ --> Actions:\n",
      "mean: 0.0020155935525504216 sdev: 0.0002457069922206903\n",
      "Training iteration: 376          last optimization: 375# --> Actions:\n",
      "mean: 0.0020157073100984446 sdev: 0.0002456849034174499\n",
      "Training iteration: 377          last optimization: 375+ --> Actions:\n",
      "mean: 0.0020158408972568717 sdev: 0.0002459102914876954\n",
      "Training iteration: 378          last optimization: 375# --> Actions:\n",
      "mean: 0.002015976210862011 sdev: 0.00024635180361283146\n",
      "Training iteration: 379          last optimization: 375+ --> Actions:\n",
      "mean: 0.002016107782653649 sdev: 0.0002469818750283432\n",
      "Training iteration: 380          last optimization: 380# --> Actions:\n",
      "mean: 0.0018873904387705885 sdev: 0.00021575024391490573\n",
      "Training iteration: 381          last optimization: 380+ --> Actions:\n",
      "mean: 0.0018872917137120067 sdev: 0.00021475836461630336\n",
      "Training iteration: 382          last optimization: 380# --> Actions:\n",
      "mean: 0.0018871127363782937 sdev: 0.00021365204963426753\n",
      "Training iteration: 383          last optimization: 380+ --> Actions:\n",
      "mean: 0.001886952147256695 sdev: 0.0002126484942935168\n",
      "Training iteration: 384          last optimization: 380# --> Actions:\n",
      "mean: 0.0018868150254598502 sdev: 0.00021170854234781828\n",
      "Training iteration: 385          last optimization: 385+ --> Actions:\n",
      "mean: 0.0018401194764969269 sdev: 0.0003457415555531546\n",
      "Training iteration: 386          last optimization: 385# --> Actions:\n",
      "mean: 0.0018398243601770565 sdev: 0.0003444836650826172\n",
      "Training iteration: 387          last optimization: 385+ --> Actions:\n",
      "mean: 0.0018395376553479333 sdev: 0.00034318758448068857\n",
      "Training iteration: 388          last optimization: 385# --> Actions:\n",
      "mean: 0.001839245389145583 sdev: 0.0003419537243126082\n",
      "Training iteration: 389          last optimization: 385+ --> Actions:\n",
      "mean: 0.001838878388937766 sdev: 0.00034081360419683214\n",
      "Training iteration: 390          last optimization: 390# --> Actions:\n",
      "mean: 0.0018635223005089776 sdev: 0.0003512459060099808\n",
      "Training iteration: 391          last optimization: 390+ --> Actions:\n",
      "mean: 0.0018631389267027715 sdev: 0.0003501716281463642\n",
      "Training iteration: 392          last optimization: 390# --> Actions:\n",
      "mean: 0.001862754545078079 sdev: 0.0003492628126990658\n",
      "Training iteration: 393          last optimization: 390+ --> Actions:\n",
      "mean: 0.0018624472925028931 sdev: 0.0003486165116540027\n",
      "Training iteration: 394          last optimization: 390# --> Actions:\n",
      "mean: 0.0018622285275522986 sdev: 0.00034821894096169535\n",
      "Training iteration: 395          last optimization: 395+ --> Actions:\n",
      "mean: 0.0019291934226485883 sdev: 0.0002119440594809242\n",
      "Training iteration: 396          last optimization: 395# --> Actions:\n",
      "mean: 0.0019291178131275028 sdev: 0.00021236525322103586\n",
      "Training iteration: 397          last optimization: 395+ --> Actions:\n",
      "mean: 0.0019291884906287413 sdev: 0.00021308751343335902\n",
      "Training iteration: 398          last optimization: 395# --> Actions:\n",
      "mean: 0.0019294658036192627 sdev: 0.00021413010317417958\n",
      "Training iteration: 399          last optimization: 395+ --> Actions:\n",
      "mean: 0.0019299395799649937 sdev: 0.00021545911898386796\n",
      "Training iteration: 400          last optimization: 400# --> Actions:\n",
      "mean: 0.0019896400530056237 sdev: 0.00017003652548396955\n",
      "Training iteration: 401          last optimization: 400+ --> Actions:\n",
      "mean: 0.0019903449390047375 sdev: 0.00016851993269523997\n",
      "Training iteration: 402          last optimization: 400# --> Actions:\n",
      "mean: 0.0019911246752025717 sdev: 0.00016677408137264952\n",
      "Training iteration: 403          last optimization: 400+ --> Actions:\n",
      "mean: 0.0019919127116442064 sdev: 0.0001648845743547773\n",
      "Training iteration: 404          last optimization: 400# --> Actions:\n",
      "mean: 0.0019926524399888792 sdev: 0.00016303470970008776\n",
      "Training iteration: 405          last optimization: 405+ --> Actions:\n",
      "mean: 0.001983964095404964 sdev: 0.00026519262538793196\n",
      "Training iteration: 406          last optimization: 405# --> Actions:\n",
      "mean: 0.001984867665439327 sdev: 0.0002634606938306225\n",
      "Training iteration: 407          last optimization: 405+ --> Actions:\n",
      "mean: 0.0019857651845206466 sdev: 0.00026175486558714054\n",
      "Training iteration: 408          last optimization: 405# --> Actions:\n",
      "mean: 0.0019866349731796603 sdev: 0.00026019774268098305\n",
      "Training iteration: 409          last optimization: 405+ --> Actions:\n",
      "mean: 0.0019874612973946977 sdev: 0.00025878376405517943\n",
      "Training iteration: 410          last optimization: 410# --> Actions:\n",
      "mean: 0.001963920479921096 sdev: 0.00022738897430439755\n",
      "Training iteration: 411          last optimization: 410+ --> Actions:\n",
      "mean: 0.0019646450004421993 sdev: 0.00022660090271854743\n",
      "Training iteration: 412          last optimization: 410# --> Actions:\n",
      "mean: 0.001965287604630536 sdev: 0.00022598700363951724\n",
      "Training iteration: 413          last optimization: 410+ --> Actions:\n",
      "mean: 0.0019658793323667936 sdev: 0.00022553573392437862\n",
      "Training iteration: 414          last optimization: 410# --> Actions:\n",
      "mean: 0.0019664083671031025 sdev: 0.0002253056755458403\n",
      "Training iteration: 415          last optimization: 415+ --> Actions:\n",
      "mean: 0.0019557177644197628 sdev: 5.835042055367531e-05\n",
      "Training iteration: 416          last optimization: 415# --> Actions:\n",
      "mean: 0.001956131097180275 sdev: 5.8334348136393974e-05\n",
      "Training iteration: 417          last optimization: 415+ --> Actions:\n",
      "mean: 0.001956552972887358 sdev: 5.832437050817637e-05\n",
      "Training iteration: 418          last optimization: 415# --> Actions:\n",
      "mean: 0.0019568798753506244 sdev: 5.829777024029037e-05\n",
      "Training iteration: 419          last optimization: 415+ --> Actions:\n",
      "mean: 0.001957205476480901 sdev: 5.825170001607603e-05\n",
      "Training iteration: 420          last optimization: 420# --> Actions:\n",
      "mean: 0.0019739854180121125 sdev: 0.0002756431217302956\n",
      "Training iteration: 421          last optimization: 420+ --> Actions:\n",
      "mean: 0.0019742144521697385 sdev: 0.00027590611213096394\n",
      "Training iteration: 422          last optimization: 420# --> Actions:\n",
      "mean: 0.001974389080650022 sdev: 0.0002761938769202478\n",
      "Training iteration: 423          last optimization: 420+ --> Actions:\n",
      "mean: 0.001974442290301096 sdev: 0.0002764398340275444\n",
      "Training iteration: 424          last optimization: 420# --> Actions:\n",
      "mean: 0.0019744915489074326 sdev: 0.0002767172240165904\n",
      "Training iteration: 425          last optimization: 425+ --> Actions:\n",
      "mean: 0.0019732819790774644 sdev: 0.00021287925132532572\n",
      "Training iteration: 426          last optimization: 425# --> Actions:\n",
      "mean: 0.0019733568062693797 sdev: 0.00021313032723786838\n",
      "Training iteration: 427          last optimization: 425+ --> Actions:\n",
      "mean: 0.0019734702039496893 sdev: 0.00021332114568552925\n",
      "Training iteration: 428          last optimization: 425# --> Actions:\n",
      "mean: 0.00197365870670176 sdev: 0.0002134027390915653\n",
      "Training iteration: 429          last optimization: 425+ --> Actions:\n",
      "mean: 0.0019739090736258192 sdev: 0.00021350733309764348\n",
      "Training iteration: 430          last optimization: 430# --> Actions:\n",
      "mean: 0.0019629883474792595 sdev: 0.00017164712494230672\n",
      "Training iteration: 431          last optimization: 430+ --> Actions:\n",
      "mean: 0.001963307157933408 sdev: 0.00017198500806461477\n",
      "Training iteration: 432          last optimization: 430# --> Actions:\n",
      "mean: 0.00196354895935846 sdev: 0.0001722445240460837\n",
      "Training iteration: 433          last optimization: 430+ --> Actions:\n",
      "mean: 0.0019637915805203053 sdev: 0.0001723799887904833\n",
      "Training iteration: 434          last optimization: 430# --> Actions:\n",
      "mean: 0.0019639948435370646 sdev: 0.0001724165364105788\n",
      "Training iteration: 435          last optimization: 435+ --> Actions:\n",
      "mean: 0.0019700743414523257 sdev: 0.00018466804328611753\n",
      "Training iteration: 436          last optimization: 435# --> Actions:\n",
      "mean: 0.0019700520545103926 sdev: 0.00018458817824866495\n",
      "Training iteration: 437          last optimization: 435+ --> Actions:\n",
      "mean: 0.0019699064590271076 sdev: 0.00018460244326254656\n",
      "Training iteration: 438          last optimization: 435# --> Actions:\n",
      "mean: 0.001969664091301791 sdev: 0.00018474236607457913\n",
      "Training iteration: 439          last optimization: 435+ --> Actions:\n",
      "mean: 0.001969358298259244 sdev: 0.0001849829045875651\n",
      "Training iteration: 440          last optimization: 440# --> Actions:\n",
      "mean: 0.001982559261107153 sdev: 0.000148623281154951\n",
      "Training iteration: 441          last optimization: 440+ --> Actions:\n",
      "mean: 0.001982087786978206 sdev: 0.00014990451980038946\n",
      "Training iteration: 442          last optimization: 440# --> Actions:\n",
      "mean: 0.001981594630821543 sdev: 0.00015127808003360268\n",
      "Training iteration: 443          last optimization: 440+ --> Actions:\n",
      "mean: 0.001981092975671994 sdev: 0.00015273996154522334\n",
      "Training iteration: 444          last optimization: 440# --> Actions:\n",
      "mean: 0.001980510828167712 sdev: 0.00015424121159159435\n",
      "Training iteration: 445          last optimization: 445+ --> Actions:\n",
      "mean: 0.0019774145176091407 sdev: 0.00012555153561271388\n",
      "Training iteration: 446          last optimization: 445# --> Actions:\n",
      "mean: 0.001976692729038696 sdev: 0.00012499510406800433\n",
      "Training iteration: 447          last optimization: 445+ --> Actions:\n",
      "mean: 0.001975948170342815 sdev: 0.00012464067520485812\n",
      "Training iteration: 448          last optimization: 445# --> Actions:\n",
      "mean: 0.001975231355718548 sdev: 0.00012442151683710753\n",
      "Training iteration: 449          last optimization: 445+ --> Actions:\n",
      "mean: 0.0019745441964951556 sdev: 0.00012434992474847555\n",
      "Training iteration: 450          last optimization: 450# --> Actions:\n",
      "mean: 0.0019493422197873027 sdev: 0.00019726409559029195\n",
      "Training iteration: 451          last optimization: 450+ --> Actions:\n",
      "mean: 0.0019487238829746872 sdev: 0.00019673975388438745\n",
      "Training iteration: 452          last optimization: 450# --> Actions:\n",
      "mean: 0.0019481550956893662 sdev: 0.00019631197805424378\n",
      "Training iteration: 453          last optimization: 450+ --> Actions:\n",
      "mean: 0.0019476454342907412 sdev: 0.0001960353241260923\n",
      "Training iteration: 454          last optimization: 450# --> Actions:\n",
      "mean: 0.0019472056378714918 sdev: 0.00019604501752931258\n",
      "Training iteration: 455          last optimization: 455+ --> Actions:\n",
      "mean: 0.0019349264482523844 sdev: 0.00016362578652518483\n",
      "Training iteration: 456          last optimization: 455# --> Actions:\n",
      "mean: 0.001934687569145755 sdev: 0.00016364051672181713\n",
      "Training iteration: 457          last optimization: 455+ --> Actions:\n",
      "mean: 0.001934551234560784 sdev: 0.00016381572844025055\n",
      "Training iteration: 458          last optimization: 455# --> Actions:\n",
      "mean: 0.0019345461654578667 sdev: 0.00016418990139654968\n",
      "Training iteration: 459          last optimization: 455+ --> Actions:\n",
      "mean: 0.0019346560748620283 sdev: 0.0001646273500741788\n",
      "Training iteration: 460          last optimization: 460# --> Actions:\n",
      "mean: 0.0019504390008250171 sdev: 0.00016879381933780684\n",
      "Training iteration: 461          last optimization: 460+ --> Actions:\n",
      "mean: 0.0019506684661928782 sdev: 0.00016778698793919734\n",
      "Training iteration: 462          last optimization: 460# --> Actions:\n",
      "mean: 0.0019509479459063495 sdev: 0.00016685698437511877\n",
      "Training iteration: 463          last optimization: 460+ --> Actions:\n",
      "mean: 0.0019513111491402287 sdev: 0.00016608236858811607\n",
      "Training iteration: 464          last optimization: 460# --> Actions:\n",
      "mean: 0.0019516702076305334 sdev: 0.0001654964731570673\n",
      "Training iteration: 465          last optimization: 465+ --> Actions:\n",
      "mean: 0.0019761080812323757 sdev: 0.00015443308830569936\n",
      "Training iteration: 466          last optimization: 465# --> Actions:\n",
      "mean: 0.0019764045995769135 sdev: 0.00015446736498671382\n",
      "Training iteration: 467          last optimization: 465+ --> Actions:\n",
      "mean: 0.0019766461099676677 sdev: 0.00015459572960027664\n",
      "Training iteration: 468          last optimization: 465# --> Actions:\n",
      "mean: 0.001976846645573449 sdev: 0.00015472269606497694\n",
      "Training iteration: 469          last optimization: 465+ --> Actions:\n",
      "mean: 0.001976984803803183 sdev: 0.0001548681705209522\n",
      "Training iteration: 470          last optimization: 470# --> Actions:\n",
      "mean: 0.0019724391981070627 sdev: 0.00016121661325206834\n",
      "Training iteration: 471          last optimization: 470+ --> Actions:\n",
      "mean: 0.0019724110614383413 sdev: 0.0001611547270387185\n",
      "Training iteration: 472          last optimization: 470# --> Actions:\n",
      "mean: 0.001972346826934219 sdev: 0.00016110854437078074\n",
      "Training iteration: 473          last optimization: 470+ --> Actions:\n",
      "mean: 0.0019721761446906813 sdev: 0.00016095614340119375\n",
      "Training iteration: 474          last optimization: 470# --> Actions:\n",
      "mean: 0.001971965802630289 sdev: 0.00016074742129879502\n",
      "Training iteration: 475          last optimization: 475+ --> Actions:\n",
      "mean: 0.0019421474936213764 sdev: 0.0001292173996953575\n",
      "Training iteration: 476          last optimization: 475# --> Actions:\n",
      "mean: 0.001941975051929111 sdev: 0.0001294687952405166\n",
      "Training iteration: 477          last optimization: 475+ --> Actions:\n",
      "mean: 0.0019419040927769599 sdev: 0.0001296813756580582\n",
      "Training iteration: 478          last optimization: 475# --> Actions:\n",
      "mean: 0.0019419408753138128 sdev: 0.0001298892544492604\n",
      "Training iteration: 479          last optimization: 475+ --> Actions:\n",
      "mean: 0.001942095985138981 sdev: 0.00013013337151046534\n",
      "Training iteration: 480          last optimization: 480# --> Actions:\n",
      "mean: 0.0019371118912759222 sdev: 0.0001859068668440093\n",
      "Training iteration: 481          last optimization: 480+ --> Actions:\n",
      "mean: 0.0019374545796862874 sdev: 0.00018577386377252554\n",
      "Training iteration: 482          last optimization: 480# --> Actions:\n",
      "mean: 0.001937882753375569 sdev: 0.00018555899270954234\n",
      "Training iteration: 483          last optimization: 480+ --> Actions:\n",
      "mean: 0.0019384547498468383 sdev: 0.00018529134934883168\n",
      "Training iteration: 484          last optimization: 480# --> Actions:\n",
      "mean: 0.0019391572867743477 sdev: 0.00018493159371434098\n",
      "Training iteration: 485          last optimization: 485+ --> Actions:\n",
      "mean: 0.001960925848233082 sdev: 0.00014960821750906119\n",
      "Training iteration: 486          last optimization: 485# --> Actions:\n",
      "mean: 0.0019618316260920773 sdev: 0.00014898014120275576\n",
      "Training iteration: 487          last optimization: 485+ --> Actions:\n",
      "mean: 0.00196275729424012 sdev: 0.00014846067350790033\n",
      "Training iteration: 488          last optimization: 485# --> Actions:\n",
      "mean: 0.001963729368435619 sdev: 0.00014808862014356104\n",
      "Training iteration: 489          last optimization: 485+ --> Actions:\n",
      "mean: 0.00196463753562902 sdev: 0.00014781399792835177\n",
      "Training iteration: 490          last optimization: 490# --> Actions:\n",
      "mean: 0.0019846146603413424 sdev: 0.00017679237018807325\n",
      "Training iteration: 491          last optimization: 490+ --> Actions:\n",
      "mean: 0.0019854588572501804 sdev: 0.00017685030535145117\n",
      "Training iteration: 492          last optimization: 490# --> Actions:\n",
      "mean: 0.0019862878378672177 sdev: 0.00017678573985028422\n",
      "Training iteration: 493          last optimization: 490+ --> Actions:\n",
      "mean: 0.0019870442661197507 sdev: 0.0001766071343375695\n",
      "Training iteration: 494          last optimization: 490# --> Actions:\n",
      "mean: 0.0019876747337195526 sdev: 0.000176337078654637\n",
      "Training iteration: 495          last optimization: 495+ --> Actions:\n",
      "mean: 0.001979612481639501 sdev: 0.00016781122659577862\n",
      "Training iteration: 496          last optimization: 495# --> Actions:\n",
      "mean: 0.0019798778026223944 sdev: 0.00016723435154890372\n",
      "Training iteration: 497          last optimization: 495+ --> Actions:\n",
      "mean: 0.001980035569010811 sdev: 0.00016656942212165123\n",
      "Training iteration: 498          last optimization: 495# --> Actions:\n",
      "mean: 0.0019800629832111465 sdev: 0.00016581905123167406\n",
      "Training iteration: 499          last optimization: 495+ --> Actions:\n",
      "mean: 0.0019799534531847107 sdev: 0.00016512000697938603\n",
      "Training iteration: 500          last optimization: 500#\n",
      "***--> Total Elapsed Runtime: 00:00:03 for training the agent\n"
     ]
    }
   ],
   "source": [
    "# Thx2: https://discuss.pytorch.org/t/how-to-check-if-model-is-on-cuda/180/2?u=ferenc_acs\n",
    "start_time = time()\n",
    "\n",
    "agent.train()\n",
    "\n",
    "end_time = time()\n",
    "\n",
    "print_elapsed_time(start_time, end_time, \"for training the agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***--> Total Elapsed Runtime: 00:00:00 for observing the trained agent\n",
      "#\n",
      "Total score (averaged over agents) this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Some reminders about lambda functions\n",
    "# Thx2: https://realpython.com/python-lambda/\n",
    "# Thx2: https://thispointer.com/python-how-to-use-if-else-elif-in-lambda-functions/\n",
    "\n",
    "RANDOMRUN = False\n",
    "\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "#env_info = env.reset(train_mode=True)[brain_name] # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "avg100sum = np.zeros(num_agents)\n",
    "exectime = 0\n",
    "\n",
    "scores100 = deque(avg100sum, 100)\n",
    "time100 = list()\n",
    "epc = 0\n",
    "\n",
    "\n",
    "#import pdb; pdb.set_trace() # Debug! Debug! Debug! Debug! Debug! Debug! \n",
    "start_time = time()\n",
    "\n",
    "while RANDOMRUN: #== True:\n",
    "    epc += 1\n",
    "    #print(f'\\r#{epc}', end = ' ')\n",
    "    print(f'\\r#{str(epc).rjust(6)}', end = ' ')\n",
    "    #actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = agent.a2c_net.select_action(states)\n",
    "    #actions = np.clip(actions.detach().cpu().numpy(), -1, 1)                  # all actions between -1 and 1\n",
    "        \n",
    "    t_step_b = time()\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    t_step_e = time()\n",
    "    time100.append(t_step_e - t_step_b)\n",
    "    \n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    rewards = env_info.rewards\n",
    "    nprewards = np.array(rewards)\n",
    "    scores += rewards                         # update the score (for each agent)\n",
    "    scores100.append(rewards)\n",
    "    if np.sum(nprewards) > 0:\n",
    "        #for x in scores100:\n",
    "        #    avg100sum += x\n",
    "        print(f'\\r#{epc} Avg 100 Rewards = {np.mean(scores100)}')  \n",
    "        avg100sum = np.zeros(num_agents)\n",
    "        maskagent = nprewards > 0\n",
    "        \n",
    "    if epc%100 == 0:\n",
    "        print(f'Exec time Avg 100: {np.mean(time100)}')\n",
    "        time100 = []\n",
    "        \n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "        \n",
    "end_time = time()\n",
    "\n",
    "print_elapsed_time(start_time, end_time, \"for observing the trained agent\")\n",
    "        \n",
    "print('#')\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-26 / 20-31-23  Notebook for Continuous Control ended.\n"
     ]
    }
   ],
   "source": [
    "print(get_time_string(sep=True), ' Notebook for Continuous Control ended.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
